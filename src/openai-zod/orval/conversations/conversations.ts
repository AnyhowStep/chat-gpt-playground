/**
 * Generated by orval v7.7.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import {
  z as zod
} from 'zod';


/**
 * Create items in a conversation with the given ID.
 * @summary Create items
 */
export const createConversationItemsParams = zod.object({
  "conversation_id": zod.string().describe('The ID of the conversation to add the item to.')
})

export const createConversationItemsQueryParams = zod.object({
  "include": zod.array(zod.enum(['file_search_call.results', 'web_search_call.results', 'web_search_call.action.sources', 'message.input_image.image_url', 'computer_call_output.output.image_url', 'code_interpreter_call.outputs', 'reasoning.encrypted_content', 'message.output_text.logprobs']).describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).')).optional().describe('Additional fields to include in the response. See the `include`\nparameter for [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include) for more information.\n')
})

export const createConversationItemsBodyItemsItemContentItemTypeDefault = "input_text";export const createConversationItemsBodyItemsItemContentItemTypeDefaultOne = "input_image";export const createConversationItemsBodyItemsItemContentItemTypeDefaultTwo = "input_file";export const createConversationItemsBodyItemsItemContentItemTypeDefaultFour = "input_text";export const createConversationItemsBodyItemsItemContentItemTypeDefaultFive = "input_image";export const createConversationItemsBodyItemsItemContentItemTypeDefaultSix = "input_file";export const createConversationItemsBodyItemsItemContentItemTypeDefaultEight = "output_text";export const createConversationItemsBodyItemsItemContentItemAnnotationsItemTypeDefault = "file_citation";export const createConversationItemsBodyItemsItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const createConversationItemsBodyItemsItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const createConversationItemsBodyItemsItemContentItemTypeDefaultNine = "refusal";export const createConversationItemsBodyItemsItemResultsItemAttributesMaxThree = 512;
export const createConversationItemsBodyItemsItemTypeDefaultFour = "computer_call";export const createConversationItemsBodyItemsItemActionTypeDefault = "click";export const createConversationItemsBodyItemsItemActionTypeDefaultOne = "double_click";export const createConversationItemsBodyItemsItemActionTypeDefaultTwo = "drag";export const createConversationItemsBodyItemsItemActionTypeDefaultThree = "keypress";export const createConversationItemsBodyItemsItemActionTypeDefaultFour = "move";export const createConversationItemsBodyItemsItemActionTypeDefaultFive = "screenshot";export const createConversationItemsBodyItemsItemActionTypeDefaultSix = "scroll";export const createConversationItemsBodyItemsItemActionTypeDefaultSeven = "type";export const createConversationItemsBodyItemsItemActionTypeDefaultEight = "wait";export const createConversationItemsBodyItemsItemCallIdMaxOne = 64;
export const createConversationItemsBodyItemsItemTypeDefaultFive = "computer_call_output";export const createConversationItemsBodyItemsItemOutputTypeDefault = "computer_screenshot";export const createConversationItemsBodyItemsItemCallIdMaxThree = 64;
export const createConversationItemsBodyItemsItemTypeDefaultEight = "function_call_output";export const createConversationItemsBodyItemsItemOutputMaxTwo = 10485760;
export const createConversationItemsBodyItemsItemOutputItemTypeDefault = "input_text";export const createConversationItemsBodyItemsItemOutputItemTextMax = 10485760;
export const createConversationItemsBodyItemsItemOutputItemTypeDefaultOne = "input_image";export const createConversationItemsBodyItemsItemOutputItemImageUrlMaxOne = 20971520;
export const createConversationItemsBodyItemsItemOutputItemTypeDefaultTwo = "input_file";export const createConversationItemsBodyItemsItemOutputItemFileDataMaxOne = 33554432;
export const createConversationItemsBodyItemsItemSummaryItemTypeDefault = "summary_text";export const createConversationItemsBodyItemsItemContentItemTypeDefaultOnezero = "reasoning_text";export const createConversationItemsBodyItemsItemTypeDefaultOneone = "code_interpreter_call";export const createConversationItemsBodyItemsItemOutputsItemTypeDefault = "logs";export const createConversationItemsBodyItemsItemOutputsItemTypeDefaultOne = "image";export const createConversationItemsBodyItemsItemActionTypeDefaultOnetwo = "exec";export const createConversationItemsBodyItemsItemOutputItemTypeDefaultThree = "input_text";export const createConversationItemsBodyItemsItemOutputItemTypeDefaultFour = "input_image";export const createConversationItemsBodyItemsItemOutputItemTypeDefaultFive = "input_file";export const createConversationItemsBodyItemsItemTypeDefaultTwoone = "item_reference";export const createConversationItemsBodyItemsMax = 20;


export const createConversationItemsBody = zod.object({
  "items": zod.array(zod.discriminatedUnion('type', [zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'),zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always set to `message`.\n'),
  "role": zod.enum(['user', 'system', 'developer']).describe('The role of the message input. One of `user`, `system`, or `developer`.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(createConversationItemsBodyItemsItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "id": zod.string().describe('The ID of the computer tool call output.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createConversationItemsBodyItemsItemCallIdMaxOne).describe('The ID of the computer tool call that produced the output.'),
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The safety checks reported by the API that have been acknowledged by the developer.').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a computer tool call.'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the function tool call output. Populated when this item is returned via API.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createConversationItemsBodyItemsItemCallIdMaxThree).describe('The unique ID of the function tool call generated by the model.'),
  "type": zod.enum(['function_call_output']).optional().describe('The type of the function tool call output. Always `function_call_output`.'),
  "output": zod.string().max(createConversationItemsBodyItemsItemOutputMaxTwo).describe('A JSON string of the output of the function tool call.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().max(createConversationItemsBodyItemsItemOutputItemTextMax).describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().max(createConversationItemsBodyItemsItemOutputItemImageUrlMaxOne).describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto']).or(zod.null()).optional()
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision)'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().describe('The name of the file to be sent to the model.').or(zod.null()).optional(),
  "file_data": zod.string().max(createConversationItemsBodyItemsItemOutputItemFileDataMaxOne).describe('The base64-encoded data of the file to be sent to the model.').or(zod.null()).optional(),
  "file_url": zod.string().describe('The URL of the file to be sent to the model.').or(zod.null()).optional()
}).describe('A file input to the model.')]))).describe('Text, image, or file output of the function tool call.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a function tool call.'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n').or(zod.null()).optional(),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')]).describe('Content item used to generate a response.\n'),zod.object({
  "type": zod.enum(['item_reference']).optional().describe('The type of item to reference. Always `item_reference`.').or(zod.null()).optional(),
  "id": zod.string().describe('The ID of the item to reference.')
}).describe('An internal identifier for an item to reference.')])).max(createConversationItemsBodyItemsMax).describe('The items to add to the conversation. You may add up to 20 items at a time.\n')
})

export const createConversationItemsResponseDataItemTypeDefault = "message";export const createConversationItemsResponseDataItemContentItemTypeDefault = "input_text";export const createConversationItemsResponseDataItemContentItemTypeDefaultOne = "output_text";export const createConversationItemsResponseDataItemContentItemAnnotationsItemTypeDefault = "file_citation";export const createConversationItemsResponseDataItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const createConversationItemsResponseDataItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const createConversationItemsResponseDataItemContentItemTypeDefaultTwo = "text";export const createConversationItemsResponseDataItemContentItemTypeDefaultThree = "summary_text";export const createConversationItemsResponseDataItemContentItemTypeDefaultFour = "reasoning_text";export const createConversationItemsResponseDataItemContentItemTypeDefaultFive = "refusal";export const createConversationItemsResponseDataItemContentItemTypeDefaultSix = "input_image";export const createConversationItemsResponseDataItemContentItemTypeDefaultSeven = "computer_screenshot";export const createConversationItemsResponseDataItemContentItemTypeDefaultEight = "input_file";export const createConversationItemsResponseDataItemOutputItemTypeDefault = "input_text";export const createConversationItemsResponseDataItemOutputItemTypeDefaultOne = "input_image";export const createConversationItemsResponseDataItemOutputItemTypeDefaultTwo = "input_file";export const createConversationItemsResponseDataItemResultsItemAttributesMaxThree = 512;
export const createConversationItemsResponseDataItemTypeDefaultSix = "computer_call";export const createConversationItemsResponseDataItemActionTypeDefaultThree = "click";export const createConversationItemsResponseDataItemActionTypeDefaultFour = "double_click";export const createConversationItemsResponseDataItemActionTypeDefaultFive = "drag";export const createConversationItemsResponseDataItemActionTypeDefaultSix = "keypress";export const createConversationItemsResponseDataItemActionTypeDefaultSeven = "move";export const createConversationItemsResponseDataItemActionTypeDefaultEight = "screenshot";export const createConversationItemsResponseDataItemActionTypeDefaultNine = "scroll";export const createConversationItemsResponseDataItemActionTypeDefaultOnezero = "type";export const createConversationItemsResponseDataItemActionTypeDefaultOneone = "wait";export const createConversationItemsResponseDataItemTypeDefaultSeven = "computer_call_output";export const createConversationItemsResponseDataItemOutputTypeDefault = "computer_screenshot";export const createConversationItemsResponseDataItemSummaryItemTypeDefault = "summary_text";export const createConversationItemsResponseDataItemContentItemTypeDefaultNine = "reasoning_text";export const createConversationItemsResponseDataItemTypeDefaultNine = "code_interpreter_call";export const createConversationItemsResponseDataItemOutputsItemTypeDefault = "logs";export const createConversationItemsResponseDataItemOutputsItemTypeDefaultOne = "image";export const createConversationItemsResponseDataItemActionTypeDefaultOnetwo = "exec";export const createConversationItemsResponseDataItemOutputItemTypeDefaultThree = "input_text";export const createConversationItemsResponseDataItemOutputItemTypeDefaultFour = "input_image";export const createConversationItemsResponseDataItemOutputItemTypeDefaultFive = "input_file";

export const createConversationItemsResponse = zod.object({
  "object": zod.any().describe('The type of object returned, must be `list`.'),
  "data": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message. Always set to `message`.'),
  "id": zod.string().describe('The unique ID of the message.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']),
  "role": zod.enum(['unknown', 'user', 'assistant', 'system', 'critic', 'discriminator', 'developer', 'tool']),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['text']).optional(),
  "text": zod.string()
}).describe('A text content.'),zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.'),zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is always set to `computer_screenshot`.'),
  "image_url": zod.string().describe('The URL of the screenshot image.').or(zod.null()),
  "file_id": zod.string().describe('The identifier of an uploaded file that contains the screenshot.').or(zod.null())
}).describe('A screenshot of a computer.'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('The content of the message')
}).describe('A message to or from the model.'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function tool call.\n')
})),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call output. Populated when this item\nis returned via API.\n'),
  "type": zod.enum(['function_call_output']).describe('The type of the function tool call output. Always `function_call_output`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "output": zod.string().describe('A string of the output of the function call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the function call.\n')).describe('The output from the function call generated by your code.\nCan be a string or an list of output content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('The output of a function tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function call tool output.\n')
})),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(createConversationItemsResponseDataItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.\n'),
  "id": zod.string().optional().describe('The ID of the computer tool call output.\n'),
  "call_id": zod.string().describe('The ID of the computer tool call that produced the output.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).optional().describe('The safety checks reported by the API that have been acknowledged by the\ndeveloper.\n'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('The output of a computer tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the computer call tool output.\n')
})),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n'),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n')]).describe('A single item within a conversation. The set of possible types are the same as the `output` type of a [Response object](https://platform.openai.com/docs/api-reference/responses/object#responses/object-output).')).describe('A list of conversation items.'),
  "has_more": zod.boolean().describe('Whether there are more items available.'),
  "first_id": zod.string().describe('The ID of the first item in the list.'),
  "last_id": zod.string().describe('The ID of the last item in the list.')
}).describe('A list of Conversation items.')

/**
 * List all items for a conversation with the given ID.
 * @summary List items
 */
export const listConversationItemsParams = zod.object({
  "conversation_id": zod.string().describe('The ID of the conversation to list items for.')
})

export const listConversationItemsQueryLimitDefault = 20;

export const listConversationItemsQueryParams = zod.object({
  "limit": zod.number().optional().describe('A limit on the number of objects to be returned. Limit can range between\n1 and 100, and the default is 20.\n'),
  "order": zod.enum(['asc', 'desc']).optional().describe('The order to return the input items in. Default is `desc`.\n- `asc`: Return the input items in ascending order.\n- `desc`: Return the input items in descending order.\n'),
  "after": zod.string().optional().describe('An item ID to list items after, used in pagination.\n'),
  "include": zod.array(zod.enum(['file_search_call.results', 'web_search_call.results', 'web_search_call.action.sources', 'message.input_image.image_url', 'computer_call_output.output.image_url', 'code_interpreter_call.outputs', 'reasoning.encrypted_content', 'message.output_text.logprobs']).describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).')).optional().describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).')
})

export const listConversationItemsResponseDataItemTypeDefault = "message";export const listConversationItemsResponseDataItemContentItemTypeDefault = "input_text";export const listConversationItemsResponseDataItemContentItemTypeDefaultOne = "output_text";export const listConversationItemsResponseDataItemContentItemAnnotationsItemTypeDefault = "file_citation";export const listConversationItemsResponseDataItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const listConversationItemsResponseDataItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const listConversationItemsResponseDataItemContentItemTypeDefaultTwo = "text";export const listConversationItemsResponseDataItemContentItemTypeDefaultThree = "summary_text";export const listConversationItemsResponseDataItemContentItemTypeDefaultFour = "reasoning_text";export const listConversationItemsResponseDataItemContentItemTypeDefaultFive = "refusal";export const listConversationItemsResponseDataItemContentItemTypeDefaultSix = "input_image";export const listConversationItemsResponseDataItemContentItemTypeDefaultSeven = "computer_screenshot";export const listConversationItemsResponseDataItemContentItemTypeDefaultEight = "input_file";export const listConversationItemsResponseDataItemOutputItemTypeDefault = "input_text";export const listConversationItemsResponseDataItemOutputItemTypeDefaultOne = "input_image";export const listConversationItemsResponseDataItemOutputItemTypeDefaultTwo = "input_file";export const listConversationItemsResponseDataItemResultsItemAttributesMaxThree = 512;
export const listConversationItemsResponseDataItemTypeDefaultSix = "computer_call";export const listConversationItemsResponseDataItemActionTypeDefaultThree = "click";export const listConversationItemsResponseDataItemActionTypeDefaultFour = "double_click";export const listConversationItemsResponseDataItemActionTypeDefaultFive = "drag";export const listConversationItemsResponseDataItemActionTypeDefaultSix = "keypress";export const listConversationItemsResponseDataItemActionTypeDefaultSeven = "move";export const listConversationItemsResponseDataItemActionTypeDefaultEight = "screenshot";export const listConversationItemsResponseDataItemActionTypeDefaultNine = "scroll";export const listConversationItemsResponseDataItemActionTypeDefaultOnezero = "type";export const listConversationItemsResponseDataItemActionTypeDefaultOneone = "wait";export const listConversationItemsResponseDataItemTypeDefaultSeven = "computer_call_output";export const listConversationItemsResponseDataItemOutputTypeDefault = "computer_screenshot";export const listConversationItemsResponseDataItemSummaryItemTypeDefault = "summary_text";export const listConversationItemsResponseDataItemContentItemTypeDefaultNine = "reasoning_text";export const listConversationItemsResponseDataItemTypeDefaultNine = "code_interpreter_call";export const listConversationItemsResponseDataItemOutputsItemTypeDefault = "logs";export const listConversationItemsResponseDataItemOutputsItemTypeDefaultOne = "image";export const listConversationItemsResponseDataItemActionTypeDefaultOnetwo = "exec";export const listConversationItemsResponseDataItemOutputItemTypeDefaultThree = "input_text";export const listConversationItemsResponseDataItemOutputItemTypeDefaultFour = "input_image";export const listConversationItemsResponseDataItemOutputItemTypeDefaultFive = "input_file";

export const listConversationItemsResponse = zod.object({
  "object": zod.any().describe('The type of object returned, must be `list`.'),
  "data": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message. Always set to `message`.'),
  "id": zod.string().describe('The unique ID of the message.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']),
  "role": zod.enum(['unknown', 'user', 'assistant', 'system', 'critic', 'discriminator', 'developer', 'tool']),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['text']).optional(),
  "text": zod.string()
}).describe('A text content.'),zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.'),zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is always set to `computer_screenshot`.'),
  "image_url": zod.string().describe('The URL of the screenshot image.').or(zod.null()),
  "file_id": zod.string().describe('The identifier of an uploaded file that contains the screenshot.').or(zod.null())
}).describe('A screenshot of a computer.'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('The content of the message')
}).describe('A message to or from the model.'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function tool call.\n')
})),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call output. Populated when this item\nis returned via API.\n'),
  "type": zod.enum(['function_call_output']).describe('The type of the function tool call output. Always `function_call_output`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "output": zod.string().describe('A string of the output of the function call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the function call.\n')).describe('The output from the function call generated by your code.\nCan be a string or an list of output content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('The output of a function tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function call tool output.\n')
})),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(listConversationItemsResponseDataItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.\n'),
  "id": zod.string().optional().describe('The ID of the computer tool call output.\n'),
  "call_id": zod.string().describe('The ID of the computer tool call that produced the output.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).optional().describe('The safety checks reported by the API that have been acknowledged by the\ndeveloper.\n'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('The output of a computer tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the computer call tool output.\n')
})),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n'),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n')]).describe('A single item within a conversation. The set of possible types are the same as the `output` type of a [Response object](https://platform.openai.com/docs/api-reference/responses/object#responses/object-output).')).describe('A list of conversation items.'),
  "has_more": zod.boolean().describe('Whether there are more items available.'),
  "first_id": zod.string().describe('The ID of the first item in the list.'),
  "last_id": zod.string().describe('The ID of the last item in the list.')
}).describe('A list of Conversation items.')

/**
 * Get a single item from a conversation with the given IDs.
 * @summary Retrieve an item
 */
export const getConversationItemParams = zod.object({
  "conversation_id": zod.string().describe('The ID of the conversation that contains the item.'),
  "item_id": zod.string().describe('The ID of the item to retrieve.')
})

export const getConversationItemQueryParams = zod.object({
  "include": zod.array(zod.enum(['file_search_call.results', 'web_search_call.results', 'web_search_call.action.sources', 'message.input_image.image_url', 'computer_call_output.output.image_url', 'code_interpreter_call.outputs', 'reasoning.encrypted_content', 'message.output_text.logprobs']).describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).')).optional().describe('Additional fields to include in the response. See the `include`\nparameter for [listing Conversation items above](https://platform.openai.com/docs/api-reference/conversations/list-items#conversations_list_items-include) for more information.\n')
})

export const getConversationItemResponseTypeDefault = "message";export const getConversationItemResponseContentItemTypeDefault = "input_text";export const getConversationItemResponseContentItemTypeDefaultOne = "output_text";export const getConversationItemResponseContentItemAnnotationsItemTypeDefault = "file_citation";export const getConversationItemResponseContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const getConversationItemResponseContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const getConversationItemResponseContentItemTypeDefaultTwo = "text";export const getConversationItemResponseContentItemTypeDefaultThree = "summary_text";export const getConversationItemResponseContentItemTypeDefaultFour = "reasoning_text";export const getConversationItemResponseContentItemTypeDefaultFive = "refusal";export const getConversationItemResponseContentItemTypeDefaultSix = "input_image";export const getConversationItemResponseContentItemTypeDefaultSeven = "computer_screenshot";export const getConversationItemResponseContentItemTypeDefaultEight = "input_file";export const getConversationItemResponseOutputItemTypeDefault = "input_text";export const getConversationItemResponseOutputItemTypeDefaultOne = "input_image";export const getConversationItemResponseOutputItemTypeDefaultTwo = "input_file";export const getConversationItemResponseResultsItemAttributesMaxThree = 512;
export const getConversationItemResponseTypeDefaultSix = "computer_call";export const getConversationItemResponseActionTypeDefaultThree = "click";export const getConversationItemResponseActionTypeDefaultFour = "double_click";export const getConversationItemResponseActionTypeDefaultFive = "drag";export const getConversationItemResponseActionTypeDefaultSix = "keypress";export const getConversationItemResponseActionTypeDefaultSeven = "move";export const getConversationItemResponseActionTypeDefaultEight = "screenshot";export const getConversationItemResponseActionTypeDefaultNine = "scroll";export const getConversationItemResponseActionTypeDefaultOnezero = "type";export const getConversationItemResponseActionTypeDefaultOneone = "wait";export const getConversationItemResponseTypeDefaultSeven = "computer_call_output";export const getConversationItemResponseOutputTypeDefault = "computer_screenshot";export const getConversationItemResponseSummaryItemTypeDefault = "summary_text";export const getConversationItemResponseContentItemTypeDefaultNine = "reasoning_text";export const getConversationItemResponseTypeDefaultNine = "code_interpreter_call";export const getConversationItemResponseOutputsItemTypeDefault = "logs";export const getConversationItemResponseOutputsItemTypeDefaultOne = "image";export const getConversationItemResponseActionTypeDefaultOnetwo = "exec";export const getConversationItemResponseOutputItemTypeDefaultThree = "input_text";export const getConversationItemResponseOutputItemTypeDefaultFour = "input_image";export const getConversationItemResponseOutputItemTypeDefaultFive = "input_file";

export const getConversationItemResponse = zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message. Always set to `message`.'),
  "id": zod.string().describe('The unique ID of the message.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']),
  "role": zod.enum(['unknown', 'user', 'assistant', 'system', 'critic', 'discriminator', 'developer', 'tool']),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['text']).optional(),
  "text": zod.string()
}).describe('A text content.'),zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.'),zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is always set to `computer_screenshot`.'),
  "image_url": zod.string().describe('The URL of the screenshot image.').or(zod.null()),
  "file_id": zod.string().describe('The identifier of an uploaded file that contains the screenshot.').or(zod.null())
}).describe('A screenshot of a computer.'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('The content of the message')
}).describe('A message to or from the model.'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function tool call.\n')
})),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call output. Populated when this item\nis returned via API.\n'),
  "type": zod.enum(['function_call_output']).describe('The type of the function tool call output. Always `function_call_output`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "output": zod.string().describe('A string of the output of the function call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the function call.\n')).describe('The output from the function call generated by your code.\nCan be a string or an list of output content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('The output of a function tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function call tool output.\n')
})),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(getConversationItemResponseResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.\n'),
  "id": zod.string().optional().describe('The ID of the computer tool call output.\n'),
  "call_id": zod.string().describe('The ID of the computer tool call that produced the output.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).optional().describe('The safety checks reported by the API that have been acknowledged by the\ndeveloper.\n'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('The output of a computer tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the computer call tool output.\n')
})),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n'),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n')]).describe('A single item within a conversation. The set of possible types are the same as the `output` type of a [Response object](https://platform.openai.com/docs/api-reference/responses/object#responses/object-output).')

/**
 * Delete an item from a conversation with the given IDs.
 * @summary Delete an item
 */
export const deleteConversationItemParams = zod.object({
  "conversation_id": zod.string().describe('The ID of the conversation that contains the item.'),
  "item_id": zod.string().describe('The ID of the item to delete.')
})

export const deleteConversationItemResponseObjectDefault = "conversation";

export const deleteConversationItemResponse = zod.object({
  "id": zod.string().describe('The unique ID of the conversation.'),
  "object": zod.enum(['conversation']).optional().describe('The object type, which is always `conversation`.'),
  "metadata": zod.any().describe('Set of 16 key-value pairs that can be attached to an object. This can be         useful for storing additional information about the object in a structured         format, and querying for objects via API or the dashboard.\n        Keys are strings with a maximum length of 64 characters. Values are strings         with a maximum length of 512 characters.'),
  "created_at": zod.number().describe('The time at which the conversation was created, measured in seconds since the Unix epoch.')
})

/**
 * Create a conversation.
 * @summary Create a conversation
 */
export const createConversationBodyItemsItemContentItemTypeDefault = "input_text";export const createConversationBodyItemsItemContentItemTypeDefaultOne = "input_image";export const createConversationBodyItemsItemContentItemTypeDefaultTwo = "input_file";export const createConversationBodyItemsItemContentItemTypeDefaultFour = "input_text";export const createConversationBodyItemsItemContentItemTypeDefaultFive = "input_image";export const createConversationBodyItemsItemContentItemTypeDefaultSix = "input_file";export const createConversationBodyItemsItemContentItemTypeDefaultEight = "output_text";export const createConversationBodyItemsItemContentItemAnnotationsItemTypeDefault = "file_citation";export const createConversationBodyItemsItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const createConversationBodyItemsItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const createConversationBodyItemsItemContentItemTypeDefaultNine = "refusal";export const createConversationBodyItemsItemResultsItemAttributesMaxThree = 512;
export const createConversationBodyItemsItemTypeDefaultFour = "computer_call";export const createConversationBodyItemsItemActionTypeDefault = "click";export const createConversationBodyItemsItemActionTypeDefaultOne = "double_click";export const createConversationBodyItemsItemActionTypeDefaultTwo = "drag";export const createConversationBodyItemsItemActionTypeDefaultThree = "keypress";export const createConversationBodyItemsItemActionTypeDefaultFour = "move";export const createConversationBodyItemsItemActionTypeDefaultFive = "screenshot";export const createConversationBodyItemsItemActionTypeDefaultSix = "scroll";export const createConversationBodyItemsItemActionTypeDefaultSeven = "type";export const createConversationBodyItemsItemActionTypeDefaultEight = "wait";export const createConversationBodyItemsItemCallIdMaxOne = 64;
export const createConversationBodyItemsItemTypeDefaultFive = "computer_call_output";export const createConversationBodyItemsItemOutputTypeDefault = "computer_screenshot";export const createConversationBodyItemsItemCallIdMaxThree = 64;
export const createConversationBodyItemsItemTypeDefaultEight = "function_call_output";export const createConversationBodyItemsItemOutputMaxTwo = 10485760;
export const createConversationBodyItemsItemOutputItemTypeDefault = "input_text";export const createConversationBodyItemsItemOutputItemTextMax = 10485760;
export const createConversationBodyItemsItemOutputItemTypeDefaultOne = "input_image";export const createConversationBodyItemsItemOutputItemImageUrlMaxOne = 20971520;
export const createConversationBodyItemsItemOutputItemTypeDefaultTwo = "input_file";export const createConversationBodyItemsItemOutputItemFileDataMaxOne = 33554432;
export const createConversationBodyItemsItemSummaryItemTypeDefault = "summary_text";export const createConversationBodyItemsItemContentItemTypeDefaultOnezero = "reasoning_text";export const createConversationBodyItemsItemTypeDefaultOneone = "code_interpreter_call";export const createConversationBodyItemsItemOutputsItemTypeDefault = "logs";export const createConversationBodyItemsItemOutputsItemTypeDefaultOne = "image";export const createConversationBodyItemsItemActionTypeDefaultOnetwo = "exec";export const createConversationBodyItemsItemOutputItemTypeDefaultThree = "input_text";export const createConversationBodyItemsItemOutputItemTypeDefaultFour = "input_image";export const createConversationBodyItemsItemOutputItemTypeDefaultFive = "input_file";export const createConversationBodyItemsItemTypeDefaultTwoone = "item_reference";export const createConversationBodyItemsMaxOne = 20;


export const createConversationBody = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).or(zod.null()).optional(),
  "items": zod.array(zod.discriminatedUnion('type', [zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'),zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always set to `message`.\n'),
  "role": zod.enum(['user', 'system', 'developer']).describe('The role of the message input. One of `user`, `system`, or `developer`.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(createConversationBodyItemsItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "id": zod.string().describe('The ID of the computer tool call output.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createConversationBodyItemsItemCallIdMaxOne).describe('The ID of the computer tool call that produced the output.'),
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The safety checks reported by the API that have been acknowledged by the developer.').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a computer tool call.'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the function tool call output. Populated when this item is returned via API.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createConversationBodyItemsItemCallIdMaxThree).describe('The unique ID of the function tool call generated by the model.'),
  "type": zod.enum(['function_call_output']).optional().describe('The type of the function tool call output. Always `function_call_output`.'),
  "output": zod.string().max(createConversationBodyItemsItemOutputMaxTwo).describe('A JSON string of the output of the function tool call.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().max(createConversationBodyItemsItemOutputItemTextMax).describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().max(createConversationBodyItemsItemOutputItemImageUrlMaxOne).describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto']).or(zod.null()).optional()
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision)'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().describe('The name of the file to be sent to the model.').or(zod.null()).optional(),
  "file_data": zod.string().max(createConversationBodyItemsItemOutputItemFileDataMaxOne).describe('The base64-encoded data of the file to be sent to the model.').or(zod.null()).optional(),
  "file_url": zod.string().describe('The URL of the file to be sent to the model.').or(zod.null()).optional()
}).describe('A file input to the model.')]))).describe('Text, image, or file output of the function tool call.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a function tool call.'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n').or(zod.null()).optional(),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')]).describe('Content item used to generate a response.\n'),zod.object({
  "type": zod.enum(['item_reference']).optional().describe('The type of item to reference. Always `item_reference`.').or(zod.null()).optional(),
  "id": zod.string().describe('The ID of the item to reference.')
}).describe('An internal identifier for an item to reference.')])).max(createConversationBodyItemsMaxOne).describe('Initial items to include in the conversation context. You may add up to 20 items at a time.').or(zod.null()).optional()
})

export const createConversationResponseObjectDefault = "conversation";

export const createConversationResponse = zod.object({
  "id": zod.string().describe('The unique ID of the conversation.'),
  "object": zod.enum(['conversation']).optional().describe('The object type, which is always `conversation`.'),
  "metadata": zod.any().describe('Set of 16 key-value pairs that can be attached to an object. This can be         useful for storing additional information about the object in a structured         format, and querying for objects via API or the dashboard.\n        Keys are strings with a maximum length of 64 characters. Values are strings         with a maximum length of 512 characters.'),
  "created_at": zod.number().describe('The time at which the conversation was created, measured in seconds since the Unix epoch.')
})

/**
 * Get a conversation
 * @summary Retrieve a conversation
 */
export const getConversationParams = zod.object({
  "conversation_id": zod.string().describe('The ID of the conversation to retrieve.')
})

export const getConversationResponseObjectDefault = "conversation";

export const getConversationResponse = zod.object({
  "id": zod.string().describe('The unique ID of the conversation.'),
  "object": zod.enum(['conversation']).optional().describe('The object type, which is always `conversation`.'),
  "metadata": zod.any().describe('Set of 16 key-value pairs that can be attached to an object. This can be         useful for storing additional information about the object in a structured         format, and querying for objects via API or the dashboard.\n        Keys are strings with a maximum length of 64 characters. Values are strings         with a maximum length of 512 characters.'),
  "created_at": zod.number().describe('The time at which the conversation was created, measured in seconds since the Unix epoch.')
})

/**
 * Delete a conversation. Items in the conversation will not be deleted.
 * @summary Delete a conversation
 */
export const deleteConversationParams = zod.object({
  "conversation_id": zod.string().describe('The ID of the conversation to delete.')
})

export const deleteConversationResponseObjectDefault = "conversation.deleted";

export const deleteConversationResponse = zod.object({
  "object": zod.enum(['conversation.deleted']).optional(),
  "deleted": zod.boolean(),
  "id": zod.string()
})

/**
 * Update a conversation
 * @summary Update a conversation
 */
export const updateConversationParams = zod.object({
  "conversation_id": zod.string().describe('The ID of the conversation to update.')
})

export const updateConversationBody = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
})

export const updateConversationResponseObjectDefault = "conversation";

export const updateConversationResponse = zod.object({
  "id": zod.string().describe('The unique ID of the conversation.'),
  "object": zod.enum(['conversation']).optional().describe('The object type, which is always `conversation`.'),
  "metadata": zod.any().describe('Set of 16 key-value pairs that can be attached to an object. This can be         useful for storing additional information about the object in a structured         format, and querying for objects via API or the dashboard.\n        Keys are strings with a maximum length of 64 characters. Values are strings         with a maximum length of 512 characters.'),
  "created_at": zod.number().describe('The time at which the conversation was created, measured in seconds since the Unix epoch.')
})

