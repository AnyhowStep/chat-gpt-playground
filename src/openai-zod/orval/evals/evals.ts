/**
 * Generated by orval v7.7.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import {
  z as zod
} from 'zod';


/**
 * List evaluations for a project.

 * @summary List evals
 */
export const listEvalsQueryLimitDefault = 20;export const listEvalsQueryOrderDefault = "asc";export const listEvalsQueryOrderByDefault = "created_at";

export const listEvalsQueryParams = zod.object({
  "after": zod.string().optional().describe('Identifier for the last eval from the previous pagination request.'),
  "limit": zod.number().optional().describe('Number of evals to retrieve.'),
  "order": zod.enum(['asc', 'desc']).optional().describe('Sort order for evals by timestamp. Use `asc` for ascending order or `desc` for descending order.'),
  "order_by": zod.enum(['created_at', 'updated_at']).optional().describe('Evals can be ordered by creation time or last updated time. Use\n`created_at` for creation time or `updated_at` for last updated time.\n')
})

export const listEvalsResponseObjectDefault = "list";export const listEvalsResponseDataItemObjectDefault = "eval";export const listEvalsResponseDataItemDataSourceConfigTypeDefault = "custom";export const listEvalsResponseDataItemDataSourceConfigTypeDefaultOne = "logs";export const listEvalsResponseDataItemDataSourceConfigTypeDefaultTwo = "stored_completions";export const listEvalsResponseDataItemTestingCriteriaItemInputItemContentTypeDefault = "input_text";export const listEvalsResponseDataItemTestingCriteriaItemTypeDefaultTwo = "text_similarity";export const listEvalsResponseDataItemTestingCriteriaItemSamplingParamsTopPDefaultOne = 1;export const listEvalsResponseDataItemTestingCriteriaItemSamplingParamsReasoningEffortDefaultOne = "medium";export const listEvalsResponseDataItemTestingCriteriaItemInputItemContentTypeDefaultFour = "input_text";

export const listEvalsResponse = zod.object({
  "object": zod.enum(['list']).optional().describe('The type of this object. It is always set to \"list\".\n'),
  "data": zod.array(zod.object({
  "object": zod.enum(['eval']).optional().describe('The object type.'),
  "id": zod.string().describe('Unique identifier for the evaluation.'),
  "name": zod.string().describe('The name of the evaluation.'),
  "data_source_config": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of data source. Always `custom`.'),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('A CustomDataSourceConfig which specifies the schema of your `item` and optionally `sample` namespaces.\nThe response schema defines the shape of the data that will be:\n- Used to define your testing criteria and\n- What data is required when creating a run\n'),zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of data source. Always `logs`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('A LogsDataSourceConfig which specifies the metadata property of your logs query.\nThis is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\nThe schema returned by this data source config is used to defined what variables are available in your evals.\n`item` and `sample` are both defined when using this data source config.\n'),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of data source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('Deprecated in favor of LogsDataSourceConfig.\n')]).describe('Configuration of data sources used in runs of the evaluation.'),
  "testing_criteria": zod.array(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n').or(zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n')).or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n').and(zod.object({
  "pass_threshold": zod.number().describe('The threshold for the score.')
}))).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
}))).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
})))).describe('A list of testing criteria.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the eval was created.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('An Eval object with a data source config and testing criteria.\nAn Eval represents a task to be done for your LLM integration.\nLike:\n - Improve the quality of my chatbot\n - See how well my chatbot handles customer support\n - Check if o4-mini is better at my usecase than gpt-4o\n')).describe('An array of eval objects.\n'),
  "first_id": zod.string().describe('The identifier of the first eval in the data array.'),
  "last_id": zod.string().describe('The identifier of the last eval in the data array.'),
  "has_more": zod.boolean().describe('Indicates whether there are more evals available.')
}).describe('An object representing a list of evals.\n')

/**
 * Create the structure of an evaluation that can be used to test a model's performance.
An evaluation is a set of testing criteria and the config for a data source, which dictates the schema of the data used in the evaluation. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources.
For more information, see the [Evals guide](https://platform.openai.com/docs/guides/evals).

 * @summary Create eval
 */
export const createEvalBodyDataSourceConfigTypeDefault = "custom";export const createEvalBodyDataSourceConfigIncludeSampleSchemaDefault = false;export const createEvalBodyDataSourceConfigTypeDefaultOne = "logs";export const createEvalBodyDataSourceConfigTypeDefaultTwo = "stored_completions";export const createEvalBodyTestingCriteriaItemInputItemContentTypeDefault = "input_text";export const createEvalBodyTestingCriteriaItemTypeDefaultTwo = "text_similarity";export const createEvalBodyTestingCriteriaItemSamplingParamsTopPDefaultOne = 1;export const createEvalBodyTestingCriteriaItemSamplingParamsReasoningEffortDefaultOne = "medium";export const createEvalBodyTestingCriteriaItemInputItemContentTypeDefaultFour = "input_text";

export const createEvalBody = zod.object({
  "name": zod.string().optional().describe('The name of the evaluation.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "data_source_config": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of data source. Always `custom`.'),
  "item_schema": zod.record(zod.string(), zod.any()).describe('The json schema for each row in the data source.'),
  "include_sample_schema": zod.boolean().optional().describe('Whether the eval should expect you to populate the sample namespace (ie, by generating responses off of your data source)')
}).describe('A CustomDataSourceConfig object that defines the schema for the data source used for the evaluation runs.\nThis schema is used to define the shape of the data that will be:\n- Used to define your testing criteria and\n- What data is required when creating a run\n'),zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of data source. Always `logs`.'),
  "metadata": zod.record(zod.string(), zod.any()).optional().describe('Metadata filters for the logs data source.')
}).describe('A data source config which specifies the metadata property of your logs query.\nThis is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\n'),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of data source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.any()).optional().describe('Metadata filters for the stored completions data source.')
}).describe('Deprecated in favor of LogsDataSourceConfig.\n')]).describe('The configuration for the data source used for the evaluation runs. Dictates the schema of the data used in the evaluation.'),
  "testing_criteria": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.string().describe('The role of the message (e.g. \"system\", \"assistant\", \"user\").'),
  "content": zod.string().describe('The content of the message.')
}).or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('A chat message that makes up the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.'),
  "labels": zod.array(zod.string()).describe('The labels to classify to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n'),zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n'),zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n').and(zod.object({
  "pass_threshold": zod.number().describe('The threshold for the score.')
})),zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
})),zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
}))])).describe('A list of graders for all eval runs in this group. Graders can reference variables in the data source using double curly braces notation, like `{{item.variable_name}}`. To reference the model\'s output, use the `sample` namespace (ie, `{{sample.output_text}}`).')
})

/**
 * Get an evaluation by ID.

 * @summary Get an eval
 */
export const getEvalParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to retrieve.')
})

export const getEvalResponseObjectDefault = "eval";export const getEvalResponseDataSourceConfigTypeDefault = "custom";export const getEvalResponseDataSourceConfigTypeDefaultOne = "logs";export const getEvalResponseDataSourceConfigTypeDefaultTwo = "stored_completions";export const getEvalResponseTestingCriteriaItemInputItemContentTypeDefault = "input_text";export const getEvalResponseTestingCriteriaItemTypeDefaultTwo = "text_similarity";export const getEvalResponseTestingCriteriaItemSamplingParamsTopPDefaultOne = 1;export const getEvalResponseTestingCriteriaItemSamplingParamsReasoningEffortDefaultOne = "medium";export const getEvalResponseTestingCriteriaItemInputItemContentTypeDefaultFour = "input_text";

export const getEvalResponse = zod.object({
  "object": zod.enum(['eval']).optional().describe('The object type.'),
  "id": zod.string().describe('Unique identifier for the evaluation.'),
  "name": zod.string().describe('The name of the evaluation.'),
  "data_source_config": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of data source. Always `custom`.'),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('A CustomDataSourceConfig which specifies the schema of your `item` and optionally `sample` namespaces.\nThe response schema defines the shape of the data that will be:\n- Used to define your testing criteria and\n- What data is required when creating a run\n'),zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of data source. Always `logs`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('A LogsDataSourceConfig which specifies the metadata property of your logs query.\nThis is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\nThe schema returned by this data source config is used to defined what variables are available in your evals.\n`item` and `sample` are both defined when using this data source config.\n'),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of data source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('Deprecated in favor of LogsDataSourceConfig.\n')]).describe('Configuration of data sources used in runs of the evaluation.'),
  "testing_criteria": zod.array(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n').or(zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n')).or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n').and(zod.object({
  "pass_threshold": zod.number().describe('The threshold for the score.')
}))).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
}))).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
})))).describe('A list of testing criteria.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the eval was created.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('An Eval object with a data source config and testing criteria.\nAn Eval represents a task to be done for your LLM integration.\nLike:\n - Improve the quality of my chatbot\n - See how well my chatbot handles customer support\n - Check if o4-mini is better at my usecase than gpt-4o\n')

/**
 * Update certain properties of an evaluation.

 * @summary Update an eval
 */
export const updateEvalParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to update.')
})

export const updateEvalBody = zod.object({
  "name": zod.string().optional().describe('Rename the evaluation.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

export const updateEvalResponseObjectDefault = "eval";export const updateEvalResponseDataSourceConfigTypeDefault = "custom";export const updateEvalResponseDataSourceConfigTypeDefaultOne = "logs";export const updateEvalResponseDataSourceConfigTypeDefaultTwo = "stored_completions";export const updateEvalResponseTestingCriteriaItemInputItemContentTypeDefault = "input_text";export const updateEvalResponseTestingCriteriaItemTypeDefaultTwo = "text_similarity";export const updateEvalResponseTestingCriteriaItemSamplingParamsTopPDefaultOne = 1;export const updateEvalResponseTestingCriteriaItemSamplingParamsReasoningEffortDefaultOne = "medium";export const updateEvalResponseTestingCriteriaItemInputItemContentTypeDefaultFour = "input_text";

export const updateEvalResponse = zod.object({
  "object": zod.enum(['eval']).optional().describe('The object type.'),
  "id": zod.string().describe('Unique identifier for the evaluation.'),
  "name": zod.string().describe('The name of the evaluation.'),
  "data_source_config": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of data source. Always `custom`.'),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('A CustomDataSourceConfig which specifies the schema of your `item` and optionally `sample` namespaces.\nThe response schema defines the shape of the data that will be:\n- Used to define your testing criteria and\n- What data is required when creating a run\n'),zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of data source. Always `logs`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('A LogsDataSourceConfig which specifies the metadata property of your logs query.\nThis is usually metadata like `usecase=chatbot` or `prompt-version=v2`, etc.\nThe schema returned by this data source config is used to defined what variables are available in your evals.\n`item` and `sample` are both defined when using this data source config.\n'),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of data source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "schema": zod.record(zod.string(), zod.any()).describe('The json schema for the run data source items.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n')
}).describe('Deprecated in favor of LogsDataSourceConfig.\n')]).describe('Configuration of data sources used in runs of the evaluation.'),
  "testing_criteria": zod.array(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n').or(zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n')).or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n').and(zod.object({
  "pass_threshold": zod.number().describe('The threshold for the score.')
}))).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
}))).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n').and(zod.object({
  "pass_threshold": zod.number().optional().describe('The threshold for the score.')
})))).describe('A list of testing criteria.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the eval was created.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('An Eval object with a data source config and testing criteria.\nAn Eval represents a task to be done for your LLM integration.\nLike:\n - Improve the quality of my chatbot\n - See how well my chatbot handles customer support\n - Check if o4-mini is better at my usecase than gpt-4o\n')

/**
 * Delete an evaluation.

 * @summary Delete an eval
 */
export const deleteEvalParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to delete.')
})

export const deleteEvalResponse = zod.object({
  "object": zod.string(),
  "deleted": zod.boolean(),
  "eval_id": zod.string()
})

/**
 * Get a list of runs for an evaluation.

 * @summary Get eval runs
 */
export const getEvalRunsParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to retrieve runs for.')
})

export const getEvalRunsQueryLimitDefault = 20;export const getEvalRunsQueryOrderDefault = "asc";

export const getEvalRunsQueryParams = zod.object({
  "after": zod.string().optional().describe('Identifier for the last run from the previous pagination request.'),
  "limit": zod.number().optional().describe('Number of runs to retrieve.'),
  "order": zod.enum(['asc', 'desc']).optional().describe('Sort order for runs by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.'),
  "status": zod.enum(['queued', 'in_progress', 'completed', 'canceled', 'failed']).optional().describe('Filter runs by status. One of `queued` | `in_progress` | `failed` | `completed` | `canceled`.')
})

export const getEvalRunsResponseObjectDefault = "list";export const getEvalRunsResponseDataItemObjectDefault = "eval.run";export const getEvalRunsResponseDataItemDataSourceTypeDefault = "jsonl";export const getEvalRunsResponseDataItemDataSourceSourceTypeDefault = "file_content";export const getEvalRunsResponseDataItemDataSourceSourceTypeDefaultOne = "file_id";export const getEvalRunsResponseDataItemDataSourceTypeDefaultOne = "completions";export const getEvalRunsResponseDataItemDataSourceInputMessagesTemplateItemContentItemTypeDefault = "input_text";export const getEvalRunsResponseDataItemDataSourceInputMessagesTemplateItemContentItemTypeDefaultOne = "input_image";export const getEvalRunsResponseDataItemDataSourceInputMessagesTemplateItemContentItemTypeDefaultTwo = "input_file";export const getEvalRunsResponseDataItemDataSourceInputMessagesTemplateItemContentTypeDefault = "input_text";export const getEvalRunsResponseDataItemDataSourceSamplingParamsReasoningEffortDefaultOne = "medium";export const getEvalRunsResponseDataItemDataSourceSamplingParamsTemperatureDefault = 1;export const getEvalRunsResponseDataItemDataSourceSamplingParamsTopPDefault = 1;export const getEvalRunsResponseDataItemDataSourceSamplingParamsSeedDefault = 42;export const getEvalRunsResponseDataItemDataSourceSamplingParamsResponseFormatJsonSchemaStrictDefaultOne = false;export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemFunctionStrictDefaultOne = false;export const getEvalRunsResponseDataItemDataSourceSourceTypeDefaultTwo = "file_content";export const getEvalRunsResponseDataItemDataSourceSourceTypeDefaultThree = "file_id";export const getEvalRunsResponseDataItemDataSourceSourceTypeDefaultFour = "stored_completions";export const getEvalRunsResponseDataItemDataSourceTypeDefaultTwo = "responses";export const getEvalRunsResponseDataItemDataSourceInputMessagesTemplateItemContentTypeDefaultFour = "input_text";export const getEvalRunsResponseDataItemDataSourceSamplingParamsReasoningEffortDefaultFour = "medium";export const getEvalRunsResponseDataItemDataSourceSamplingParamsTemperatureDefaultOne = 1;export const getEvalRunsResponseDataItemDataSourceSamplingParamsTopPDefaultOne = 1;export const getEvalRunsResponseDataItemDataSourceSamplingParamsSeedDefaultOne = 42;export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemTypeDefaultOne = "function";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemTypeDefaultTwo = "file_search";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemFiltersTypeDefault = "eq";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemFiltersFiltersItemTypeDefault = "eq";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemTypeDefaultThree = "computer_use_preview";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemTypeDefaultFour = "web_search";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemFiltersAllowedDomainsDefaultOne = [];export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemUserLocationTypeDefault = "approximate";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemSearchContextSizeDefault = "medium";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemRequireApprovalDefaultOne = "always";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemContainerTypeDefault = "auto";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemContainerFileIdsMax = 50;
export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemModelDefault = "gpt-image-1";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemQualityDefault = "auto";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemSizeDefault = "auto";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemOutputFormatDefault = "png";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemOutputCompressionDefault = 100;
export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemOutputCompressionMin = 0;

export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemOutputCompressionMax = 100;
export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemModerationDefault = "auto";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemBackgroundDefault = "auto";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemPartialImagesDefault = 0;
export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemPartialImagesMin = 0;

export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemPartialImagesMax = 3;
export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemTypeDefaultEight = "local_shell";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemTypeDefaultNine = "custom";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemFormatTypeDefault = "text";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemFormatTypeDefaultOne = "grammar";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemTypeDefaultOnezero = "web_search_preview";export const getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemUserLocationTypeDefaultOne = "approximate";export const getEvalRunsResponseDataItemDataSourceSamplingParamsTextFormatStrictDefaultOne = false;export const getEvalRunsResponseDataItemDataSourceSourceTypeDefaultFive = "file_content";export const getEvalRunsResponseDataItemDataSourceSourceTypeDefaultSix = "file_id";export const getEvalRunsResponseDataItemDataSourceSourceCreatedAfterMinFour = 0;
export const getEvalRunsResponseDataItemDataSourceSourceCreatedBeforeMinFour = 0;
export const getEvalRunsResponseDataItemDataSourceSourceReasoningEffortDefaultTwo = "medium";

export const getEvalRunsResponse = zod.object({
  "object": zod.enum(['list']).optional().describe('The type of this object. It is always set to \"list\".\n'),
  "data": zod.array(zod.object({
  "object": zod.enum(['eval.run']).optional().describe('The type of the object. Always \"eval.run\".'),
  "id": zod.string().describe('Unique identifier for the evaluation run.'),
  "eval_id": zod.string().describe('The identifier of the associated evaluation.'),
  "status": zod.string().describe('The status of the evaluation run.'),
  "model": zod.string().describe('The model that is evaluated, if applicable.'),
  "name": zod.string().describe('The name of the evaluation run.'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) when the evaluation run was created.'),
  "report_url": zod.string().describe('The URL to the rendered evaluation run report on the UI dashboard.'),
  "result_counts": zod.object({
  "total": zod.number().describe('Total number of executed output items.'),
  "errored": zod.number().describe('Number of output items that resulted in an error.'),
  "failed": zod.number().describe('Number of output items that failed to pass the evaluation.'),
  "passed": zod.number().describe('Number of output items that passed the evaluation.')
}).describe('Counters summarizing the outcomes of the evaluation run.'),
  "per_model_usage": zod.array(zod.object({
  "model_name": zod.string().describe('The name of the model.'),
  "invocation_count": zod.number().describe('The number of invocations.'),
  "prompt_tokens": zod.number().describe('The number of prompt tokens used.'),
  "completion_tokens": zod.number().describe('The number of completion tokens generated.'),
  "total_tokens": zod.number().describe('The total number of tokens used.'),
  "cached_tokens": zod.number().describe('The number of tokens retrieved from cache.')
})).describe('Usage statistics for each model during the evaluation run.'),
  "per_testing_criteria_results": zod.array(zod.object({
  "testing_criteria": zod.string().describe('A description of the testing criteria.'),
  "passed": zod.number().describe('Number of tests passed for this criteria.'),
  "failed": zod.number().describe('Number of tests failed for this criteria.')
})).describe('Results per testing criteria applied during the evaluation run.'),
  "data_source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['jsonl']).optional().describe('The type of data source. Always `jsonl`.'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
})]).describe('Determines what populates the `item` namespace in the data source.')
}).describe('A JsonlRunDataSource object with that specifies a JSONL file that matches the eval\n'),zod.object({
  "type": zod.enum(['completions']).optional().describe('The type of run data source. Always `completions`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n').or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.input_trajectory\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "response_format": zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n').or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).optional().describe('An object specifying the format that the model must output.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables\nStructured Outputs which ensures the model will match your supplied JSON\nschema. Learn more in the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['function']).describe('The type of the tool. Currently, only `function` is supported.'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
}).describe('A function tool that can be used to generate a response.\n')).optional().describe('A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "model": zod.string().describe('An optional model to filter by (e.g., \'gpt-4o\').').or(zod.null()).optional(),
  "created_after": zod.number().describe('An optional Unix timestamp to filter items created after this time.').or(zod.null()).optional(),
  "created_before": zod.number().describe('An optional Unix timestamp to filter items created before this time.').or(zod.null()).optional(),
  "limit": zod.number().describe('An optional maximum number of items to return.').or(zod.null()).optional()
}).describe('A StoredCompletionsRunDataSource configuration describing a set of filters\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A CompletionsRunDataSource object describing a model sampling configuration.\n'),zod.object({
  "type": zod.enum(['responses']).optional().describe('The type of run data source. Always `responses`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.string().describe('The role of the message (e.g. \"system\", \"assistant\", \"user\").'),
  "content": zod.string().describe('The content of the message.')
}).or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.name\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemOutputCompressionMin).max(getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemPartialImagesMin).max(getEvalRunsResponseDataItemDataSourceSamplingParamsToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling).\n'),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n')
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['responses']).describe('The type of run data source. Always `responses`.'),
  "metadata": zod.object({

}).describe('Metadata filter for the responses. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "model": zod.string().describe('The name of the model to find responses for. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "instructions_search": zod.string().describe('Optional string to search the \'instructions\' field. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_after": zod.number().min(getEvalRunsResponseDataItemDataSourceSourceCreatedAfterMinFour).describe('Only include items created after this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_before": zod.number().min(getEvalRunsResponseDataItemDataSourceSourceCreatedBeforeMinFour).describe('Only include items created before this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).or(zod.null()).optional(),
  "temperature": zod.number().describe('Sampling temperature. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "top_p": zod.number().describe('Nucleus sampling parameter. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "users": zod.array(zod.string()).describe('List of user identifiers. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "tools": zod.array(zod.string()).describe('List of tool names. This is a query parameter used to select responses.').or(zod.null()).optional()
}).describe('A EvalResponsesSource object describing a run data source configuration.\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A ResponsesRunDataSource object describing a model sampling configuration.\n')]).describe('Information about the run\'s data source.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "error": zod.object({
  "code": zod.string().describe('The error code.'),
  "message": zod.string().describe('The error message.')
}).describe('An object representing an error response from the Eval API.\n')
}).describe('A schema representing an evaluation run.\n')).describe('An array of eval run objects.\n'),
  "first_id": zod.string().describe('The identifier of the first eval run in the data array.'),
  "last_id": zod.string().describe('The identifier of the last eval run in the data array.'),
  "has_more": zod.boolean().describe('Indicates whether there are more evals available.')
}).describe('An object representing a list of runs for an evaluation.\n')

/**
 * Kicks off a new run for a given evaluation, specifying the data source, and what model configuration to use to test. The datasource will be validated against the schema specified in the config of the evaluation.

 * @summary Create eval run
 */
export const createEvalRunParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to create a run for.')
})

export const createEvalRunBodyDataSourceTypeDefault = "jsonl";export const createEvalRunBodyDataSourceSourceTypeDefault = "file_content";export const createEvalRunBodyDataSourceSourceTypeDefaultOne = "file_id";export const createEvalRunBodyDataSourceTypeDefaultOne = "completions";export const createEvalRunBodyDataSourceInputMessagesTemplateItemContentItemTypeDefault = "input_text";export const createEvalRunBodyDataSourceInputMessagesTemplateItemContentItemTypeDefaultOne = "input_image";export const createEvalRunBodyDataSourceInputMessagesTemplateItemContentItemTypeDefaultTwo = "input_file";export const createEvalRunBodyDataSourceInputMessagesTemplateItemContentTypeDefault = "input_text";export const createEvalRunBodyDataSourceSamplingParamsReasoningEffortDefaultOne = "medium";export const createEvalRunBodyDataSourceSamplingParamsTemperatureDefault = 1;export const createEvalRunBodyDataSourceSamplingParamsTopPDefault = 1;export const createEvalRunBodyDataSourceSamplingParamsSeedDefault = 42;export const createEvalRunBodyDataSourceSamplingParamsResponseFormatJsonSchemaStrictDefaultOne = false;export const createEvalRunBodyDataSourceSamplingParamsToolsItemFunctionStrictDefaultOne = false;export const createEvalRunBodyDataSourceSourceTypeDefaultTwo = "file_content";export const createEvalRunBodyDataSourceSourceTypeDefaultThree = "file_id";export const createEvalRunBodyDataSourceSourceTypeDefaultFour = "stored_completions";export const createEvalRunBodyDataSourceTypeDefaultTwo = "responses";export const createEvalRunBodyDataSourceInputMessagesTemplateItemContentTypeDefaultFour = "input_text";export const createEvalRunBodyDataSourceSamplingParamsReasoningEffortDefaultFour = "medium";export const createEvalRunBodyDataSourceSamplingParamsTemperatureDefaultOne = 1;export const createEvalRunBodyDataSourceSamplingParamsTopPDefaultOne = 1;export const createEvalRunBodyDataSourceSamplingParamsSeedDefaultOne = 42;export const createEvalRunBodyDataSourceSamplingParamsToolsItemTypeDefaultOne = "function";export const createEvalRunBodyDataSourceSamplingParamsToolsItemTypeDefaultTwo = "file_search";export const createEvalRunBodyDataSourceSamplingParamsToolsItemFiltersTypeDefault = "eq";export const createEvalRunBodyDataSourceSamplingParamsToolsItemFiltersFiltersItemTypeDefault = "eq";export const createEvalRunBodyDataSourceSamplingParamsToolsItemTypeDefaultThree = "computer_use_preview";export const createEvalRunBodyDataSourceSamplingParamsToolsItemTypeDefaultFour = "web_search";export const createEvalRunBodyDataSourceSamplingParamsToolsItemFiltersAllowedDomainsDefaultOne = [];export const createEvalRunBodyDataSourceSamplingParamsToolsItemUserLocationTypeDefault = "approximate";export const createEvalRunBodyDataSourceSamplingParamsToolsItemSearchContextSizeDefault = "medium";export const createEvalRunBodyDataSourceSamplingParamsToolsItemRequireApprovalDefaultOne = "always";export const createEvalRunBodyDataSourceSamplingParamsToolsItemContainerTypeDefault = "auto";export const createEvalRunBodyDataSourceSamplingParamsToolsItemContainerFileIdsMax = 50;
export const createEvalRunBodyDataSourceSamplingParamsToolsItemModelDefault = "gpt-image-1";export const createEvalRunBodyDataSourceSamplingParamsToolsItemQualityDefault = "auto";export const createEvalRunBodyDataSourceSamplingParamsToolsItemSizeDefault = "auto";export const createEvalRunBodyDataSourceSamplingParamsToolsItemOutputFormatDefault = "png";export const createEvalRunBodyDataSourceSamplingParamsToolsItemOutputCompressionDefault = 100;
export const createEvalRunBodyDataSourceSamplingParamsToolsItemOutputCompressionMin = 0;

export const createEvalRunBodyDataSourceSamplingParamsToolsItemOutputCompressionMax = 100;
export const createEvalRunBodyDataSourceSamplingParamsToolsItemModerationDefault = "auto";export const createEvalRunBodyDataSourceSamplingParamsToolsItemBackgroundDefault = "auto";export const createEvalRunBodyDataSourceSamplingParamsToolsItemPartialImagesDefault = 0;
export const createEvalRunBodyDataSourceSamplingParamsToolsItemPartialImagesMin = 0;

export const createEvalRunBodyDataSourceSamplingParamsToolsItemPartialImagesMax = 3;
export const createEvalRunBodyDataSourceSamplingParamsToolsItemTypeDefaultEight = "local_shell";export const createEvalRunBodyDataSourceSamplingParamsToolsItemTypeDefaultNine = "custom";export const createEvalRunBodyDataSourceSamplingParamsToolsItemFormatTypeDefault = "text";export const createEvalRunBodyDataSourceSamplingParamsToolsItemFormatTypeDefaultOne = "grammar";export const createEvalRunBodyDataSourceSamplingParamsToolsItemTypeDefaultOnezero = "web_search_preview";export const createEvalRunBodyDataSourceSamplingParamsToolsItemUserLocationTypeDefaultOne = "approximate";export const createEvalRunBodyDataSourceSamplingParamsTextFormatStrictDefaultOne = false;export const createEvalRunBodyDataSourceSourceTypeDefaultFive = "file_content";export const createEvalRunBodyDataSourceSourceTypeDefaultSix = "file_id";export const createEvalRunBodyDataSourceSourceCreatedAfterMinFour = 0;
export const createEvalRunBodyDataSourceSourceCreatedBeforeMinFour = 0;
export const createEvalRunBodyDataSourceSourceReasoningEffortDefaultTwo = "medium";

export const createEvalRunBody = zod.object({
  "name": zod.string().optional().describe('The name of the run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "data_source": zod.object({
  "type": zod.enum(['jsonl']).optional().describe('The type of data source. Always `jsonl`.'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
})]).describe('Determines what populates the `item` namespace in the data source.')
}).describe('A JsonlRunDataSource object with that specifies a JSONL file that matches the eval\n').or(zod.object({
  "type": zod.enum(['completions']).optional().describe('The type of run data source. Always `completions`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n').or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.input_trajectory\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "response_format": zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n').or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).optional().describe('An object specifying the format that the model must output.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables\nStructured Outputs which ensures the model will match your supplied JSON\nschema. Learn more in the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['function']).describe('The type of the tool. Currently, only `function` is supported.'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
}).describe('A function tool that can be used to generate a response.\n')).optional().describe('A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "model": zod.string().describe('An optional model to filter by (e.g., \'gpt-4o\').').or(zod.null()).optional(),
  "created_after": zod.number().describe('An optional Unix timestamp to filter items created after this time.').or(zod.null()).optional(),
  "created_before": zod.number().describe('An optional Unix timestamp to filter items created before this time.').or(zod.null()).optional(),
  "limit": zod.number().describe('An optional maximum number of items to return.').or(zod.null()).optional()
}).describe('A StoredCompletionsRunDataSource configuration describing a set of filters\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A CompletionsRunDataSource object describing a model sampling configuration.\n')).or(zod.object({
  "type": zod.enum(['responses']).optional().describe('The type of run data source. Always `responses`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.string().describe('The role of the message (e.g. \"system\", \"assistant\", \"user\").'),
  "content": zod.string().describe('The content of the message.')
}).or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.name\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(createEvalRunBodyDataSourceSamplingParamsToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(createEvalRunBodyDataSourceSamplingParamsToolsItemOutputCompressionMin).max(createEvalRunBodyDataSourceSamplingParamsToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(createEvalRunBodyDataSourceSamplingParamsToolsItemPartialImagesMin).max(createEvalRunBodyDataSourceSamplingParamsToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling).\n'),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n')
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['responses']).describe('The type of run data source. Always `responses`.'),
  "metadata": zod.object({

}).describe('Metadata filter for the responses. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "model": zod.string().describe('The name of the model to find responses for. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "instructions_search": zod.string().describe('Optional string to search the \'instructions\' field. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_after": zod.number().min(createEvalRunBodyDataSourceSourceCreatedAfterMinFour).describe('Only include items created after this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_before": zod.number().min(createEvalRunBodyDataSourceSourceCreatedBeforeMinFour).describe('Only include items created before this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).or(zod.null()).optional(),
  "temperature": zod.number().describe('Sampling temperature. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "top_p": zod.number().describe('Nucleus sampling parameter. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "users": zod.array(zod.string()).describe('List of user identifiers. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "tools": zod.array(zod.string()).describe('List of tool names. This is a query parameter used to select responses.').or(zod.null()).optional()
}).describe('A EvalResponsesSource object describing a run data source configuration.\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A ResponsesRunDataSource object describing a model sampling configuration.\n')).describe('Details about the run\'s data source.')
})

/**
 * Get an evaluation run by ID.

 * @summary Get an eval run
 */
export const getEvalRunParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to retrieve runs for.'),
  "run_id": zod.string().describe('The ID of the run to retrieve.')
})

export const getEvalRunResponseObjectDefault = "eval.run";export const getEvalRunResponseDataSourceTypeDefault = "jsonl";export const getEvalRunResponseDataSourceSourceTypeDefault = "file_content";export const getEvalRunResponseDataSourceSourceTypeDefaultOne = "file_id";export const getEvalRunResponseDataSourceTypeDefaultOne = "completions";export const getEvalRunResponseDataSourceInputMessagesTemplateItemContentItemTypeDefault = "input_text";export const getEvalRunResponseDataSourceInputMessagesTemplateItemContentItemTypeDefaultOne = "input_image";export const getEvalRunResponseDataSourceInputMessagesTemplateItemContentItemTypeDefaultTwo = "input_file";export const getEvalRunResponseDataSourceInputMessagesTemplateItemContentTypeDefault = "input_text";export const getEvalRunResponseDataSourceSamplingParamsReasoningEffortDefaultOne = "medium";export const getEvalRunResponseDataSourceSamplingParamsTemperatureDefault = 1;export const getEvalRunResponseDataSourceSamplingParamsTopPDefault = 1;export const getEvalRunResponseDataSourceSamplingParamsSeedDefault = 42;export const getEvalRunResponseDataSourceSamplingParamsResponseFormatJsonSchemaStrictDefaultOne = false;export const getEvalRunResponseDataSourceSamplingParamsToolsItemFunctionStrictDefaultOne = false;export const getEvalRunResponseDataSourceSourceTypeDefaultTwo = "file_content";export const getEvalRunResponseDataSourceSourceTypeDefaultThree = "file_id";export const getEvalRunResponseDataSourceSourceTypeDefaultFour = "stored_completions";export const getEvalRunResponseDataSourceTypeDefaultTwo = "responses";export const getEvalRunResponseDataSourceInputMessagesTemplateItemContentTypeDefaultFour = "input_text";export const getEvalRunResponseDataSourceSamplingParamsReasoningEffortDefaultFour = "medium";export const getEvalRunResponseDataSourceSamplingParamsTemperatureDefaultOne = 1;export const getEvalRunResponseDataSourceSamplingParamsTopPDefaultOne = 1;export const getEvalRunResponseDataSourceSamplingParamsSeedDefaultOne = 42;export const getEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultOne = "function";export const getEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultTwo = "file_search";export const getEvalRunResponseDataSourceSamplingParamsToolsItemFiltersTypeDefault = "eq";export const getEvalRunResponseDataSourceSamplingParamsToolsItemFiltersFiltersItemTypeDefault = "eq";export const getEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultThree = "computer_use_preview";export const getEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultFour = "web_search";export const getEvalRunResponseDataSourceSamplingParamsToolsItemFiltersAllowedDomainsDefaultOne = [];export const getEvalRunResponseDataSourceSamplingParamsToolsItemUserLocationTypeDefault = "approximate";export const getEvalRunResponseDataSourceSamplingParamsToolsItemSearchContextSizeDefault = "medium";export const getEvalRunResponseDataSourceSamplingParamsToolsItemRequireApprovalDefaultOne = "always";export const getEvalRunResponseDataSourceSamplingParamsToolsItemContainerTypeDefault = "auto";export const getEvalRunResponseDataSourceSamplingParamsToolsItemContainerFileIdsMax = 50;
export const getEvalRunResponseDataSourceSamplingParamsToolsItemModelDefault = "gpt-image-1";export const getEvalRunResponseDataSourceSamplingParamsToolsItemQualityDefault = "auto";export const getEvalRunResponseDataSourceSamplingParamsToolsItemSizeDefault = "auto";export const getEvalRunResponseDataSourceSamplingParamsToolsItemOutputFormatDefault = "png";export const getEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionDefault = 100;
export const getEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMin = 0;

export const getEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMax = 100;
export const getEvalRunResponseDataSourceSamplingParamsToolsItemModerationDefault = "auto";export const getEvalRunResponseDataSourceSamplingParamsToolsItemBackgroundDefault = "auto";export const getEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesDefault = 0;
export const getEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMin = 0;

export const getEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMax = 3;
export const getEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultEight = "local_shell";export const getEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultNine = "custom";export const getEvalRunResponseDataSourceSamplingParamsToolsItemFormatTypeDefault = "text";export const getEvalRunResponseDataSourceSamplingParamsToolsItemFormatTypeDefaultOne = "grammar";export const getEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultOnezero = "web_search_preview";export const getEvalRunResponseDataSourceSamplingParamsToolsItemUserLocationTypeDefaultOne = "approximate";export const getEvalRunResponseDataSourceSamplingParamsTextFormatStrictDefaultOne = false;export const getEvalRunResponseDataSourceSourceTypeDefaultFive = "file_content";export const getEvalRunResponseDataSourceSourceTypeDefaultSix = "file_id";export const getEvalRunResponseDataSourceSourceCreatedAfterMinFour = 0;
export const getEvalRunResponseDataSourceSourceCreatedBeforeMinFour = 0;
export const getEvalRunResponseDataSourceSourceReasoningEffortDefaultTwo = "medium";

export const getEvalRunResponse = zod.object({
  "object": zod.enum(['eval.run']).optional().describe('The type of the object. Always \"eval.run\".'),
  "id": zod.string().describe('Unique identifier for the evaluation run.'),
  "eval_id": zod.string().describe('The identifier of the associated evaluation.'),
  "status": zod.string().describe('The status of the evaluation run.'),
  "model": zod.string().describe('The model that is evaluated, if applicable.'),
  "name": zod.string().describe('The name of the evaluation run.'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) when the evaluation run was created.'),
  "report_url": zod.string().describe('The URL to the rendered evaluation run report on the UI dashboard.'),
  "result_counts": zod.object({
  "total": zod.number().describe('Total number of executed output items.'),
  "errored": zod.number().describe('Number of output items that resulted in an error.'),
  "failed": zod.number().describe('Number of output items that failed to pass the evaluation.'),
  "passed": zod.number().describe('Number of output items that passed the evaluation.')
}).describe('Counters summarizing the outcomes of the evaluation run.'),
  "per_model_usage": zod.array(zod.object({
  "model_name": zod.string().describe('The name of the model.'),
  "invocation_count": zod.number().describe('The number of invocations.'),
  "prompt_tokens": zod.number().describe('The number of prompt tokens used.'),
  "completion_tokens": zod.number().describe('The number of completion tokens generated.'),
  "total_tokens": zod.number().describe('The total number of tokens used.'),
  "cached_tokens": zod.number().describe('The number of tokens retrieved from cache.')
})).describe('Usage statistics for each model during the evaluation run.'),
  "per_testing_criteria_results": zod.array(zod.object({
  "testing_criteria": zod.string().describe('A description of the testing criteria.'),
  "passed": zod.number().describe('Number of tests passed for this criteria.'),
  "failed": zod.number().describe('Number of tests failed for this criteria.')
})).describe('Results per testing criteria applied during the evaluation run.'),
  "data_source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['jsonl']).optional().describe('The type of data source. Always `jsonl`.'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
})]).describe('Determines what populates the `item` namespace in the data source.')
}).describe('A JsonlRunDataSource object with that specifies a JSONL file that matches the eval\n'),zod.object({
  "type": zod.enum(['completions']).optional().describe('The type of run data source. Always `completions`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n').or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.input_trajectory\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "response_format": zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n').or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).optional().describe('An object specifying the format that the model must output.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables\nStructured Outputs which ensures the model will match your supplied JSON\nschema. Learn more in the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['function']).describe('The type of the tool. Currently, only `function` is supported.'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
}).describe('A function tool that can be used to generate a response.\n')).optional().describe('A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "model": zod.string().describe('An optional model to filter by (e.g., \'gpt-4o\').').or(zod.null()).optional(),
  "created_after": zod.number().describe('An optional Unix timestamp to filter items created after this time.').or(zod.null()).optional(),
  "created_before": zod.number().describe('An optional Unix timestamp to filter items created before this time.').or(zod.null()).optional(),
  "limit": zod.number().describe('An optional maximum number of items to return.').or(zod.null()).optional()
}).describe('A StoredCompletionsRunDataSource configuration describing a set of filters\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A CompletionsRunDataSource object describing a model sampling configuration.\n'),zod.object({
  "type": zod.enum(['responses']).optional().describe('The type of run data source. Always `responses`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.string().describe('The role of the message (e.g. \"system\", \"assistant\", \"user\").'),
  "content": zod.string().describe('The content of the message.')
}).or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.name\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(getEvalRunResponseDataSourceSamplingParamsToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(getEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMin).max(getEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(getEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMin).max(getEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling).\n'),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n')
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['responses']).describe('The type of run data source. Always `responses`.'),
  "metadata": zod.object({

}).describe('Metadata filter for the responses. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "model": zod.string().describe('The name of the model to find responses for. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "instructions_search": zod.string().describe('Optional string to search the \'instructions\' field. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_after": zod.number().min(getEvalRunResponseDataSourceSourceCreatedAfterMinFour).describe('Only include items created after this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_before": zod.number().min(getEvalRunResponseDataSourceSourceCreatedBeforeMinFour).describe('Only include items created before this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).or(zod.null()).optional(),
  "temperature": zod.number().describe('Sampling temperature. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "top_p": zod.number().describe('Nucleus sampling parameter. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "users": zod.array(zod.string()).describe('List of user identifiers. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "tools": zod.array(zod.string()).describe('List of tool names. This is a query parameter used to select responses.').or(zod.null()).optional()
}).describe('A EvalResponsesSource object describing a run data source configuration.\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A ResponsesRunDataSource object describing a model sampling configuration.\n')]).describe('Information about the run\'s data source.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "error": zod.object({
  "code": zod.string().describe('The error code.'),
  "message": zod.string().describe('The error message.')
}).describe('An object representing an error response from the Eval API.\n')
}).describe('A schema representing an evaluation run.\n')

/**
 * Cancel an ongoing evaluation run.

 * @summary Cancel eval run
 */
export const cancelEvalRunParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation whose run you want to cancel.'),
  "run_id": zod.string().describe('The ID of the run to cancel.')
})

export const cancelEvalRunResponseObjectDefault = "eval.run";export const cancelEvalRunResponseDataSourceTypeDefault = "jsonl";export const cancelEvalRunResponseDataSourceSourceTypeDefault = "file_content";export const cancelEvalRunResponseDataSourceSourceTypeDefaultOne = "file_id";export const cancelEvalRunResponseDataSourceTypeDefaultOne = "completions";export const cancelEvalRunResponseDataSourceInputMessagesTemplateItemContentItemTypeDefault = "input_text";export const cancelEvalRunResponseDataSourceInputMessagesTemplateItemContentItemTypeDefaultOne = "input_image";export const cancelEvalRunResponseDataSourceInputMessagesTemplateItemContentItemTypeDefaultTwo = "input_file";export const cancelEvalRunResponseDataSourceInputMessagesTemplateItemContentTypeDefault = "input_text";export const cancelEvalRunResponseDataSourceSamplingParamsReasoningEffortDefaultOne = "medium";export const cancelEvalRunResponseDataSourceSamplingParamsTemperatureDefault = 1;export const cancelEvalRunResponseDataSourceSamplingParamsTopPDefault = 1;export const cancelEvalRunResponseDataSourceSamplingParamsSeedDefault = 42;export const cancelEvalRunResponseDataSourceSamplingParamsResponseFormatJsonSchemaStrictDefaultOne = false;export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemFunctionStrictDefaultOne = false;export const cancelEvalRunResponseDataSourceSourceTypeDefaultTwo = "file_content";export const cancelEvalRunResponseDataSourceSourceTypeDefaultThree = "file_id";export const cancelEvalRunResponseDataSourceSourceTypeDefaultFour = "stored_completions";export const cancelEvalRunResponseDataSourceTypeDefaultTwo = "responses";export const cancelEvalRunResponseDataSourceInputMessagesTemplateItemContentTypeDefaultFour = "input_text";export const cancelEvalRunResponseDataSourceSamplingParamsReasoningEffortDefaultFour = "medium";export const cancelEvalRunResponseDataSourceSamplingParamsTemperatureDefaultOne = 1;export const cancelEvalRunResponseDataSourceSamplingParamsTopPDefaultOne = 1;export const cancelEvalRunResponseDataSourceSamplingParamsSeedDefaultOne = 42;export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultOne = "function";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultTwo = "file_search";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemFiltersTypeDefault = "eq";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemFiltersFiltersItemTypeDefault = "eq";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultThree = "computer_use_preview";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultFour = "web_search";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemFiltersAllowedDomainsDefaultOne = [];export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemUserLocationTypeDefault = "approximate";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemSearchContextSizeDefault = "medium";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemRequireApprovalDefaultOne = "always";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemContainerTypeDefault = "auto";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemContainerFileIdsMax = 50;
export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemModelDefault = "gpt-image-1";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemQualityDefault = "auto";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemSizeDefault = "auto";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemOutputFormatDefault = "png";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionDefault = 100;
export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMin = 0;

export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMax = 100;
export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemModerationDefault = "auto";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemBackgroundDefault = "auto";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesDefault = 0;
export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMin = 0;

export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMax = 3;
export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultEight = "local_shell";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultNine = "custom";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemFormatTypeDefault = "text";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemFormatTypeDefaultOne = "grammar";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemTypeDefaultOnezero = "web_search_preview";export const cancelEvalRunResponseDataSourceSamplingParamsToolsItemUserLocationTypeDefaultOne = "approximate";export const cancelEvalRunResponseDataSourceSamplingParamsTextFormatStrictDefaultOne = false;export const cancelEvalRunResponseDataSourceSourceTypeDefaultFive = "file_content";export const cancelEvalRunResponseDataSourceSourceTypeDefaultSix = "file_id";export const cancelEvalRunResponseDataSourceSourceCreatedAfterMinFour = 0;
export const cancelEvalRunResponseDataSourceSourceCreatedBeforeMinFour = 0;
export const cancelEvalRunResponseDataSourceSourceReasoningEffortDefaultTwo = "medium";

export const cancelEvalRunResponse = zod.object({
  "object": zod.enum(['eval.run']).optional().describe('The type of the object. Always \"eval.run\".'),
  "id": zod.string().describe('Unique identifier for the evaluation run.'),
  "eval_id": zod.string().describe('The identifier of the associated evaluation.'),
  "status": zod.string().describe('The status of the evaluation run.'),
  "model": zod.string().describe('The model that is evaluated, if applicable.'),
  "name": zod.string().describe('The name of the evaluation run.'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) when the evaluation run was created.'),
  "report_url": zod.string().describe('The URL to the rendered evaluation run report on the UI dashboard.'),
  "result_counts": zod.object({
  "total": zod.number().describe('Total number of executed output items.'),
  "errored": zod.number().describe('Number of output items that resulted in an error.'),
  "failed": zod.number().describe('Number of output items that failed to pass the evaluation.'),
  "passed": zod.number().describe('Number of output items that passed the evaluation.')
}).describe('Counters summarizing the outcomes of the evaluation run.'),
  "per_model_usage": zod.array(zod.object({
  "model_name": zod.string().describe('The name of the model.'),
  "invocation_count": zod.number().describe('The number of invocations.'),
  "prompt_tokens": zod.number().describe('The number of prompt tokens used.'),
  "completion_tokens": zod.number().describe('The number of completion tokens generated.'),
  "total_tokens": zod.number().describe('The total number of tokens used.'),
  "cached_tokens": zod.number().describe('The number of tokens retrieved from cache.')
})).describe('Usage statistics for each model during the evaluation run.'),
  "per_testing_criteria_results": zod.array(zod.object({
  "testing_criteria": zod.string().describe('A description of the testing criteria.'),
  "passed": zod.number().describe('Number of tests passed for this criteria.'),
  "failed": zod.number().describe('Number of tests failed for this criteria.')
})).describe('Results per testing criteria applied during the evaluation run.'),
  "data_source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['jsonl']).optional().describe('The type of data source. Always `jsonl`.'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
})]).describe('Determines what populates the `item` namespace in the data source.')
}).describe('A JsonlRunDataSource object with that specifies a JSONL file that matches the eval\n'),zod.object({
  "type": zod.enum(['completions']).optional().describe('The type of run data source. Always `completions`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n').or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.input_trajectory\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "response_format": zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n').or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).optional().describe('An object specifying the format that the model must output.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables\nStructured Outputs which ensures the model will match your supplied JSON\nschema. Learn more in the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['function']).describe('The type of the tool. Currently, only `function` is supported.'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
}).describe('A function tool that can be used to generate a response.\n')).optional().describe('A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['stored_completions']).optional().describe('The type of source. Always `stored_completions`.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "model": zod.string().describe('An optional model to filter by (e.g., \'gpt-4o\').').or(zod.null()).optional(),
  "created_after": zod.number().describe('An optional Unix timestamp to filter items created after this time.').or(zod.null()).optional(),
  "created_before": zod.number().describe('An optional Unix timestamp to filter items created before this time.').or(zod.null()).optional(),
  "limit": zod.number().describe('An optional maximum number of items to return.').or(zod.null()).optional()
}).describe('A StoredCompletionsRunDataSource configuration describing a set of filters\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A CompletionsRunDataSource object describing a model sampling configuration.\n'),zod.object({
  "type": zod.enum(['responses']).optional().describe('The type of run data source. Always `responses`.'),
  "input_messages": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['template']).describe('The type of input messages. Always `template`.'),
  "template": zod.array(zod.object({
  "role": zod.string().describe('The role of the message (e.g. \"system\", \"assistant\", \"user\").'),
  "content": zod.string().describe('The content of the message.')
}).or(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'))).describe('A list of chat messages forming the prompt or context. May include variable references to the `item` namespace, ie {{item.name}}.')
}),zod.object({
  "type": zod.enum(['item_reference']).describe('The type of input messages. Always `item_reference`.'),
  "item_reference": zod.string().describe('A reference to a variable in the `item` namespace. Ie, \"item.name\"')
})]).optional().describe('Used when sampling from a model. Dictates the structure of the messages passed into the model. Can either be a reference to a prebuilt trajectory (ie, `item.input_trajectory`), or a template with variable references to the `item` namespace.'),
  "sampling_params": zod.object({
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "temperature": zod.number().optional().describe('A higher temperature increases randomness in the outputs.'),
  "max_completion_tokens": zod.number().optional().describe('The maximum number of tokens in the generated output.'),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.'),
  "seed": zod.number().optional().describe('A seed value to initialize the randomness, during sampling.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(cancelEvalRunResponseDataSourceSamplingParamsToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(cancelEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMin).max(cancelEvalRunResponseDataSourceSamplingParamsToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(cancelEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMin).max(cancelEvalRunResponseDataSourceSamplingParamsToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nThe two categories of tools you can provide the model are:\n\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling).\n'),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n')
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n')
}).optional(),
  "model": zod.string().optional().describe('The name of the model to use for generating completions (e.g. \"o3-mini\").'),
  "source": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_content']).optional().describe('The type of jsonl source. Always `file_content`.'),
  "content": zod.array(zod.object({
  "item": zod.record(zod.string(), zod.any()),
  "sample": zod.record(zod.string(), zod.any()).optional()
})).describe('The content of the jsonl file.')
}),zod.object({
  "type": zod.enum(['file_id']).optional().describe('The type of jsonl source. Always `file_id`.'),
  "id": zod.string().describe('The identifier of the file.')
}),zod.object({
  "type": zod.enum(['responses']).describe('The type of run data source. Always `responses`.'),
  "metadata": zod.object({

}).describe('Metadata filter for the responses. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "model": zod.string().describe('The name of the model to find responses for. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "instructions_search": zod.string().describe('Optional string to search the \'instructions\' field. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_after": zod.number().min(cancelEvalRunResponseDataSourceSourceCreatedAfterMinFour).describe('Only include items created after this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "created_before": zod.number().min(cancelEvalRunResponseDataSourceSourceCreatedBeforeMinFour).describe('Only include items created before this timestamp (inclusive). This is a query parameter used to select responses.').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).or(zod.null()).optional(),
  "temperature": zod.number().describe('Sampling temperature. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "top_p": zod.number().describe('Nucleus sampling parameter. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "users": zod.array(zod.string()).describe('List of user identifiers. This is a query parameter used to select responses.').or(zod.null()).optional(),
  "tools": zod.array(zod.string()).describe('List of tool names. This is a query parameter used to select responses.').or(zod.null()).optional()
}).describe('A EvalResponsesSource object describing a run data source configuration.\n')]).describe('Determines what populates the `item` namespace in this run\'s data source.')
}).describe('A ResponsesRunDataSource object describing a model sampling configuration.\n')]).describe('Information about the run\'s data source.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "error": zod.object({
  "code": zod.string().describe('The error code.'),
  "message": zod.string().describe('The error message.')
}).describe('An object representing an error response from the Eval API.\n')
}).describe('A schema representing an evaluation run.\n')

/**
 * Delete an eval run.

 * @summary Delete eval run
 */
export const deleteEvalRunParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to delete the run from.'),
  "run_id": zod.string().describe('The ID of the run to delete.')
})

export const deleteEvalRunResponse = zod.object({
  "object": zod.string().optional(),
  "deleted": zod.boolean().optional(),
  "run_id": zod.string().optional()
})

/**
 * Get a list of output items for an evaluation run.

 * @summary Get eval run output items
 */
export const getEvalRunOutputItemsParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to retrieve runs for.'),
  "run_id": zod.string().describe('The ID of the run to retrieve output items for.')
})

export const getEvalRunOutputItemsQueryLimitDefault = 20;export const getEvalRunOutputItemsQueryOrderDefault = "asc";

export const getEvalRunOutputItemsQueryParams = zod.object({
  "after": zod.string().optional().describe('Identifier for the last output item from the previous pagination request.'),
  "limit": zod.number().optional().describe('Number of output items to retrieve.'),
  "status": zod.enum(['fail', 'pass']).optional().describe('Filter output items by status. Use `failed` to filter by failed output\nitems or `pass` to filter by passed output items.\n'),
  "order": zod.enum(['asc', 'desc']).optional().describe('Sort order for output items by timestamp. Use `asc` for ascending order or `desc` for descending order. Defaults to `asc`.')
})

export const getEvalRunOutputItemsResponseObjectDefault = "list";export const getEvalRunOutputItemsResponseDataItemObjectDefault = "eval.run.output_item";

export const getEvalRunOutputItemsResponse = zod.object({
  "object": zod.enum(['list']).optional().describe('The type of this object. It is always set to \"list\".\n'),
  "data": zod.array(zod.object({
  "object": zod.enum(['eval.run.output_item']).optional().describe('The type of the object. Always \"eval.run.output_item\".'),
  "id": zod.string().describe('Unique identifier for the evaluation run output item.'),
  "run_id": zod.string().describe('The identifier of the evaluation run associated with this output item.'),
  "eval_id": zod.string().describe('The identifier of the evaluation group.'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) when the evaluation run was created.'),
  "status": zod.string().describe('The status of the evaluation run.'),
  "datasource_item_id": zod.number().describe('The identifier for the data source item.'),
  "datasource_item": zod.record(zod.string(), zod.any()).describe('Details of the input data source item.'),
  "results": zod.array(zod.object({
  "name": zod.string().describe('The name of the grader.'),
  "type": zod.string().optional().describe('The grader type (for example, \"string-check-grader\").'),
  "score": zod.number().describe('The numeric score produced by the grader.'),
  "passed": zod.boolean().describe('Whether the grader considered the output a pass.'),
  "sample": zod.record(zod.string(), zod.any()).or(zod.null()).optional().describe('Optional sample or intermediate data produced by the grader.')
}).describe('A single grader result for an evaluation run output item.\n')).describe('A list of grader results for this output item.'),
  "sample": zod.object({
  "input": zod.array(zod.object({
  "role": zod.string().describe('The role of the message sender (e.g., system, user, developer).'),
  "content": zod.string().describe('The content of the message.')
}).describe('An input message.')).describe('An array of input messages.'),
  "output": zod.array(zod.object({
  "role": zod.string().optional().describe('The role of the message (e.g. \"system\", \"assistant\", \"user\").'),
  "content": zod.string().optional().describe('The content of the message.')
})).describe('An array of output messages.'),
  "finish_reason": zod.string().describe('The reason why the sample generation was finished.'),
  "model": zod.string().describe('The model used for generating the sample.'),
  "usage": zod.object({
  "total_tokens": zod.number().describe('The total number of tokens used.'),
  "completion_tokens": zod.number().describe('The number of completion tokens generated.'),
  "prompt_tokens": zod.number().describe('The number of prompt tokens used.'),
  "cached_tokens": zod.number().describe('The number of tokens retrieved from cache.')
}).describe('Token usage details for the sample.'),
  "error": zod.object({
  "code": zod.string().describe('The error code.'),
  "message": zod.string().describe('The error message.')
}).describe('An object representing an error response from the Eval API.\n'),
  "temperature": zod.number().describe('The sampling temperature used.'),
  "max_completion_tokens": zod.number().describe('The maximum number of tokens allowed for completion.'),
  "top_p": zod.number().describe('The top_p value used for sampling.'),
  "seed": zod.number().describe('The seed used for generating the sample.')
}).describe('A sample containing the input and output of the evaluation run.')
}).describe('A schema representing an evaluation run output item.\n')).describe('An array of eval run output item objects.\n'),
  "first_id": zod.string().describe('The identifier of the first eval run output item in the data array.'),
  "last_id": zod.string().describe('The identifier of the last eval run output item in the data array.'),
  "has_more": zod.boolean().describe('Indicates whether there are more eval run output items available.')
}).describe('An object representing a list of output items for an evaluation run.\n')

/**
 * Get an evaluation run output item by ID.

 * @summary Get an output item of an eval run
 */
export const getEvalRunOutputItemParams = zod.object({
  "eval_id": zod.string().describe('The ID of the evaluation to retrieve runs for.'),
  "run_id": zod.string().describe('The ID of the run to retrieve.'),
  "output_item_id": zod.string().describe('The ID of the output item to retrieve.')
})

export const getEvalRunOutputItemResponseObjectDefault = "eval.run.output_item";

export const getEvalRunOutputItemResponse = zod.object({
  "object": zod.enum(['eval.run.output_item']).optional().describe('The type of the object. Always \"eval.run.output_item\".'),
  "id": zod.string().describe('Unique identifier for the evaluation run output item.'),
  "run_id": zod.string().describe('The identifier of the evaluation run associated with this output item.'),
  "eval_id": zod.string().describe('The identifier of the evaluation group.'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) when the evaluation run was created.'),
  "status": zod.string().describe('The status of the evaluation run.'),
  "datasource_item_id": zod.number().describe('The identifier for the data source item.'),
  "datasource_item": zod.record(zod.string(), zod.any()).describe('Details of the input data source item.'),
  "results": zod.array(zod.object({
  "name": zod.string().describe('The name of the grader.'),
  "type": zod.string().optional().describe('The grader type (for example, \"string-check-grader\").'),
  "score": zod.number().describe('The numeric score produced by the grader.'),
  "passed": zod.boolean().describe('Whether the grader considered the output a pass.'),
  "sample": zod.record(zod.string(), zod.any()).or(zod.null()).optional().describe('Optional sample or intermediate data produced by the grader.')
}).describe('A single grader result for an evaluation run output item.\n')).describe('A list of grader results for this output item.'),
  "sample": zod.object({
  "input": zod.array(zod.object({
  "role": zod.string().describe('The role of the message sender (e.g., system, user, developer).'),
  "content": zod.string().describe('The content of the message.')
}).describe('An input message.')).describe('An array of input messages.'),
  "output": zod.array(zod.object({
  "role": zod.string().optional().describe('The role of the message (e.g. \"system\", \"assistant\", \"user\").'),
  "content": zod.string().optional().describe('The content of the message.')
})).describe('An array of output messages.'),
  "finish_reason": zod.string().describe('The reason why the sample generation was finished.'),
  "model": zod.string().describe('The model used for generating the sample.'),
  "usage": zod.object({
  "total_tokens": zod.number().describe('The total number of tokens used.'),
  "completion_tokens": zod.number().describe('The number of completion tokens generated.'),
  "prompt_tokens": zod.number().describe('The number of prompt tokens used.'),
  "cached_tokens": zod.number().describe('The number of tokens retrieved from cache.')
}).describe('Token usage details for the sample.'),
  "error": zod.object({
  "code": zod.string().describe('The error code.'),
  "message": zod.string().describe('The error message.')
}).describe('An object representing an error response from the Eval API.\n'),
  "temperature": zod.number().describe('The sampling temperature used.'),
  "max_completion_tokens": zod.number().describe('The maximum number of tokens allowed for completion.'),
  "top_p": zod.number().describe('The top_p value used for sampling.'),
  "seed": zod.number().describe('The seed used for generating the sample.')
}).describe('A sample containing the input and output of the evaluation run.')
}).describe('A schema representing an evaluation run output item.\n')

