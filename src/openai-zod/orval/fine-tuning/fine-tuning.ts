/**
 * Generated by orval v7.7.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import {
  z as zod
} from 'zod';


/**
 * Run a grader.

 * @summary Run grader
 */
export const runGraderBodyGraderTypeDefaultOne = "text_similarity";export const runGraderBodyGraderSamplingParamsTopPDefaultOne = 1;export const runGraderBodyGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const runGraderBodyGraderInputItemContentTypeDefault = "input_text";export const runGraderBodyGraderTypeDefaultFour = "multi";export const runGraderBodyGraderGradersTypeDefaultOne = "text_similarity";export const runGraderBodyGraderGradersSamplingParamsTopPDefaultOne = 1;export const runGraderBodyGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const runGraderBodyGraderGradersInputItemContentTypeDefault = "input_text";export const runGraderBodyGraderGradersInputItemContentTypeDefaultFour = "input_text";

export const runGraderBody = zod.object({
  "grader": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n'),zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n'),zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n'),zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n'),zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')]).describe('The grader used for the fine-tuning job.'),
  "item": zod.object({

}).optional().describe('The dataset item provided to the grader. This will be used to populate\nthe `item` namespace. See [the guide](https://platform.openai.com/docs/guides/graders) for more details.\n'),
  "model_sample": zod.string().describe('The model sample to be evaluated. This value will be used to populate\nthe `sample` namespace. See [the guide](https://platform.openai.com/docs/guides/graders) for more details.\nThe `output_json` variable will be populated if the model sample is a\nvalid JSON string.\n')
})

export const runGraderResponse = zod.object({
  "reward": zod.number(),
  "metadata": zod.object({
  "name": zod.string(),
  "type": zod.string(),
  "errors": zod.object({
  "formula_parse_error": zod.boolean(),
  "sample_parse_error": zod.boolean(),
  "truncated_observation_error": zod.boolean(),
  "unresponsive_reward_error": zod.boolean(),
  "invalid_variable_error": zod.boolean(),
  "other_error": zod.boolean(),
  "python_grader_server_error": zod.boolean(),
  "python_grader_server_error_type": zod.string().or(zod.null()),
  "python_grader_runtime_error": zod.boolean(),
  "python_grader_runtime_error_details": zod.string().or(zod.null()),
  "model_grader_server_error": zod.boolean(),
  "model_grader_refusal_error": zod.boolean(),
  "model_grader_parse_error": zod.boolean(),
  "model_grader_server_error_details": zod.string().or(zod.null())
}),
  "execution_time": zod.number(),
  "scores": zod.record(zod.string(), zod.any()),
  "token_usage": zod.number().or(zod.null()),
  "sampled_model_name": zod.string().or(zod.null())
}),
  "sub_rewards": zod.record(zod.string(), zod.any()),
  "model_grader_token_usage_per_model": zod.record(zod.string(), zod.any())
})

/**
 * Validate a grader.

 * @summary Validate grader
 */
export const validateGraderBodyGraderTypeDefaultOne = "text_similarity";export const validateGraderBodyGraderSamplingParamsTopPDefaultOne = 1;export const validateGraderBodyGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const validateGraderBodyGraderInputItemContentTypeDefault = "input_text";export const validateGraderBodyGraderTypeDefaultFour = "multi";export const validateGraderBodyGraderGradersTypeDefaultOne = "text_similarity";export const validateGraderBodyGraderGradersSamplingParamsTopPDefaultOne = 1;export const validateGraderBodyGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const validateGraderBodyGraderGradersInputItemContentTypeDefault = "input_text";export const validateGraderBodyGraderGradersInputItemContentTypeDefaultFour = "input_text";

export const validateGraderBody = zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.')
})

export const validateGraderResponseGraderTypeDefaultOne = "text_similarity";export const validateGraderResponseGraderSamplingParamsTopPDefaultOne = 1;export const validateGraderResponseGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const validateGraderResponseGraderInputItemContentTypeDefault = "input_text";export const validateGraderResponseGraderTypeDefaultFour = "multi";export const validateGraderResponseGraderGradersTypeDefaultOne = "text_similarity";export const validateGraderResponseGraderGradersSamplingParamsTopPDefaultOne = 1;export const validateGraderResponseGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const validateGraderResponseGraderGradersInputItemContentTypeDefault = "input_text";export const validateGraderResponseGraderGradersInputItemContentTypeDefaultFour = "input_text";

export const validateGraderResponse = zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).optional().describe('The grader used for the fine-tuning job.')
})

/**
 * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

Organization owners can use this endpoint to view all permissions for a fine-tuned model checkpoint.

 * @summary List checkpoint permissions
 */
export const listFineTuningCheckpointPermissionsParams = zod.object({
  "fine_tuned_model_checkpoint": zod.string().describe('The ID of the fine-tuned model checkpoint to get permissions for.\n')
})

export const listFineTuningCheckpointPermissionsQueryLimitDefault = 10;export const listFineTuningCheckpointPermissionsQueryOrderDefault = "descending";

export const listFineTuningCheckpointPermissionsQueryParams = zod.object({
  "project_id": zod.string().optional().describe('The ID of the project to get permissions for.'),
  "after": zod.string().optional().describe('Identifier for the last permission ID from the previous pagination request.'),
  "limit": zod.number().optional().describe('Number of permissions to retrieve.'),
  "order": zod.enum(['ascending', 'descending']).optional().describe('The order in which to retrieve permissions.')
})

export const listFineTuningCheckpointPermissionsResponse = zod.object({
  "data": zod.array(zod.object({
  "id": zod.string().describe('The permission identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the permission was created.'),
  "project_id": zod.string().describe('The project identifier that the permission is for.'),
  "object": zod.enum(['checkpoint.permission']).describe('The object type, which is always \"checkpoint.permission\".')
}).describe('The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint.\n')),
  "object": zod.enum(['list']),
  "first_id": zod.string().or(zod.null()).optional(),
  "last_id": zod.string().or(zod.null()).optional(),
  "has_more": zod.boolean()
})

/**
 * **NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).

This enables organization owners to share fine-tuned models with other projects in their organization.

 * @summary Create checkpoint permissions
 */
export const createFineTuningCheckpointPermissionParams = zod.object({
  "fine_tuned_model_checkpoint": zod.string().describe('The ID of the fine-tuned model checkpoint to create a permission for.\n')
})

export const createFineTuningCheckpointPermissionBody = zod.object({
  "project_ids": zod.array(zod.string()).describe('The project identifiers to grant access to.')
})

export const createFineTuningCheckpointPermissionResponse = zod.object({
  "data": zod.array(zod.object({
  "id": zod.string().describe('The permission identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the permission was created.'),
  "project_id": zod.string().describe('The project identifier that the permission is for.'),
  "object": zod.enum(['checkpoint.permission']).describe('The object type, which is always \"checkpoint.permission\".')
}).describe('The `checkpoint.permission` object represents a permission for a fine-tuned model checkpoint.\n')),
  "object": zod.enum(['list']),
  "first_id": zod.string().or(zod.null()).optional(),
  "last_id": zod.string().or(zod.null()).optional(),
  "has_more": zod.boolean()
})

/**
 * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).

Organization owners can use this endpoint to delete a permission for a fine-tuned model checkpoint.

 * @summary Delete checkpoint permission
 */
export const deleteFineTuningCheckpointPermissionParams = zod.object({
  "fine_tuned_model_checkpoint": zod.string().describe('The ID of the fine-tuned model checkpoint to delete a permission for.\n'),
  "permission_id": zod.string().describe('The ID of the fine-tuned model checkpoint permission to delete.\n')
})

export const deleteFineTuningCheckpointPermissionResponse = zod.object({
  "id": zod.string().describe('The ID of the fine-tuned model checkpoint permission that was deleted.'),
  "object": zod.enum(['checkpoint.permission']).describe('The object type, which is always \"checkpoint.permission\".'),
  "deleted": zod.boolean().describe('Whether the fine-tuned model checkpoint permission was successfully deleted.')
})

/**
 * Creates a fine-tuning job which begins the process of creating a new model from a given dataset.

Response includes details of the enqueued job including job status and the name of the fine-tuned models once complete.

[Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)

 * @summary Create fine-tuning job
 */
export const createFineTuningJobBodyHyperparametersBatchSizeMaxTwo = 256;
export const createFineTuningJobBodyHyperparametersBatchSizeDefault = "auto";export const createFineTuningJobBodyHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobBodyHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobBodyHyperparametersNEpochsDefault = "auto";export const createFineTuningJobBodySuffixDefault = null;
export const createFineTuningJobBodySuffixMax = 64;
export const createFineTuningJobBodySeedMin = 0;

export const createFineTuningJobBodySeedMax = 2147483647;
export const createFineTuningJobBodyMethodSupervisedHyperparametersBatchSizeMaxTwo = 256;
export const createFineTuningJobBodyMethodSupervisedHyperparametersBatchSizeDefault = "auto";export const createFineTuningJobBodyMethodSupervisedHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobBodyMethodSupervisedHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobBodyMethodSupervisedHyperparametersNEpochsDefault = "auto";export const createFineTuningJobBodyMethodDpoHyperparametersBetaMinTwo = 0;
export const createFineTuningJobBodyMethodDpoHyperparametersBetaMaxTwo = 2;
export const createFineTuningJobBodyMethodDpoHyperparametersBatchSizeMaxTwo = 256;
export const createFineTuningJobBodyMethodDpoHyperparametersBatchSizeDefault = "auto";export const createFineTuningJobBodyMethodDpoHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobBodyMethodDpoHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobBodyMethodDpoHyperparametersNEpochsDefault = "auto";export const createFineTuningJobBodyMethodReinforcementGraderTypeDefaultOne = "text_similarity";export const createFineTuningJobBodyMethodReinforcementGraderSamplingParamsTopPDefaultOne = 1;export const createFineTuningJobBodyMethodReinforcementGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const createFineTuningJobBodyMethodReinforcementGraderInputItemContentTypeDefault = "input_text";export const createFineTuningJobBodyMethodReinforcementGraderTypeDefaultFour = "multi";export const createFineTuningJobBodyMethodReinforcementGraderGradersTypeDefaultOne = "text_similarity";export const createFineTuningJobBodyMethodReinforcementGraderGradersSamplingParamsTopPDefaultOne = 1;export const createFineTuningJobBodyMethodReinforcementGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const createFineTuningJobBodyMethodReinforcementGraderGradersInputItemContentTypeDefault = "input_text";export const createFineTuningJobBodyMethodReinforcementGraderGradersInputItemContentTypeDefaultFour = "input_text";export const createFineTuningJobBodyMethodReinforcementHyperparametersBatchSizeMaxTwo = 256;
export const createFineTuningJobBodyMethodReinforcementHyperparametersBatchSizeDefault = "auto";export const createFineTuningJobBodyMethodReinforcementHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobBodyMethodReinforcementHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobBodyMethodReinforcementHyperparametersNEpochsDefault = "auto";export const createFineTuningJobBodyMethodReinforcementHyperparametersReasoningEffortDefault = "default";export const createFineTuningJobBodyMethodReinforcementHyperparametersComputeMultiplierMinTwo = 0.00001;
export const createFineTuningJobBodyMethodReinforcementHyperparametersComputeMultiplierMaxTwo = 10;
export const createFineTuningJobBodyMethodReinforcementHyperparametersEvalIntervalDefault = "auto";export const createFineTuningJobBodyMethodReinforcementHyperparametersEvalSamplesDefault = "auto";

export const createFineTuningJobBody = zod.object({
  "model": zod.string().or(zod.enum(['babbage-002', 'davinci-002', 'gpt-3.5-turbo', 'gpt-4o-mini'])).describe('The name of the model to fine-tune. You can select one of the\n[supported models](https://platform.openai.com/docs/guides/fine-tuning#which-models-can-be-fine-tuned).\n'),
  "training_file": zod.string().describe('The ID of an uploaded file that contains training data.\n\nSee [upload file](https://platform.openai.com/docs/api-reference/files/create) for how to upload a file.\n\nYour dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.\n\nThe contents of the file should differ depending on if the model uses the [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input), [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input) format, or if the fine-tuning method uses the [preference](https://platform.openai.com/docs/api-reference/fine-tuning/preference-input) format.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization) for more details.\n'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobBodyHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.\nThis value is now deprecated in favor of `method`, and should be passed in under the `method` parameter.\n'),
  "suffix": zod.string().min(1).max(createFineTuningJobBodySuffixMax).nullish().describe('A string of up to 64 characters that will be added to your fine-tuned model name.\n\nFor example, a `suffix` of \"custom-model-name\" would produce a model name like `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n'),
  "validation_file": zod.string().nullish().describe('The ID of an uploaded file that contains validation data.\n\nIf you provide this file, the data is used to generate validation\nmetrics periodically during fine-tuning. These metrics can be viewed in\nthe fine-tuning results file.\nThe same data should not be present in both train and validation files.\n\nYour dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.\n\nSee the [fine-tuning guide](https://platform.openai.com/docs/guides/model-optimization) for more details.\n'),
  "integrations": zod.array(zod.object({
  "type": zod.enum(['wandb']).describe('The type of integration to enable. Currently, only \"wandb\" (Weights and Biases) is supported.\n'),
  "wandb": zod.object({
  "project": zod.string().describe('The name of the project that the new run will be created under.\n'),
  "name": zod.string().nullish().describe('A display name to set for the run. If not set, we will use the Job ID as the name.\n'),
  "entity": zod.string().nullish().describe('The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n'),
  "tags": zod.array(zod.string()).optional().describe('A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n')
}).describe('The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n')
})).nullish().describe('A list of integrations to enable for your fine-tuning job.'),
  "seed": zod.number().min(createFineTuningJobBodySeedMin).max(createFineTuningJobBodySeedMax).nullish().describe('The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.\nIf a seed is not specified, one will be generated for you.\n'),
  "method": zod.object({
  "type": zod.enum(['supervised', 'dpo', 'reinforcement']).describe('The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'),
  "supervised": zod.object({
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyMethodSupervisedHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobBodyMethodSupervisedHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyMethodSupervisedHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.')
}).optional().describe('Configuration for the supervised fine-tuning method.'),
  "dpo": zod.object({
  "hyperparameters": zod.object({
  "beta": zod.enum(['auto']).or(zod.number().min(createFineTuningJobBodyMethodDpoHyperparametersBetaMinTwo).max(createFineTuningJobBodyMethodDpoHyperparametersBetaMaxTwo)).optional().describe('The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n'),
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyMethodDpoHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobBodyMethodDpoHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyMethodDpoHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the DPO fine-tuning job.')
}).optional().describe('Configuration for the DPO fine-tuning method.'),
  "reinforcement": zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyMethodReinforcementHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobBodyMethodReinforcementHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobBodyMethodReinforcementHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n'),
  "reasoning_effort": zod.enum(['default', 'low', 'medium', 'high']).optional().describe('Level of reasoning effort.\n'),
  "compute_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobBodyMethodReinforcementHyperparametersComputeMultiplierMinTwo).max(createFineTuningJobBodyMethodReinforcementHyperparametersComputeMultiplierMaxTwo)).optional().describe('Multiplier on amount of compute used for exploring search space during training.\n'),
  "eval_interval": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('The number of training steps between evaluation runs.\n'),
  "eval_samples": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('Number of evaluation samples to generate per training step.\n')
}).optional().describe('The hyperparameters used for the reinforcement fine-tuning job.')
}).optional().describe('Configuration for the reinforcement fine-tuning method.')
}).optional().describe('The method used for fine-tuning.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

export const createFineTuningJobResponseHyperparametersBatchSizeMaxThree = 256;
export const createFineTuningJobResponseHyperparametersBatchSizeDefaultOne = "auto";export const createFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobResponseHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobResponseHyperparametersNEpochsDefault = "auto";export const createFineTuningJobResponseIntegrationsMaxOne = 5;
export const createFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo = 256;
export const createFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeDefault = "auto";export const createFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobResponseMethodSupervisedHyperparametersNEpochsDefault = "auto";export const createFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo = 0;
export const createFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo = 2;
export const createFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo = 256;
export const createFineTuningJobResponseMethodDpoHyperparametersBatchSizeDefault = "auto";export const createFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobResponseMethodDpoHyperparametersNEpochsDefault = "auto";export const createFineTuningJobResponseMethodReinforcementGraderTypeDefaultOne = "text_similarity";export const createFineTuningJobResponseMethodReinforcementGraderSamplingParamsTopPDefaultOne = 1;export const createFineTuningJobResponseMethodReinforcementGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const createFineTuningJobResponseMethodReinforcementGraderInputItemContentTypeDefault = "input_text";export const createFineTuningJobResponseMethodReinforcementGraderTypeDefaultFour = "multi";export const createFineTuningJobResponseMethodReinforcementGraderGradersTypeDefaultOne = "text_similarity";export const createFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsTopPDefaultOne = 1;export const createFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const createFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefault = "input_text";export const createFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefaultFour = "input_text";export const createFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo = 256;
export const createFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeDefault = "auto";export const createFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo = 0;
export const createFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo = 50;
export const createFineTuningJobResponseMethodReinforcementHyperparametersNEpochsDefault = "auto";export const createFineTuningJobResponseMethodReinforcementHyperparametersReasoningEffortDefault = "default";export const createFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo = 0.00001;
export const createFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo = 10;
export const createFineTuningJobResponseMethodReinforcementHyperparametersEvalIntervalDefault = "auto";export const createFineTuningJobResponseMethodReinforcementHyperparametersEvalSamplesDefault = "auto";

export const createFineTuningJobResponse = zod.object({
  "id": zod.string().describe('The object identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was created.'),
  "error": zod.object({
  "code": zod.string().describe('A machine-readable error code.'),
  "message": zod.string().describe('A human-readable error message.'),
  "param": zod.string().describe('The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.').or(zod.null())
}).describe('For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.').or(zod.null()),
  "fine_tuned_model": zod.string().describe('The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "finished_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseHyperparametersBatchSizeMaxThree)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n').or(zod.null()).optional(),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n')
}).describe('The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.'),
  "model": zod.string().describe('The base model that is being fine-tuned.'),
  "object": zod.enum(['fine_tuning.job']).describe('The object type, which is always \"fine_tuning.job\".'),
  "organization_id": zod.string().describe('The organization that owns the fine-tuning job.'),
  "result_files": zod.array(zod.string()).describe('The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "status": zod.enum(['validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled']).describe('The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'),
  "trained_tokens": zod.number().describe('The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "training_file": zod.string().describe('The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "validation_file": zod.string().describe('The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).').or(zod.null()),
  "integrations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['wandb']).describe('The type of the integration being enabled for the fine-tuning job'),
  "wandb": zod.object({
  "project": zod.string().describe('The name of the project that the new run will be created under.\n'),
  "name": zod.string().describe('A display name to set for the run. If not set, we will use the Job ID as the name.\n').or(zod.null()).optional(),
  "entity": zod.string().describe('The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n').or(zod.null()).optional(),
  "tags": zod.array(zod.string()).optional().describe('A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n')
}).describe('The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n')
})])).max(createFineTuningJobResponseIntegrationsMaxOne).describe('A list of integrations to enable for this fine-tuning job.').or(zod.null()).optional(),
  "seed": zod.number().describe('The seed used for the fine-tuning job.'),
  "estimated_finish": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.').or(zod.null()).optional(),
  "method": zod.object({
  "type": zod.enum(['supervised', 'dpo', 'reinforcement']).describe('The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'),
  "supervised": zod.object({
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.')
}).optional().describe('Configuration for the supervised fine-tuning method.'),
  "dpo": zod.object({
  "hyperparameters": zod.object({
  "beta": zod.enum(['auto']).or(zod.number().min(createFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo).max(createFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo)).optional().describe('The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n'),
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the DPO fine-tuning job.')
}).optional().describe('Configuration for the DPO fine-tuning method.'),
  "reinforcement": zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(createFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n'),
  "reasoning_effort": zod.enum(['default', 'low', 'medium', 'high']).optional().describe('Level of reasoning effort.\n'),
  "compute_multiplier": zod.enum(['auto']).or(zod.number().min(createFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo).max(createFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo)).optional().describe('Multiplier on amount of compute used for exploring search space during training.\n'),
  "eval_interval": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('The number of training steps between evaluation runs.\n'),
  "eval_samples": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('Number of evaluation samples to generate per training step.\n')
}).optional().describe('The hyperparameters used for the reinforcement fine-tuning job.')
}).optional().describe('Configuration for the reinforcement fine-tuning method.')
}).optional().describe('The method used for fine-tuning.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).describe('The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n')

/**
 * List your organization's fine-tuning jobs

 * @summary List fine-tuning jobs
 */
export const listPaginatedFineTuningJobsQueryLimitDefault = 20;

export const listPaginatedFineTuningJobsQueryParams = zod.object({
  "after": zod.string().optional().describe('Identifier for the last job from the previous pagination request.'),
  "limit": zod.number().optional().describe('Number of fine-tuning jobs to retrieve.'),
  "metadata": zod.record(zod.string(), zod.string()).nullish().describe('Optional metadata filter. To filter, use the syntax `metadata[k]=v`. Alternatively, set `metadata=null` to indicate no metadata.\n')
})

export const listPaginatedFineTuningJobsResponseDataItemHyperparametersBatchSizeMaxThree = 256;
export const listPaginatedFineTuningJobsResponseDataItemHyperparametersBatchSizeDefaultOne = "auto";export const listPaginatedFineTuningJobsResponseDataItemHyperparametersLearningRateMultiplierMinTwo = 0;
export const listPaginatedFineTuningJobsResponseDataItemHyperparametersNEpochsMaxTwo = 50;
export const listPaginatedFineTuningJobsResponseDataItemHyperparametersNEpochsDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemIntegrationsMaxOne = 5;
export const listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersBatchSizeMaxTwo = 256;
export const listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersBatchSizeDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersLearningRateMultiplierMinTwo = 0;
export const listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersNEpochsMaxTwo = 50;
export const listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersNEpochsDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersBetaMinTwo = 0;
export const listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersBetaMaxTwo = 2;
export const listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersBatchSizeMaxTwo = 256;
export const listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersBatchSizeDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersLearningRateMultiplierMinTwo = 0;
export const listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersNEpochsMaxTwo = 50;
export const listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersNEpochsDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderTypeDefaultOne = "text_similarity";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderSamplingParamsTopPDefaultOne = 1;export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderInputItemContentTypeDefault = "input_text";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderTypeDefaultFour = "multi";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderGradersTypeDefaultOne = "text_similarity";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderGradersSamplingParamsTopPDefaultOne = 1;export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderGradersInputItemContentTypeDefault = "input_text";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementGraderGradersInputItemContentTypeDefaultFour = "input_text";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersBatchSizeMaxTwo = 256;
export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersBatchSizeDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersLearningRateMultiplierMinTwo = 0;
export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersNEpochsMaxTwo = 50;
export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersNEpochsDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersReasoningEffortDefault = "default";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersComputeMultiplierMinTwo = 0.00001;
export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersComputeMultiplierMaxTwo = 10;
export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersEvalIntervalDefault = "auto";export const listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersEvalSamplesDefault = "auto";

export const listPaginatedFineTuningJobsResponse = zod.object({
  "data": zod.array(zod.object({
  "id": zod.string().describe('The object identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was created.'),
  "error": zod.object({
  "code": zod.string().describe('A machine-readable error code.'),
  "message": zod.string().describe('A human-readable error message.'),
  "param": zod.string().describe('The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.').or(zod.null())
}).describe('For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.').or(zod.null()),
  "fine_tuned_model": zod.string().describe('The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "finished_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemHyperparametersBatchSizeMaxThree)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n').or(zod.null()).optional(),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(listPaginatedFineTuningJobsResponseDataItemHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n')
}).describe('The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.'),
  "model": zod.string().describe('The base model that is being fine-tuned.'),
  "object": zod.enum(['fine_tuning.job']).describe('The object type, which is always \"fine_tuning.job\".'),
  "organization_id": zod.string().describe('The organization that owns the fine-tuning job.'),
  "result_files": zod.array(zod.string()).describe('The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "status": zod.enum(['validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled']).describe('The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'),
  "trained_tokens": zod.number().describe('The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "training_file": zod.string().describe('The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "validation_file": zod.string().describe('The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).').or(zod.null()),
  "integrations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['wandb']).describe('The type of the integration being enabled for the fine-tuning job'),
  "wandb": zod.object({
  "project": zod.string().describe('The name of the project that the new run will be created under.\n'),
  "name": zod.string().describe('A display name to set for the run. If not set, we will use the Job ID as the name.\n').or(zod.null()).optional(),
  "entity": zod.string().describe('The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n').or(zod.null()).optional(),
  "tags": zod.array(zod.string()).optional().describe('A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n')
}).describe('The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n')
})])).max(listPaginatedFineTuningJobsResponseDataItemIntegrationsMaxOne).describe('A list of integrations to enable for this fine-tuning job.').or(zod.null()).optional(),
  "seed": zod.number().describe('The seed used for the fine-tuning job.'),
  "estimated_finish": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.').or(zod.null()).optional(),
  "method": zod.object({
  "type": zod.enum(['supervised', 'dpo', 'reinforcement']).describe('The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'),
  "supervised": zod.object({
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemMethodSupervisedHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.')
}).optional().describe('Configuration for the supervised fine-tuning method.'),
  "dpo": zod.object({
  "hyperparameters": zod.object({
  "beta": zod.enum(['auto']).or(zod.number().min(listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersBetaMinTwo).max(listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersBetaMaxTwo)).optional().describe('The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n'),
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemMethodDpoHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the DPO fine-tuning job.')
}).optional().describe('Configuration for the DPO fine-tuning method.'),
  "reinforcement": zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n'),
  "reasoning_effort": zod.enum(['default', 'low', 'medium', 'high']).optional().describe('Level of reasoning effort.\n'),
  "compute_multiplier": zod.enum(['auto']).or(zod.number().min(listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersComputeMultiplierMinTwo).max(listPaginatedFineTuningJobsResponseDataItemMethodReinforcementHyperparametersComputeMultiplierMaxTwo)).optional().describe('Multiplier on amount of compute used for exploring search space during training.\n'),
  "eval_interval": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('The number of training steps between evaluation runs.\n'),
  "eval_samples": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('Number of evaluation samples to generate per training step.\n')
}).optional().describe('The hyperparameters used for the reinforcement fine-tuning job.')
}).optional().describe('Configuration for the reinforcement fine-tuning method.')
}).optional().describe('The method used for fine-tuning.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).describe('The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n')),
  "has_more": zod.boolean(),
  "object": zod.enum(['list'])
})

/**
 * Get info about a fine-tuning job.

[Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)

 * @summary Retrieve fine-tuning job
 */
export const retrieveFineTuningJobParams = zod.object({
  "fine_tuning_job_id": zod.string().describe('The ID of the fine-tuning job.\n')
})

export const retrieveFineTuningJobResponseHyperparametersBatchSizeMaxThree = 256;
export const retrieveFineTuningJobResponseHyperparametersBatchSizeDefaultOne = "auto";export const retrieveFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo = 0;
export const retrieveFineTuningJobResponseHyperparametersNEpochsMaxTwo = 50;
export const retrieveFineTuningJobResponseHyperparametersNEpochsDefault = "auto";export const retrieveFineTuningJobResponseIntegrationsMaxOne = 5;
export const retrieveFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo = 256;
export const retrieveFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeDefault = "auto";export const retrieveFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo = 0;
export const retrieveFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo = 50;
export const retrieveFineTuningJobResponseMethodSupervisedHyperparametersNEpochsDefault = "auto";export const retrieveFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo = 0;
export const retrieveFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo = 2;
export const retrieveFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo = 256;
export const retrieveFineTuningJobResponseMethodDpoHyperparametersBatchSizeDefault = "auto";export const retrieveFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo = 0;
export const retrieveFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo = 50;
export const retrieveFineTuningJobResponseMethodDpoHyperparametersNEpochsDefault = "auto";export const retrieveFineTuningJobResponseMethodReinforcementGraderTypeDefaultOne = "text_similarity";export const retrieveFineTuningJobResponseMethodReinforcementGraderSamplingParamsTopPDefaultOne = 1;export const retrieveFineTuningJobResponseMethodReinforcementGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const retrieveFineTuningJobResponseMethodReinforcementGraderInputItemContentTypeDefault = "input_text";export const retrieveFineTuningJobResponseMethodReinforcementGraderTypeDefaultFour = "multi";export const retrieveFineTuningJobResponseMethodReinforcementGraderGradersTypeDefaultOne = "text_similarity";export const retrieveFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsTopPDefaultOne = 1;export const retrieveFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const retrieveFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefault = "input_text";export const retrieveFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefaultFour = "input_text";export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo = 256;
export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeDefault = "auto";export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo = 0;
export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo = 50;
export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersNEpochsDefault = "auto";export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersReasoningEffortDefault = "default";export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo = 0.00001;
export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo = 10;
export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersEvalIntervalDefault = "auto";export const retrieveFineTuningJobResponseMethodReinforcementHyperparametersEvalSamplesDefault = "auto";

export const retrieveFineTuningJobResponse = zod.object({
  "id": zod.string().describe('The object identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was created.'),
  "error": zod.object({
  "code": zod.string().describe('A machine-readable error code.'),
  "message": zod.string().describe('A human-readable error message.'),
  "param": zod.string().describe('The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.').or(zod.null())
}).describe('For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.').or(zod.null()),
  "fine_tuned_model": zod.string().describe('The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "finished_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseHyperparametersBatchSizeMaxThree)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n').or(zod.null()).optional(),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(retrieveFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n')
}).describe('The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.'),
  "model": zod.string().describe('The base model that is being fine-tuned.'),
  "object": zod.enum(['fine_tuning.job']).describe('The object type, which is always \"fine_tuning.job\".'),
  "organization_id": zod.string().describe('The organization that owns the fine-tuning job.'),
  "result_files": zod.array(zod.string()).describe('The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "status": zod.enum(['validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled']).describe('The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'),
  "trained_tokens": zod.number().describe('The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "training_file": zod.string().describe('The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "validation_file": zod.string().describe('The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).').or(zod.null()),
  "integrations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['wandb']).describe('The type of the integration being enabled for the fine-tuning job'),
  "wandb": zod.object({
  "project": zod.string().describe('The name of the project that the new run will be created under.\n'),
  "name": zod.string().describe('A display name to set for the run. If not set, we will use the Job ID as the name.\n').or(zod.null()).optional(),
  "entity": zod.string().describe('The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n').or(zod.null()).optional(),
  "tags": zod.array(zod.string()).optional().describe('A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n')
}).describe('The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n')
})])).max(retrieveFineTuningJobResponseIntegrationsMaxOne).describe('A list of integrations to enable for this fine-tuning job.').or(zod.null()).optional(),
  "seed": zod.number().describe('The seed used for the fine-tuning job.'),
  "estimated_finish": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.').or(zod.null()).optional(),
  "method": zod.object({
  "type": zod.enum(['supervised', 'dpo', 'reinforcement']).describe('The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'),
  "supervised": zod.object({
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(retrieveFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.')
}).optional().describe('Configuration for the supervised fine-tuning method.'),
  "dpo": zod.object({
  "hyperparameters": zod.object({
  "beta": zod.enum(['auto']).or(zod.number().min(retrieveFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo).max(retrieveFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo)).optional().describe('The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n'),
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(retrieveFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the DPO fine-tuning job.')
}).optional().describe('Configuration for the DPO fine-tuning method.'),
  "reinforcement": zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(retrieveFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(retrieveFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n'),
  "reasoning_effort": zod.enum(['default', 'low', 'medium', 'high']).optional().describe('Level of reasoning effort.\n'),
  "compute_multiplier": zod.enum(['auto']).or(zod.number().min(retrieveFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo).max(retrieveFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo)).optional().describe('Multiplier on amount of compute used for exploring search space during training.\n'),
  "eval_interval": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('The number of training steps between evaluation runs.\n'),
  "eval_samples": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('Number of evaluation samples to generate per training step.\n')
}).optional().describe('The hyperparameters used for the reinforcement fine-tuning job.')
}).optional().describe('Configuration for the reinforcement fine-tuning method.')
}).optional().describe('The method used for fine-tuning.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).describe('The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n')

/**
 * Immediately cancel a fine-tune job.

 * @summary Cancel fine-tuning
 */
export const cancelFineTuningJobParams = zod.object({
  "fine_tuning_job_id": zod.string().describe('The ID of the fine-tuning job to cancel.\n')
})

export const cancelFineTuningJobResponseHyperparametersBatchSizeMaxThree = 256;
export const cancelFineTuningJobResponseHyperparametersBatchSizeDefaultOne = "auto";export const cancelFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo = 0;
export const cancelFineTuningJobResponseHyperparametersNEpochsMaxTwo = 50;
export const cancelFineTuningJobResponseHyperparametersNEpochsDefault = "auto";export const cancelFineTuningJobResponseIntegrationsMaxOne = 5;
export const cancelFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo = 256;
export const cancelFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeDefault = "auto";export const cancelFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo = 0;
export const cancelFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo = 50;
export const cancelFineTuningJobResponseMethodSupervisedHyperparametersNEpochsDefault = "auto";export const cancelFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo = 0;
export const cancelFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo = 2;
export const cancelFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo = 256;
export const cancelFineTuningJobResponseMethodDpoHyperparametersBatchSizeDefault = "auto";export const cancelFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo = 0;
export const cancelFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo = 50;
export const cancelFineTuningJobResponseMethodDpoHyperparametersNEpochsDefault = "auto";export const cancelFineTuningJobResponseMethodReinforcementGraderTypeDefaultOne = "text_similarity";export const cancelFineTuningJobResponseMethodReinforcementGraderSamplingParamsTopPDefaultOne = 1;export const cancelFineTuningJobResponseMethodReinforcementGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const cancelFineTuningJobResponseMethodReinforcementGraderInputItemContentTypeDefault = "input_text";export const cancelFineTuningJobResponseMethodReinforcementGraderTypeDefaultFour = "multi";export const cancelFineTuningJobResponseMethodReinforcementGraderGradersTypeDefaultOne = "text_similarity";export const cancelFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsTopPDefaultOne = 1;export const cancelFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const cancelFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefault = "input_text";export const cancelFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefaultFour = "input_text";export const cancelFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo = 256;
export const cancelFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeDefault = "auto";export const cancelFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo = 0;
export const cancelFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo = 50;
export const cancelFineTuningJobResponseMethodReinforcementHyperparametersNEpochsDefault = "auto";export const cancelFineTuningJobResponseMethodReinforcementHyperparametersReasoningEffortDefault = "default";export const cancelFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo = 0.00001;
export const cancelFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo = 10;
export const cancelFineTuningJobResponseMethodReinforcementHyperparametersEvalIntervalDefault = "auto";export const cancelFineTuningJobResponseMethodReinforcementHyperparametersEvalSamplesDefault = "auto";

export const cancelFineTuningJobResponse = zod.object({
  "id": zod.string().describe('The object identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was created.'),
  "error": zod.object({
  "code": zod.string().describe('A machine-readable error code.'),
  "message": zod.string().describe('A human-readable error message.'),
  "param": zod.string().describe('The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.').or(zod.null())
}).describe('For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.').or(zod.null()),
  "fine_tuned_model": zod.string().describe('The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "finished_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseHyperparametersBatchSizeMaxThree)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n').or(zod.null()).optional(),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(cancelFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n')
}).describe('The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.'),
  "model": zod.string().describe('The base model that is being fine-tuned.'),
  "object": zod.enum(['fine_tuning.job']).describe('The object type, which is always \"fine_tuning.job\".'),
  "organization_id": zod.string().describe('The organization that owns the fine-tuning job.'),
  "result_files": zod.array(zod.string()).describe('The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "status": zod.enum(['validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled']).describe('The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'),
  "trained_tokens": zod.number().describe('The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "training_file": zod.string().describe('The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "validation_file": zod.string().describe('The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).').or(zod.null()),
  "integrations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['wandb']).describe('The type of the integration being enabled for the fine-tuning job'),
  "wandb": zod.object({
  "project": zod.string().describe('The name of the project that the new run will be created under.\n'),
  "name": zod.string().describe('A display name to set for the run. If not set, we will use the Job ID as the name.\n').or(zod.null()).optional(),
  "entity": zod.string().describe('The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n').or(zod.null()).optional(),
  "tags": zod.array(zod.string()).optional().describe('A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n')
}).describe('The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n')
})])).max(cancelFineTuningJobResponseIntegrationsMaxOne).describe('A list of integrations to enable for this fine-tuning job.').or(zod.null()).optional(),
  "seed": zod.number().describe('The seed used for the fine-tuning job.'),
  "estimated_finish": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.').or(zod.null()).optional(),
  "method": zod.object({
  "type": zod.enum(['supervised', 'dpo', 'reinforcement']).describe('The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'),
  "supervised": zod.object({
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(cancelFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.')
}).optional().describe('Configuration for the supervised fine-tuning method.'),
  "dpo": zod.object({
  "hyperparameters": zod.object({
  "beta": zod.enum(['auto']).or(zod.number().min(cancelFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo).max(cancelFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo)).optional().describe('The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n'),
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(cancelFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the DPO fine-tuning job.')
}).optional().describe('Configuration for the DPO fine-tuning method.'),
  "reinforcement": zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(cancelFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(cancelFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n'),
  "reasoning_effort": zod.enum(['default', 'low', 'medium', 'high']).optional().describe('Level of reasoning effort.\n'),
  "compute_multiplier": zod.enum(['auto']).or(zod.number().min(cancelFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo).max(cancelFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo)).optional().describe('Multiplier on amount of compute used for exploring search space during training.\n'),
  "eval_interval": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('The number of training steps between evaluation runs.\n'),
  "eval_samples": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('Number of evaluation samples to generate per training step.\n')
}).optional().describe('The hyperparameters used for the reinforcement fine-tuning job.')
}).optional().describe('Configuration for the reinforcement fine-tuning method.')
}).optional().describe('The method used for fine-tuning.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).describe('The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n')

/**
 * List checkpoints for a fine-tuning job.

 * @summary List fine-tuning checkpoints
 */
export const listFineTuningJobCheckpointsParams = zod.object({
  "fine_tuning_job_id": zod.string().describe('The ID of the fine-tuning job to get checkpoints for.\n')
})

export const listFineTuningJobCheckpointsQueryLimitDefault = 10;

export const listFineTuningJobCheckpointsQueryParams = zod.object({
  "after": zod.string().optional().describe('Identifier for the last checkpoint ID from the previous pagination request.'),
  "limit": zod.number().optional().describe('Number of checkpoints to retrieve.')
})

export const listFineTuningJobCheckpointsResponse = zod.object({
  "data": zod.array(zod.object({
  "id": zod.string().describe('The checkpoint identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the checkpoint was created.'),
  "fine_tuned_model_checkpoint": zod.string().describe('The name of the fine-tuned checkpoint model that is created.'),
  "step_number": zod.number().describe('The step number that the checkpoint was created at.'),
  "metrics": zod.object({
  "step": zod.number().optional(),
  "train_loss": zod.number().optional(),
  "train_mean_token_accuracy": zod.number().optional(),
  "valid_loss": zod.number().optional(),
  "valid_mean_token_accuracy": zod.number().optional(),
  "full_valid_loss": zod.number().optional(),
  "full_valid_mean_token_accuracy": zod.number().optional()
}).describe('Metrics at the step number during the fine-tuning job.'),
  "fine_tuning_job_id": zod.string().describe('The name of the fine-tuning job that this checkpoint was created from.'),
  "object": zod.enum(['fine_tuning.job.checkpoint']).describe('The object type, which is always \"fine_tuning.job.checkpoint\".')
}).describe('The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.\n')),
  "object": zod.enum(['list']),
  "first_id": zod.string().or(zod.null()).optional(),
  "last_id": zod.string().or(zod.null()).optional(),
  "has_more": zod.boolean()
})

/**
 * Get status updates for a fine-tuning job.

 * @summary List fine-tuning events
 */
export const listFineTuningEventsParams = zod.object({
  "fine_tuning_job_id": zod.string().describe('The ID of the fine-tuning job to get events for.\n')
})

export const listFineTuningEventsQueryLimitDefault = 20;

export const listFineTuningEventsQueryParams = zod.object({
  "after": zod.string().optional().describe('Identifier for the last event from the previous pagination request.'),
  "limit": zod.number().optional().describe('Number of events to retrieve.')
})

export const listFineTuningEventsResponse = zod.object({
  "data": zod.array(zod.object({
  "object": zod.enum(['fine_tuning.job.event']).describe('The object type, which is always \"fine_tuning.job.event\".'),
  "id": zod.string().describe('The object identifier.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was created.'),
  "level": zod.enum(['info', 'warn', 'error']).describe('The log level of the event.'),
  "message": zod.string().describe('The message of the event.'),
  "type": zod.enum(['message', 'metrics']).optional().describe('The type of event.'),
  "data": zod.object({

}).optional().describe('The data associated with the event.')
}).describe('Fine-tuning job event object')),
  "object": zod.enum(['list']),
  "has_more": zod.boolean()
})

/**
 * Pause a fine-tune job.

 * @summary Pause fine-tuning
 */
export const pauseFineTuningJobParams = zod.object({
  "fine_tuning_job_id": zod.string().describe('The ID of the fine-tuning job to pause.\n')
})

export const pauseFineTuningJobResponseHyperparametersBatchSizeMaxThree = 256;
export const pauseFineTuningJobResponseHyperparametersBatchSizeDefaultOne = "auto";export const pauseFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo = 0;
export const pauseFineTuningJobResponseHyperparametersNEpochsMaxTwo = 50;
export const pauseFineTuningJobResponseHyperparametersNEpochsDefault = "auto";export const pauseFineTuningJobResponseIntegrationsMaxOne = 5;
export const pauseFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo = 256;
export const pauseFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeDefault = "auto";export const pauseFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo = 0;
export const pauseFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo = 50;
export const pauseFineTuningJobResponseMethodSupervisedHyperparametersNEpochsDefault = "auto";export const pauseFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo = 0;
export const pauseFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo = 2;
export const pauseFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo = 256;
export const pauseFineTuningJobResponseMethodDpoHyperparametersBatchSizeDefault = "auto";export const pauseFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo = 0;
export const pauseFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo = 50;
export const pauseFineTuningJobResponseMethodDpoHyperparametersNEpochsDefault = "auto";export const pauseFineTuningJobResponseMethodReinforcementGraderTypeDefaultOne = "text_similarity";export const pauseFineTuningJobResponseMethodReinforcementGraderSamplingParamsTopPDefaultOne = 1;export const pauseFineTuningJobResponseMethodReinforcementGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const pauseFineTuningJobResponseMethodReinforcementGraderInputItemContentTypeDefault = "input_text";export const pauseFineTuningJobResponseMethodReinforcementGraderTypeDefaultFour = "multi";export const pauseFineTuningJobResponseMethodReinforcementGraderGradersTypeDefaultOne = "text_similarity";export const pauseFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsTopPDefaultOne = 1;export const pauseFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const pauseFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefault = "input_text";export const pauseFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefaultFour = "input_text";export const pauseFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo = 256;
export const pauseFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeDefault = "auto";export const pauseFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo = 0;
export const pauseFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo = 50;
export const pauseFineTuningJobResponseMethodReinforcementHyperparametersNEpochsDefault = "auto";export const pauseFineTuningJobResponseMethodReinforcementHyperparametersReasoningEffortDefault = "default";export const pauseFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo = 0.00001;
export const pauseFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo = 10;
export const pauseFineTuningJobResponseMethodReinforcementHyperparametersEvalIntervalDefault = "auto";export const pauseFineTuningJobResponseMethodReinforcementHyperparametersEvalSamplesDefault = "auto";

export const pauseFineTuningJobResponse = zod.object({
  "id": zod.string().describe('The object identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was created.'),
  "error": zod.object({
  "code": zod.string().describe('A machine-readable error code.'),
  "message": zod.string().describe('A human-readable error message.'),
  "param": zod.string().describe('The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.').or(zod.null())
}).describe('For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.').or(zod.null()),
  "fine_tuned_model": zod.string().describe('The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "finished_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseHyperparametersBatchSizeMaxThree)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n').or(zod.null()).optional(),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(pauseFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n')
}).describe('The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.'),
  "model": zod.string().describe('The base model that is being fine-tuned.'),
  "object": zod.enum(['fine_tuning.job']).describe('The object type, which is always \"fine_tuning.job\".'),
  "organization_id": zod.string().describe('The organization that owns the fine-tuning job.'),
  "result_files": zod.array(zod.string()).describe('The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "status": zod.enum(['validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled']).describe('The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'),
  "trained_tokens": zod.number().describe('The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "training_file": zod.string().describe('The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "validation_file": zod.string().describe('The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).').or(zod.null()),
  "integrations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['wandb']).describe('The type of the integration being enabled for the fine-tuning job'),
  "wandb": zod.object({
  "project": zod.string().describe('The name of the project that the new run will be created under.\n'),
  "name": zod.string().describe('A display name to set for the run. If not set, we will use the Job ID as the name.\n').or(zod.null()).optional(),
  "entity": zod.string().describe('The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n').or(zod.null()).optional(),
  "tags": zod.array(zod.string()).optional().describe('A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n')
}).describe('The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n')
})])).max(pauseFineTuningJobResponseIntegrationsMaxOne).describe('A list of integrations to enable for this fine-tuning job.').or(zod.null()).optional(),
  "seed": zod.number().describe('The seed used for the fine-tuning job.'),
  "estimated_finish": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.').or(zod.null()).optional(),
  "method": zod.object({
  "type": zod.enum(['supervised', 'dpo', 'reinforcement']).describe('The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'),
  "supervised": zod.object({
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(pauseFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.')
}).optional().describe('Configuration for the supervised fine-tuning method.'),
  "dpo": zod.object({
  "hyperparameters": zod.object({
  "beta": zod.enum(['auto']).or(zod.number().min(pauseFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo).max(pauseFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo)).optional().describe('The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n'),
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(pauseFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the DPO fine-tuning job.')
}).optional().describe('Configuration for the DPO fine-tuning method.'),
  "reinforcement": zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(pauseFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(pauseFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n'),
  "reasoning_effort": zod.enum(['default', 'low', 'medium', 'high']).optional().describe('Level of reasoning effort.\n'),
  "compute_multiplier": zod.enum(['auto']).or(zod.number().min(pauseFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo).max(pauseFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo)).optional().describe('Multiplier on amount of compute used for exploring search space during training.\n'),
  "eval_interval": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('The number of training steps between evaluation runs.\n'),
  "eval_samples": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('Number of evaluation samples to generate per training step.\n')
}).optional().describe('The hyperparameters used for the reinforcement fine-tuning job.')
}).optional().describe('Configuration for the reinforcement fine-tuning method.')
}).optional().describe('The method used for fine-tuning.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).describe('The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n')

/**
 * Resume a fine-tune job.

 * @summary Resume fine-tuning
 */
export const resumeFineTuningJobParams = zod.object({
  "fine_tuning_job_id": zod.string().describe('The ID of the fine-tuning job to resume.\n')
})

export const resumeFineTuningJobResponseHyperparametersBatchSizeMaxThree = 256;
export const resumeFineTuningJobResponseHyperparametersBatchSizeDefaultOne = "auto";export const resumeFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo = 0;
export const resumeFineTuningJobResponseHyperparametersNEpochsMaxTwo = 50;
export const resumeFineTuningJobResponseHyperparametersNEpochsDefault = "auto";export const resumeFineTuningJobResponseIntegrationsMaxOne = 5;
export const resumeFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo = 256;
export const resumeFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeDefault = "auto";export const resumeFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo = 0;
export const resumeFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo = 50;
export const resumeFineTuningJobResponseMethodSupervisedHyperparametersNEpochsDefault = "auto";export const resumeFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo = 0;
export const resumeFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo = 2;
export const resumeFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo = 256;
export const resumeFineTuningJobResponseMethodDpoHyperparametersBatchSizeDefault = "auto";export const resumeFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo = 0;
export const resumeFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo = 50;
export const resumeFineTuningJobResponseMethodDpoHyperparametersNEpochsDefault = "auto";export const resumeFineTuningJobResponseMethodReinforcementGraderTypeDefaultOne = "text_similarity";export const resumeFineTuningJobResponseMethodReinforcementGraderSamplingParamsTopPDefaultOne = 1;export const resumeFineTuningJobResponseMethodReinforcementGraderSamplingParamsReasoningEffortDefaultOne = "medium";export const resumeFineTuningJobResponseMethodReinforcementGraderInputItemContentTypeDefault = "input_text";export const resumeFineTuningJobResponseMethodReinforcementGraderTypeDefaultFour = "multi";export const resumeFineTuningJobResponseMethodReinforcementGraderGradersTypeDefaultOne = "text_similarity";export const resumeFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsTopPDefaultOne = 1;export const resumeFineTuningJobResponseMethodReinforcementGraderGradersSamplingParamsReasoningEffortDefaultOne = "medium";export const resumeFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefault = "input_text";export const resumeFineTuningJobResponseMethodReinforcementGraderGradersInputItemContentTypeDefaultFour = "input_text";export const resumeFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo = 256;
export const resumeFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeDefault = "auto";export const resumeFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo = 0;
export const resumeFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo = 50;
export const resumeFineTuningJobResponseMethodReinforcementHyperparametersNEpochsDefault = "auto";export const resumeFineTuningJobResponseMethodReinforcementHyperparametersReasoningEffortDefault = "default";export const resumeFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo = 0.00001;
export const resumeFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo = 10;
export const resumeFineTuningJobResponseMethodReinforcementHyperparametersEvalIntervalDefault = "auto";export const resumeFineTuningJobResponseMethodReinforcementHyperparametersEvalSamplesDefault = "auto";

export const resumeFineTuningJobResponse = zod.object({
  "id": zod.string().describe('The object identifier, which can be referenced in the API endpoints.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was created.'),
  "error": zod.object({
  "code": zod.string().describe('A machine-readable error code.'),
  "message": zod.string().describe('A human-readable error message.'),
  "param": zod.string().describe('The parameter that was invalid, usually `training_file` or `validation_file`. This field will be null if the failure was not parameter-specific.').or(zod.null())
}).describe('For fine-tuning jobs that have `failed`, this will contain more information on the cause of the failure.').or(zod.null()),
  "fine_tuned_model": zod.string().describe('The name of the fine-tuned model that is being created. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "finished_at": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job was finished. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseHyperparametersBatchSizeMaxThree)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters\nare updated less frequently, but with lower variance.\n').or(zod.null()).optional(),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(resumeFineTuningJobResponseHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid\noverfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle\nthrough the training dataset.\n')
}).describe('The hyperparameters used for the fine-tuning job. This value will only be returned when running `supervised` jobs.'),
  "model": zod.string().describe('The base model that is being fine-tuned.'),
  "object": zod.enum(['fine_tuning.job']).describe('The object type, which is always \"fine_tuning.job\".'),
  "organization_id": zod.string().describe('The organization that owns the fine-tuning job.'),
  "result_files": zod.array(zod.string()).describe('The compiled results file ID(s) for the fine-tuning job. You can retrieve the results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "status": zod.enum(['validating_files', 'queued', 'running', 'succeeded', 'failed', 'cancelled']).describe('The current status of the fine-tuning job, which can be either `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.'),
  "trained_tokens": zod.number().describe('The total number of billable tokens processed by this fine-tuning job. The value will be null if the fine-tuning job is still running.').or(zod.null()),
  "training_file": zod.string().describe('The file ID used for training. You can retrieve the training data with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).'),
  "validation_file": zod.string().describe('The file ID used for validation. You can retrieve the validation results with the [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).').or(zod.null()),
  "integrations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['wandb']).describe('The type of the integration being enabled for the fine-tuning job'),
  "wandb": zod.object({
  "project": zod.string().describe('The name of the project that the new run will be created under.\n'),
  "name": zod.string().describe('A display name to set for the run. If not set, we will use the Job ID as the name.\n').or(zod.null()).optional(),
  "entity": zod.string().describe('The entity to use for the run. This allows you to set the team or username of the WandB user that you would\nlike associated with the run. If not set, the default entity for the registered WandB API key is used.\n').or(zod.null()).optional(),
  "tags": zod.array(zod.string()).optional().describe('A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some\ndefault tags are generated by OpenAI: \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n')
}).describe('The settings for your integration with Weights and Biases. This payload specifies the project that\nmetrics will be sent to. Optionally, you can set an explicit display name for your run, add tags\nto your run, and set a default entity (team, username, etc) to be associated with your run.\n')
})])).max(resumeFineTuningJobResponseIntegrationsMaxOne).describe('A list of integrations to enable for this fine-tuning job.').or(zod.null()).optional(),
  "seed": zod.number().describe('The seed used for the fine-tuning job.'),
  "estimated_finish": zod.number().describe('The Unix timestamp (in seconds) for when the fine-tuning job is estimated to finish. The value will be null if the fine-tuning job is not running.').or(zod.null()).optional(),
  "method": zod.object({
  "type": zod.enum(['supervised', 'dpo', 'reinforcement']).describe('The type of method. Is either `supervised`, `dpo`, or `reinforcement`.'),
  "supervised": zod.object({
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseMethodSupervisedHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(resumeFineTuningJobResponseMethodSupervisedHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseMethodSupervisedHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the fine-tuning job.')
}).optional().describe('Configuration for the supervised fine-tuning method.'),
  "dpo": zod.object({
  "hyperparameters": zod.object({
  "beta": zod.enum(['auto']).or(zod.number().min(resumeFineTuningJobResponseMethodDpoHyperparametersBetaMinTwo).max(resumeFineTuningJobResponseMethodDpoHyperparametersBetaMaxTwo)).optional().describe('The beta value for the DPO method. A higher beta value will increase the weight of the penalty between the policy and reference model.\n'),
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseMethodDpoHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(resumeFineTuningJobResponseMethodDpoHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseMethodDpoHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n')
}).optional().describe('The hyperparameters used for the DPO fine-tuning job.')
}).optional().describe('Configuration for the DPO fine-tuning method.'),
  "reinforcement": zod.object({
  "grader": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['multi']).optional().describe('The object type, which is always `multi`.'),
  "name": zod.string().describe('The name of the grader.'),
  "graders": zod.object({
  "type": zod.enum(['string_check']).describe('The object type, which is always `string_check`.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The input text. This may include template strings.'),
  "reference": zod.string().describe('The reference text. This may include template strings.'),
  "operation": zod.enum(['eq', 'ne', 'like', 'ilike']).describe('The string check operation to perform. One of `eq`, `ne`, `like`, or `ilike`.')
}).describe('A StringCheckGrader object that performs a string comparison between input and reference using a specified operation.\n').or(zod.object({
  "type": zod.enum(['text_similarity']).optional().describe('The type of grader.'),
  "name": zod.string().describe('The name of the grader.'),
  "input": zod.string().describe('The text being graded.'),
  "reference": zod.string().describe('The text being graded against.'),
  "evaluation_metric": zod.enum(['cosine', 'fuzzy_match', 'bleu', 'gleu', 'meteor', 'rouge_1', 'rouge_2', 'rouge_3', 'rouge_4', 'rouge_5', 'rouge_l']).describe('The evaluation metric to use. One of `cosine`, `fuzzy_match`, `bleu`,\n`gleu`, `meteor`, `rouge_1`, `rouge_2`, `rouge_3`, `rouge_4`, `rouge_5`,\nor `rouge_l`.\n')
}).describe('A TextSimilarityGrader object which grades text based on similarity metrics.\n')).or(zod.object({
  "type": zod.enum(['python']).describe('The object type, which is always `python`.'),
  "name": zod.string().describe('The name of the grader.'),
  "source": zod.string().describe('The source code of the python script.'),
  "image_tag": zod.string().optional().describe('The image tag to use for the python script.')
}).describe('A PythonGrader object that runs a python script on the input.\n')).or(zod.object({
  "type": zod.enum(['score_model']).describe('The object type, which is always `score_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation.'),
  "sampling_params": zod.object({
  "seed": zod.number().describe('A seed value to initialize the randomness, during sampling.\n').or(zod.null()).optional(),
  "top_p": zod.number().optional().describe('An alternative to temperature for nucleus sampling; 1.0 includes all tokens.\n').or(zod.null()).optional(),
  "temperature": zod.number().describe('A higher temperature increases randomness in the outputs.\n').or(zod.null()).optional(),
  "max_completions_tokens": zod.number().min(1).describe('The maximum number of tokens the grader model may generate in its response.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional()
}).optional().describe('The sampling parameters for the model.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')).describe('The input text. This may include template strings.'),
  "range": zod.array(zod.number()).optional().describe('The range of the score. Defaults to `[0, 1]`.')
}).describe('A ScoreModelGrader object that uses a model to assign a score to the input.\n')).or(zod.object({
  "type": zod.enum(['label_model']).describe('The object type, which is always `label_model`.'),
  "name": zod.string().describe('The name of the grader.'),
  "model": zod.string().describe('The model to use for the evaluation. Must support structured outputs.'),
  "input": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['output_text']).describe('The type of the output text. Always `output_text`.\n'),
  "text": zod.string().describe('The text output from the model.\n')
}).describe('A text output from the model.\n')).or(zod.object({
  "type": zod.enum(['input_image']).describe('The type of the image input. Always `input_image`.\n'),
  "image_url": zod.string().describe('The URL of the image input.\n'),
  "detail": zod.string().optional().describe('The detail level of the image to be sent to the model. One of `high`, `low`, or `auto`. Defaults to `auto`.\n')
}).describe('An image input to the model.\n')).or(zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')).or(zod.array().describe('A list of inputs, each of which may be either an input text, input image, or input audio object.\n')).describe('Inputs to the model - can contain template strings.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n')),
  "labels": zod.array(zod.string()).describe('The labels to assign to each item in the evaluation.'),
  "passing_labels": zod.array(zod.string()).describe('The labels that indicate a passing result. Must be a subset of labels.')
}).describe('A LabelModelGrader object which uses a model to assign labels to each item\nin the evaluation.\n')),
  "calculate_output": zod.string().describe('A formula to calculate the output based on grader results.')
}).describe('A MultiGrader object combines the output of multiple graders to produce a single score.')).describe('The grader used for the fine-tuning job.'),
  "hyperparameters": zod.object({
  "batch_size": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseMethodReinforcementHyperparametersBatchSizeMaxTwo)).optional().describe('Number of examples in each batch. A larger batch size means that model parameters are updated less frequently, but with lower variance.\n'),
  "learning_rate_multiplier": zod.enum(['auto']).or(zod.number().min(resumeFineTuningJobResponseMethodReinforcementHyperparametersLearningRateMultiplierMinTwo)).optional().describe('Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.\n'),
  "n_epochs": zod.enum(['auto']).or(zod.number().min(1).max(resumeFineTuningJobResponseMethodReinforcementHyperparametersNEpochsMaxTwo)).optional().describe('The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n'),
  "reasoning_effort": zod.enum(['default', 'low', 'medium', 'high']).optional().describe('Level of reasoning effort.\n'),
  "compute_multiplier": zod.enum(['auto']).or(zod.number().min(resumeFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMinTwo).max(resumeFineTuningJobResponseMethodReinforcementHyperparametersComputeMultiplierMaxTwo)).optional().describe('Multiplier on amount of compute used for exploring search space during training.\n'),
  "eval_interval": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('The number of training steps between evaluation runs.\n'),
  "eval_samples": zod.enum(['auto']).or(zod.number().min(1)).optional().describe('Number of evaluation samples to generate per training step.\n')
}).optional().describe('The hyperparameters used for the reinforcement fine-tuning job.')
}).optional().describe('Configuration for the reinforcement fine-tuning method.')
}).optional().describe('The method used for fine-tuning.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).describe('The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.\n')

