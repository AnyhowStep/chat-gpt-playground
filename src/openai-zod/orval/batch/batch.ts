/**
 * Generated by orval v7.7.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import {
  z as zod
} from 'zod';


/**
 * Creates and executes a batch from an uploaded file of requests
 * @summary Create batch
 */
export const createBatchBodyOutputExpiresAfterSecondsMin = 3600;

export const createBatchBodyOutputExpiresAfterSecondsMax = 2592000;


export const createBatchBody = zod.object({
  "input_file_id": zod.string().describe('The ID of an uploaded file that contains requests for the new batch.\n\nSee [upload file](https://platform.openai.com/docs/api-reference/files/create) for how to upload a file.\n\nYour input file must be formatted as a [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input), and must be uploaded with the purpose `batch`. The file can contain up to 50,000 requests, and can be up to 200 MB in size.\n'),
  "endpoint": zod.enum(['/v1/responses', '/v1/chat/completions', '/v1/embeddings', '/v1/completions']).describe('The endpoint to be used for all requests in the batch. Currently `/v1/responses`, `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported. Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000 embedding inputs across all requests in the batch.'),
  "completion_window": zod.enum(['24h']).describe('The time frame within which the batch should be processed. Currently only `24h` is supported.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "output_expires_after": zod.object({
  "anchor": zod.enum(['created_at']).describe('Anchor timestamp after which the expiration policy applies. Supported anchors: `created_at`. Note that the anchor is the file creation time, not the time the batch is created.'),
  "seconds": zod.number().min(createBatchBodyOutputExpiresAfterSecondsMin).max(createBatchBodyOutputExpiresAfterSecondsMax).describe('The number of seconds after the anchor time that the file will expire. Must be between 3600 (1 hour) and 2592000 (30 days).')
}).optional().describe('The expiration policy for the output and/or error file that are generated for a batch.')
})

export const createBatchResponse = zod.object({
  "id": zod.string(),
  "object": zod.enum(['batch']).describe('The object type, which is always `batch`.'),
  "endpoint": zod.string().describe('The OpenAI API endpoint used by the batch.'),
  "model": zod.string().optional().describe('Model ID used to process the batch, like `gpt-5-2025-08-07`. OpenAI\noffers a wide range of models with different capabilities, performance\ncharacteristics, and price points. Refer to the [model\nguide](https://platform.openai.com/docs/models) to browse and compare available models.\n'),
  "errors": zod.object({
  "object": zod.string().optional().describe('The object type, which is always `list`.'),
  "data": zod.array(zod.object({
  "code": zod.string().optional().describe('An error code identifying the error type.'),
  "message": zod.string().optional().describe('A human-readable message providing more details about the error.'),
  "param": zod.string().describe('The name of the parameter that caused the error, if applicable.').or(zod.null()).optional(),
  "line": zod.number().describe('The line number of the input file where the error occurred, if applicable.').or(zod.null()).optional()
})).optional()
}).optional(),
  "input_file_id": zod.string().describe('The ID of the input file for the batch.'),
  "completion_window": zod.string().describe('The time frame within which the batch should be processed.'),
  "status": zod.enum(['validating', 'failed', 'in_progress', 'finalizing', 'completed', 'expired', 'cancelling', 'cancelled']).describe('The current status of the batch.'),
  "output_file_id": zod.string().optional().describe('The ID of the file containing the outputs of successfully executed requests.'),
  "error_file_id": zod.string().optional().describe('The ID of the file containing the outputs of requests with errors.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the batch was created.'),
  "in_progress_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started processing.'),
  "expires_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch will expire.'),
  "finalizing_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started finalizing.'),
  "completed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was completed.'),
  "failed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch failed.'),
  "expired_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch expired.'),
  "cancelling_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started cancelling.'),
  "cancelled_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was cancelled.'),
  "request_counts": zod.object({
  "total": zod.number().describe('Total number of requests in the batch.'),
  "completed": zod.number().describe('Number of requests that have been completed successfully.'),
  "failed": zod.number().describe('Number of requests that have failed.')
}).optional().describe('The request counts for different statuses within the batch.'),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of input tokens.'),
  "input_tokens_details": zod.object({
  "cached_tokens": zod.number().describe('The number of tokens that were retrieved from the cache. [More on\nprompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n')
}).describe('A detailed breakdown of the input tokens.'),
  "output_tokens": zod.number().describe('The number of output tokens.'),
  "output_tokens_details": zod.object({
  "reasoning_tokens": zod.number().describe('The number of reasoning tokens.')
}).describe('A detailed breakdown of the output tokens.'),
  "total_tokens": zod.number().describe('The total number of tokens used.')
}).optional().describe('Represents token usage details including input tokens, output tokens, a\nbreakdown of output tokens, and the total tokens used. Only populated on\nbatches created after September 7, 2025.\n'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

/**
 * List your organization's batches.
 * @summary List batch
 */
export const listBatchesQueryLimitDefault = 20;

export const listBatchesQueryParams = zod.object({
  "after": zod.string().optional().describe('A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n'),
  "limit": zod.number().optional().describe('A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n')
})

export const listBatchesResponse = zod.object({
  "data": zod.array(zod.object({
  "id": zod.string(),
  "object": zod.enum(['batch']).describe('The object type, which is always `batch`.'),
  "endpoint": zod.string().describe('The OpenAI API endpoint used by the batch.'),
  "model": zod.string().optional().describe('Model ID used to process the batch, like `gpt-5-2025-08-07`. OpenAI\noffers a wide range of models with different capabilities, performance\ncharacteristics, and price points. Refer to the [model\nguide](https://platform.openai.com/docs/models) to browse and compare available models.\n'),
  "errors": zod.object({
  "object": zod.string().optional().describe('The object type, which is always `list`.'),
  "data": zod.array(zod.object({
  "code": zod.string().optional().describe('An error code identifying the error type.'),
  "message": zod.string().optional().describe('A human-readable message providing more details about the error.'),
  "param": zod.string().describe('The name of the parameter that caused the error, if applicable.').or(zod.null()).optional(),
  "line": zod.number().describe('The line number of the input file where the error occurred, if applicable.').or(zod.null()).optional()
})).optional()
}).optional(),
  "input_file_id": zod.string().describe('The ID of the input file for the batch.'),
  "completion_window": zod.string().describe('The time frame within which the batch should be processed.'),
  "status": zod.enum(['validating', 'failed', 'in_progress', 'finalizing', 'completed', 'expired', 'cancelling', 'cancelled']).describe('The current status of the batch.'),
  "output_file_id": zod.string().optional().describe('The ID of the file containing the outputs of successfully executed requests.'),
  "error_file_id": zod.string().optional().describe('The ID of the file containing the outputs of requests with errors.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the batch was created.'),
  "in_progress_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started processing.'),
  "expires_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch will expire.'),
  "finalizing_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started finalizing.'),
  "completed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was completed.'),
  "failed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch failed.'),
  "expired_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch expired.'),
  "cancelling_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started cancelling.'),
  "cancelled_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was cancelled.'),
  "request_counts": zod.object({
  "total": zod.number().describe('Total number of requests in the batch.'),
  "completed": zod.number().describe('Number of requests that have been completed successfully.'),
  "failed": zod.number().describe('Number of requests that have failed.')
}).optional().describe('The request counts for different statuses within the batch.'),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of input tokens.'),
  "input_tokens_details": zod.object({
  "cached_tokens": zod.number().describe('The number of tokens that were retrieved from the cache. [More on\nprompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n')
}).describe('A detailed breakdown of the input tokens.'),
  "output_tokens": zod.number().describe('The number of output tokens.'),
  "output_tokens_details": zod.object({
  "reasoning_tokens": zod.number().describe('The number of reasoning tokens.')
}).describe('A detailed breakdown of the output tokens.'),
  "total_tokens": zod.number().describe('The total number of tokens used.')
}).optional().describe('Represents token usage details including input tokens, output tokens, a\nbreakdown of output tokens, and the total tokens used. Only populated on\nbatches created after September 7, 2025.\n'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})),
  "first_id": zod.string().optional(),
  "last_id": zod.string().optional(),
  "has_more": zod.boolean(),
  "object": zod.enum(['list'])
})

/**
 * Retrieves a batch.
 * @summary Retrieve batch
 */
export const retrieveBatchParams = zod.object({
  "batch_id": zod.string().describe('The ID of the batch to retrieve.')
})

export const retrieveBatchResponse = zod.object({
  "id": zod.string(),
  "object": zod.enum(['batch']).describe('The object type, which is always `batch`.'),
  "endpoint": zod.string().describe('The OpenAI API endpoint used by the batch.'),
  "model": zod.string().optional().describe('Model ID used to process the batch, like `gpt-5-2025-08-07`. OpenAI\noffers a wide range of models with different capabilities, performance\ncharacteristics, and price points. Refer to the [model\nguide](https://platform.openai.com/docs/models) to browse and compare available models.\n'),
  "errors": zod.object({
  "object": zod.string().optional().describe('The object type, which is always `list`.'),
  "data": zod.array(zod.object({
  "code": zod.string().optional().describe('An error code identifying the error type.'),
  "message": zod.string().optional().describe('A human-readable message providing more details about the error.'),
  "param": zod.string().describe('The name of the parameter that caused the error, if applicable.').or(zod.null()).optional(),
  "line": zod.number().describe('The line number of the input file where the error occurred, if applicable.').or(zod.null()).optional()
})).optional()
}).optional(),
  "input_file_id": zod.string().describe('The ID of the input file for the batch.'),
  "completion_window": zod.string().describe('The time frame within which the batch should be processed.'),
  "status": zod.enum(['validating', 'failed', 'in_progress', 'finalizing', 'completed', 'expired', 'cancelling', 'cancelled']).describe('The current status of the batch.'),
  "output_file_id": zod.string().optional().describe('The ID of the file containing the outputs of successfully executed requests.'),
  "error_file_id": zod.string().optional().describe('The ID of the file containing the outputs of requests with errors.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the batch was created.'),
  "in_progress_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started processing.'),
  "expires_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch will expire.'),
  "finalizing_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started finalizing.'),
  "completed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was completed.'),
  "failed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch failed.'),
  "expired_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch expired.'),
  "cancelling_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started cancelling.'),
  "cancelled_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was cancelled.'),
  "request_counts": zod.object({
  "total": zod.number().describe('Total number of requests in the batch.'),
  "completed": zod.number().describe('Number of requests that have been completed successfully.'),
  "failed": zod.number().describe('Number of requests that have failed.')
}).optional().describe('The request counts for different statuses within the batch.'),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of input tokens.'),
  "input_tokens_details": zod.object({
  "cached_tokens": zod.number().describe('The number of tokens that were retrieved from the cache. [More on\nprompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n')
}).describe('A detailed breakdown of the input tokens.'),
  "output_tokens": zod.number().describe('The number of output tokens.'),
  "output_tokens_details": zod.object({
  "reasoning_tokens": zod.number().describe('The number of reasoning tokens.')
}).describe('A detailed breakdown of the output tokens.'),
  "total_tokens": zod.number().describe('The total number of tokens used.')
}).optional().describe('Represents token usage details including input tokens, output tokens, a\nbreakdown of output tokens, and the total tokens used. Only populated on\nbatches created after September 7, 2025.\n'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

/**
 * Cancels an in-progress batch. The batch will be in status `cancelling` for up to 10 minutes, before changing to `cancelled`, where it will have partial results (if any) available in the output file.
 * @summary Cancel batch
 */
export const cancelBatchParams = zod.object({
  "batch_id": zod.string().describe('The ID of the batch to cancel.')
})

export const cancelBatchResponse = zod.object({
  "id": zod.string(),
  "object": zod.enum(['batch']).describe('The object type, which is always `batch`.'),
  "endpoint": zod.string().describe('The OpenAI API endpoint used by the batch.'),
  "model": zod.string().optional().describe('Model ID used to process the batch, like `gpt-5-2025-08-07`. OpenAI\noffers a wide range of models with different capabilities, performance\ncharacteristics, and price points. Refer to the [model\nguide](https://platform.openai.com/docs/models) to browse and compare available models.\n'),
  "errors": zod.object({
  "object": zod.string().optional().describe('The object type, which is always `list`.'),
  "data": zod.array(zod.object({
  "code": zod.string().optional().describe('An error code identifying the error type.'),
  "message": zod.string().optional().describe('A human-readable message providing more details about the error.'),
  "param": zod.string().describe('The name of the parameter that caused the error, if applicable.').or(zod.null()).optional(),
  "line": zod.number().describe('The line number of the input file where the error occurred, if applicable.').or(zod.null()).optional()
})).optional()
}).optional(),
  "input_file_id": zod.string().describe('The ID of the input file for the batch.'),
  "completion_window": zod.string().describe('The time frame within which the batch should be processed.'),
  "status": zod.enum(['validating', 'failed', 'in_progress', 'finalizing', 'completed', 'expired', 'cancelling', 'cancelled']).describe('The current status of the batch.'),
  "output_file_id": zod.string().optional().describe('The ID of the file containing the outputs of successfully executed requests.'),
  "error_file_id": zod.string().optional().describe('The ID of the file containing the outputs of requests with errors.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the batch was created.'),
  "in_progress_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started processing.'),
  "expires_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch will expire.'),
  "finalizing_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started finalizing.'),
  "completed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was completed.'),
  "failed_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch failed.'),
  "expired_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch expired.'),
  "cancelling_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch started cancelling.'),
  "cancelled_at": zod.number().optional().describe('The Unix timestamp (in seconds) for when the batch was cancelled.'),
  "request_counts": zod.object({
  "total": zod.number().describe('Total number of requests in the batch.'),
  "completed": zod.number().describe('Number of requests that have been completed successfully.'),
  "failed": zod.number().describe('Number of requests that have failed.')
}).optional().describe('The request counts for different statuses within the batch.'),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of input tokens.'),
  "input_tokens_details": zod.object({
  "cached_tokens": zod.number().describe('The number of tokens that were retrieved from the cache. [More on\nprompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n')
}).describe('A detailed breakdown of the input tokens.'),
  "output_tokens": zod.number().describe('The number of output tokens.'),
  "output_tokens_details": zod.object({
  "reasoning_tokens": zod.number().describe('The number of reasoning tokens.')
}).describe('A detailed breakdown of the output tokens.'),
  "total_tokens": zod.number().describe('The total number of tokens used.')
}).optional().describe('Represents token usage details including input tokens, output tokens, a\nbreakdown of output tokens, and the total tokens used. Only populated on\nbatches created after September 7, 2025.\n'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

