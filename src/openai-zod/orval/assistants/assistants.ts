/**
 * Generated by orval v7.7.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import {
  z as zod
} from 'zod';


/**
 * Returns a list of assistants.
 * @summary List assistants
 */
export const listAssistantsQueryLimitDefault = 20;export const listAssistantsQueryOrderDefault = "desc";

export const listAssistantsQueryParams = zod.object({
  "limit": zod.number().optional().describe('A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n'),
  "order": zod.enum(['asc', 'desc']).optional().describe('Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n'),
  "after": zod.string().optional().describe('A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n'),
  "before": zod.string().optional().describe('A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n')
})

export const listAssistantsResponseDataItemNameMaxOne = 256;
export const listAssistantsResponseDataItemDescriptionMaxOne = 512;
export const listAssistantsResponseDataItemInstructionsMaxOne = 256000;
export const listAssistantsResponseDataItemToolsItemFileSearchMaxNumResultsMax = 50;
export const listAssistantsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const listAssistantsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const listAssistantsResponseDataItemToolsItemFunctionStrictDefaultOne = false;export const listAssistantsResponseDataItemToolsDefault = [];
export const listAssistantsResponseDataItemToolsMax = 128;
export const listAssistantsResponseDataItemToolResourcesCodeInterpreterFileIdsDefault = [];
export const listAssistantsResponseDataItemToolResourcesCodeInterpreterFileIdsMax = 20;
export const listAssistantsResponseDataItemToolResourcesFileSearchVectorStoreIdsMax = 1;
export const listAssistantsResponseDataItemTemperatureDefaultOne = 1;export const listAssistantsResponseDataItemTemperatureMinOne = 0;
export const listAssistantsResponseDataItemTemperatureMaxOne = 2;
export const listAssistantsResponseDataItemTopPDefaultOne = 1;export const listAssistantsResponseDataItemTopPMinOne = 0;
export const listAssistantsResponseDataItemTopPMaxOne = 1;
export const listAssistantsResponseDataItemResponseFormatJsonSchemaStrictDefaultOne = false;

export const listAssistantsResponse = zod.object({
  "object": zod.string(),
  "data": zod.array(zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['assistant']).describe('The object type, which is always `assistant`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the assistant was created.'),
  "name": zod.string().max(listAssistantsResponseDataItemNameMaxOne).describe('The name of the assistant. The maximum length is 256 characters.\n').or(zod.null()),
  "description": zod.string().max(listAssistantsResponseDataItemDescriptionMaxOne).describe('The description of the assistant. The maximum length is 512 characters.\n').or(zod.null()),
  "model": zod.string().describe('ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n'),
  "instructions": zod.string().max(listAssistantsResponseDataItemInstructionsMaxOne).describe('The system instructions that the assistant uses. The maximum length is 256,000 characters.\n').or(zod.null()),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(listAssistantsResponseDataItemToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(listAssistantsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMin).max(listAssistantsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(listAssistantsResponseDataItemToolsMax).optional().describe('A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(listAssistantsResponseDataItemToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(listAssistantsResponseDataItemToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n')
}).optional()
}).describe('A set of resources that are used by the assistant\'s tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "temperature": zod.number().min(listAssistantsResponseDataItemTemperatureMinOne).max(listAssistantsResponseDataItemTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(listAssistantsResponseDataItemTopPMinOne).max(listAssistantsResponseDataItemTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n').or(zod.null()).optional(),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n').or(zod.null()).optional()
}).describe('Represents an `assistant` that can call the model and use tools.')),
  "first_id": zod.string(),
  "last_id": zod.string(),
  "has_more": zod.boolean()
})

/**
 * Create an assistant with a model and instructions.
 * @summary Create assistant
 */
export const createAssistantBodyNameMaxOne = 256;
export const createAssistantBodyDescriptionMaxOne = 512;
export const createAssistantBodyInstructionsMaxOne = 256000;
export const createAssistantBodyReasoningEffortDefaultOne = "medium";export const createAssistantBodyToolsItemFileSearchMaxNumResultsMax = 50;
export const createAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const createAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const createAssistantBodyToolsItemFunctionStrictDefaultOne = false;export const createAssistantBodyToolsDefault = [];
export const createAssistantBodyToolsMax = 128;
export const createAssistantBodyToolResourcesCodeInterpreterFileIdsDefault = [];
export const createAssistantBodyToolResourcesCodeInterpreterFileIdsMax = 20;
export const createAssistantBodyTemperatureDefaultOne = 1;export const createAssistantBodyTemperatureMinOne = 0;
export const createAssistantBodyTemperatureMaxOne = 2;
export const createAssistantBodyTopPDefaultOne = 1;export const createAssistantBodyTopPMinOne = 0;
export const createAssistantBodyTopPMaxOne = 1;
export const createAssistantBodyResponseFormatJsonSchemaStrictDefaultOne = false;

export const createAssistantBody = zod.object({
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'o3-mini', 'o3-mini-2025-01-31', 'o1', 'o1-2024-12-17', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4.5-preview', 'gpt-4.5-preview-2025-02-27', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).describe('ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n'),
  "name": zod.string().max(createAssistantBodyNameMaxOne).describe('The name of the assistant. The maximum length is 256 characters.\n').or(zod.null()).optional(),
  "description": zod.string().max(createAssistantBodyDescriptionMaxOne).describe('The description of the assistant. The maximum length is 512 characters.\n').or(zod.null()).optional(),
  "instructions": zod.string().max(createAssistantBodyInstructionsMaxOne).describe('The system instructions that the assistant uses. The maximum length is 256,000 characters.\n').or(zod.null()).optional(),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(createAssistantBodyToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(createAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMin).max(createAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(createAssistantBodyToolsMax).optional().describe('A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(createAssistantBodyToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.any().or(zod.any()).optional()
}).describe('A set of resources that are used by the assistant\'s tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(createAssistantBodyTemperatureMinOne).max(createAssistantBodyTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(createAssistantBodyTopPMinOne).max(createAssistantBodyTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n').or(zod.null()).optional(),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n').or(zod.null()).optional()
})

export const createAssistantResponseNameMaxOne = 256;
export const createAssistantResponseDescriptionMaxOne = 512;
export const createAssistantResponseInstructionsMaxOne = 256000;
export const createAssistantResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const createAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const createAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const createAssistantResponseToolsItemFunctionStrictDefaultOne = false;export const createAssistantResponseToolsDefault = [];
export const createAssistantResponseToolsMax = 128;
export const createAssistantResponseToolResourcesCodeInterpreterFileIdsDefault = [];
export const createAssistantResponseToolResourcesCodeInterpreterFileIdsMax = 20;
export const createAssistantResponseToolResourcesFileSearchVectorStoreIdsMax = 1;
export const createAssistantResponseTemperatureDefaultOne = 1;export const createAssistantResponseTemperatureMinOne = 0;
export const createAssistantResponseTemperatureMaxOne = 2;
export const createAssistantResponseTopPDefaultOne = 1;export const createAssistantResponseTopPMinOne = 0;
export const createAssistantResponseTopPMaxOne = 1;
export const createAssistantResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const createAssistantResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['assistant']).describe('The object type, which is always `assistant`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the assistant was created.'),
  "name": zod.string().max(createAssistantResponseNameMaxOne).describe('The name of the assistant. The maximum length is 256 characters.\n').or(zod.null()),
  "description": zod.string().max(createAssistantResponseDescriptionMaxOne).describe('The description of the assistant. The maximum length is 512 characters.\n').or(zod.null()),
  "model": zod.string().describe('ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n'),
  "instructions": zod.string().max(createAssistantResponseInstructionsMaxOne).describe('The system instructions that the assistant uses. The maximum length is 256,000 characters.\n').or(zod.null()),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(createAssistantResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(createAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(createAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(createAssistantResponseToolsMax).optional().describe('A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(createAssistantResponseToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(createAssistantResponseToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n')
}).optional()
}).describe('A set of resources that are used by the assistant\'s tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "temperature": zod.number().min(createAssistantResponseTemperatureMinOne).max(createAssistantResponseTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(createAssistantResponseTopPMinOne).max(createAssistantResponseTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n').or(zod.null()).optional(),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n').or(zod.null()).optional()
}).describe('Represents an `assistant` that can call the model and use tools.')

/**
 * Retrieves an assistant.
 * @summary Retrieve assistant
 */
export const getAssistantParams = zod.object({
  "assistant_id": zod.string().describe('The ID of the assistant to retrieve.')
})

export const getAssistantResponseNameMaxOne = 256;
export const getAssistantResponseDescriptionMaxOne = 512;
export const getAssistantResponseInstructionsMaxOne = 256000;
export const getAssistantResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const getAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const getAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const getAssistantResponseToolsItemFunctionStrictDefaultOne = false;export const getAssistantResponseToolsDefault = [];
export const getAssistantResponseToolsMax = 128;
export const getAssistantResponseToolResourcesCodeInterpreterFileIdsDefault = [];
export const getAssistantResponseToolResourcesCodeInterpreterFileIdsMax = 20;
export const getAssistantResponseToolResourcesFileSearchVectorStoreIdsMax = 1;
export const getAssistantResponseTemperatureDefaultOne = 1;export const getAssistantResponseTemperatureMinOne = 0;
export const getAssistantResponseTemperatureMaxOne = 2;
export const getAssistantResponseTopPDefaultOne = 1;export const getAssistantResponseTopPMinOne = 0;
export const getAssistantResponseTopPMaxOne = 1;
export const getAssistantResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const getAssistantResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['assistant']).describe('The object type, which is always `assistant`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the assistant was created.'),
  "name": zod.string().max(getAssistantResponseNameMaxOne).describe('The name of the assistant. The maximum length is 256 characters.\n').or(zod.null()),
  "description": zod.string().max(getAssistantResponseDescriptionMaxOne).describe('The description of the assistant. The maximum length is 512 characters.\n').or(zod.null()),
  "model": zod.string().describe('ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n'),
  "instructions": zod.string().max(getAssistantResponseInstructionsMaxOne).describe('The system instructions that the assistant uses. The maximum length is 256,000 characters.\n').or(zod.null()),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(getAssistantResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(getAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(getAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(getAssistantResponseToolsMax).optional().describe('A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(getAssistantResponseToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(getAssistantResponseToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n')
}).optional()
}).describe('A set of resources that are used by the assistant\'s tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "temperature": zod.number().min(getAssistantResponseTemperatureMinOne).max(getAssistantResponseTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(getAssistantResponseTopPMinOne).max(getAssistantResponseTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n').or(zod.null()).optional(),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n').or(zod.null()).optional()
}).describe('Represents an `assistant` that can call the model and use tools.')

/**
 * Modifies an assistant.
 * @summary Modify assistant
 */
export const modifyAssistantParams = zod.object({
  "assistant_id": zod.string().describe('The ID of the assistant to modify.')
})

export const modifyAssistantBodyReasoningEffortDefaultOne = "medium";export const modifyAssistantBodyNameMaxOne = 256;
export const modifyAssistantBodyDescriptionMaxOne = 512;
export const modifyAssistantBodyInstructionsMaxOne = 256000;
export const modifyAssistantBodyToolsItemFileSearchMaxNumResultsMax = 50;
export const modifyAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const modifyAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const modifyAssistantBodyToolsItemFunctionStrictDefaultOne = false;export const modifyAssistantBodyToolsDefault = [];
export const modifyAssistantBodyToolsMax = 128;
export const modifyAssistantBodyToolResourcesCodeInterpreterFileIdsDefault = [];
export const modifyAssistantBodyToolResourcesCodeInterpreterFileIdsMax = 20;
export const modifyAssistantBodyToolResourcesFileSearchVectorStoreIdsMax = 1;
export const modifyAssistantBodyTemperatureDefaultOne = 1;export const modifyAssistantBodyTemperatureMinOne = 0;
export const modifyAssistantBodyTemperatureMaxOne = 2;
export const modifyAssistantBodyTopPDefaultOne = 1;export const modifyAssistantBodyTopPMinOne = 0;
export const modifyAssistantBodyTopPMaxOne = 1;
export const modifyAssistantBodyResponseFormatJsonSchemaStrictDefaultOne = false;

export const modifyAssistantBody = zod.object({
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'o3-mini', 'o3-mini-2025-01-31', 'o1', 'o1-2024-12-17', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4.5-preview', 'gpt-4.5-preview-2025-02-27', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).optional().describe('ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n'),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "name": zod.string().max(modifyAssistantBodyNameMaxOne).describe('The name of the assistant. The maximum length is 256 characters.\n').or(zod.null()).optional(),
  "description": zod.string().max(modifyAssistantBodyDescriptionMaxOne).describe('The description of the assistant. The maximum length is 512 characters.\n').or(zod.null()).optional(),
  "instructions": zod.string().max(modifyAssistantBodyInstructionsMaxOne).describe('The system instructions that the assistant uses. The maximum length is 256,000 characters.\n').or(zod.null()).optional(),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(modifyAssistantBodyToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(modifyAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMin).max(modifyAssistantBodyToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(modifyAssistantBodyToolsMax).optional().describe('A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(modifyAssistantBodyToolResourcesCodeInterpreterFileIdsMax).optional().describe('Overrides the list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(modifyAssistantBodyToolResourcesFileSearchVectorStoreIdsMax).optional().describe('Overrides the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n')
}).optional()
}).describe('A set of resources that are used by the assistant\'s tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(modifyAssistantBodyTemperatureMinOne).max(modifyAssistantBodyTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(modifyAssistantBodyTopPMinOne).max(modifyAssistantBodyTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n').or(zod.null()).optional(),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n').or(zod.null()).optional()
})

export const modifyAssistantResponseNameMaxOne = 256;
export const modifyAssistantResponseDescriptionMaxOne = 512;
export const modifyAssistantResponseInstructionsMaxOne = 256000;
export const modifyAssistantResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const modifyAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const modifyAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const modifyAssistantResponseToolsItemFunctionStrictDefaultOne = false;export const modifyAssistantResponseToolsDefault = [];
export const modifyAssistantResponseToolsMax = 128;
export const modifyAssistantResponseToolResourcesCodeInterpreterFileIdsDefault = [];
export const modifyAssistantResponseToolResourcesCodeInterpreterFileIdsMax = 20;
export const modifyAssistantResponseToolResourcesFileSearchVectorStoreIdsMax = 1;
export const modifyAssistantResponseTemperatureDefaultOne = 1;export const modifyAssistantResponseTemperatureMinOne = 0;
export const modifyAssistantResponseTemperatureMaxOne = 2;
export const modifyAssistantResponseTopPDefaultOne = 1;export const modifyAssistantResponseTopPMinOne = 0;
export const modifyAssistantResponseTopPMaxOne = 1;
export const modifyAssistantResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const modifyAssistantResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['assistant']).describe('The object type, which is always `assistant`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the assistant was created.'),
  "name": zod.string().max(modifyAssistantResponseNameMaxOne).describe('The name of the assistant. The maximum length is 256 characters.\n').or(zod.null()),
  "description": zod.string().max(modifyAssistantResponseDescriptionMaxOne).describe('The description of the assistant. The maximum length is 512 characters.\n').or(zod.null()),
  "model": zod.string().describe('ID of the model to use. You can use the [List models](https://platform.openai.com/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](https://platform.openai.com/docs/models) for descriptions of them.\n'),
  "instructions": zod.string().max(modifyAssistantResponseInstructionsMaxOne).describe('The system instructions that the assistant uses. The maximum length is 256,000 characters.\n').or(zod.null()),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(modifyAssistantResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(modifyAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(modifyAssistantResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(modifyAssistantResponseToolsMax).optional().describe('A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.\n'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(modifyAssistantResponseToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(modifyAssistantResponseToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n')
}).optional()
}).describe('A set of resources that are used by the assistant\'s tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "temperature": zod.number().min(modifyAssistantResponseTemperatureMinOne).max(modifyAssistantResponseTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(modifyAssistantResponseTopPMinOne).max(modifyAssistantResponseTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n').or(zod.null()).optional(),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n').or(zod.null()).optional()
}).describe('Represents an `assistant` that can call the model and use tools.')

/**
 * Delete an assistant.
 * @summary Delete assistant
 */
export const deleteAssistantParams = zod.object({
  "assistant_id": zod.string().describe('The ID of the assistant to delete.')
})

export const deleteAssistantResponse = zod.object({
  "id": zod.string(),
  "deleted": zod.boolean(),
  "object": zod.enum(['assistant.deleted'])
})

/**
 * Create a thread.
 * @summary Create thread
 */
export const createThreadBodyMessagesItemContentItemImageFileDetailDefault = "auto";export const createThreadBodyMessagesItemContentItemImageUrlDetailDefault = "auto";export const createThreadBodyToolResourcesCodeInterpreterFileIdsDefault = [];
export const createThreadBodyToolResourcesCodeInterpreterFileIdsMax = 20;


export const createThreadBody = zod.object({
  "messages": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant']).describe('The role of the entity that is creating the message. Allowed values include:\n- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.\n- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.\n'),
  "content": zod.string().describe('The text contents of the message.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.string().describe('Text content to be sent to the model')
}).describe('The text content that is part of a message.')])).min(1).describe('An array of content parts with a defined type, each can be of type `text` or images can be passed with `image_url` or `image_file`. Image types are only supported on [Vision-compatible models](https://platform.openai.com/docs/models).')),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
})])).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they should be added to.').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})).optional().describe('A list of [messages](https://platform.openai.com/docs/api-reference/messages) to start the thread with.'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(createThreadBodyToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.any().or(zod.any()).optional()
}).describe('A set of resources that are made available to the assistant\'s tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).describe('Options to create a new thread. If no thread is provided when running a\nrequest, an empty thread will be created.\n')

export const createThreadResponseToolResourcesCodeInterpreterFileIdsDefault = [];
export const createThreadResponseToolResourcesCodeInterpreterFileIdsMax = 20;
export const createThreadResponseToolResourcesFileSearchVectorStoreIdsMax = 1;


export const createThreadResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread']).describe('The object type, which is always `thread`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the thread was created.'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(createThreadResponseToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(createThreadResponseToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n')
}).optional()
}).describe('A set of resources that are made available to the assistant\'s tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('Represents a thread that contains [messages](https://platform.openai.com/docs/api-reference/messages).')

/**
 * Create a thread and run it in one request.
 * @summary Create thread and run
 */
export const createThreadAndRunBodyThreadMessagesItemContentItemImageFileDetailDefault = "auto";export const createThreadAndRunBodyThreadMessagesItemContentItemImageUrlDetailDefault = "auto";export const createThreadAndRunBodyThreadToolResourcesCodeInterpreterFileIdsDefault = [];
export const createThreadAndRunBodyThreadToolResourcesCodeInterpreterFileIdsMax = 20;
export const createThreadAndRunBodyToolsItemFileSearchMaxNumResultsMax = 50;
export const createThreadAndRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const createThreadAndRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const createThreadAndRunBodyToolsItemFunctionStrictDefaultOne = false;export const createThreadAndRunBodyToolsMax = 20;
export const createThreadAndRunBodyToolResourcesCodeInterpreterFileIdsDefault = [];
export const createThreadAndRunBodyToolResourcesCodeInterpreterFileIdsMax = 20;
export const createThreadAndRunBodyToolResourcesFileSearchVectorStoreIdsMax = 1;
export const createThreadAndRunBodyTemperatureDefault = 1;
export const createThreadAndRunBodyTemperatureMin = 0;

export const createThreadAndRunBodyTemperatureMax = 2;
export const createThreadAndRunBodyTopPDefault = 1;
export const createThreadAndRunBodyTopPMin = 0;

export const createThreadAndRunBodyTopPMax = 1;
export const createThreadAndRunBodyMaxPromptTokensMin = 256;
export const createThreadAndRunBodyMaxCompletionTokensMin = 256;
export const createThreadAndRunBodyParallelToolCallsDefault = true;export const createThreadAndRunBodyResponseFormatJsonSchemaStrictDefaultOne = false;

export const createThreadAndRunBody = zod.object({
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.'),
  "thread": zod.object({
  "messages": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant']).describe('The role of the entity that is creating the message. Allowed values include:\n- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.\n- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.\n'),
  "content": zod.string().describe('The text contents of the message.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.string().describe('Text content to be sent to the model')
}).describe('The text content that is part of a message.')])).min(1).describe('An array of content parts with a defined type, each can be of type `text` or images can be passed with `image_url` or `image_file`. Image types are only supported on [Vision-compatible models](https://platform.openai.com/docs/models).')),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
})])).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they should be added to.').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})).optional().describe('A list of [messages](https://platform.openai.com/docs/api-reference/messages) to start the thread with.'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(createThreadAndRunBodyThreadToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.any().or(zod.any()).optional()
}).describe('A set of resources that are made available to the assistant\'s tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
}).optional().describe('Options to create a new thread. If no thread is provided when running a\nrequest, an empty thread will be created.\n'),
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4.5-preview', 'gpt-4.5-preview-2025-02-27', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).nullish().describe('The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'),
  "instructions": zod.string().nullish().describe('Override the default system message of the assistant. This is useful for modifying the behavior on a per-run basis.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(createThreadAndRunBodyToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(createThreadAndRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMin).max(createThreadAndRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(createThreadAndRunBodyToolsMax).nullish().describe('Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(createThreadAndRunBodyToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(createThreadAndRunBodyToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The ID of the [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.\n')
}).optional()
}).nullish().describe('A set of resources that are used by the assistant\'s tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(createThreadAndRunBodyTemperatureMin).max(createThreadAndRunBodyTemperatureMax).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n'),
  "top_p": zod.number().min(createThreadAndRunBodyTopPMin).max(createThreadAndRunBodyTopPMax).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n'),
  "stream": zod.boolean().nullish().describe('If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n'),
  "max_prompt_tokens": zod.number().min(createThreadAndRunBodyMaxPromptTokensMin).nullish().describe('The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n'),
  "max_completion_tokens": zod.number().min(createThreadAndRunBodyMaxCompletionTokensMin).nullish().describe('The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()).optional(),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()).optional(),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).optional().describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
})

export const createThreadAndRunResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const createThreadAndRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const createThreadAndRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const createThreadAndRunResponseToolsItemFunctionStrictDefaultOne = false;export const createThreadAndRunResponseToolsDefault = [];
export const createThreadAndRunResponseToolsMax = 20;
export const createThreadAndRunResponseMaxPromptTokensMin = 256;
export const createThreadAndRunResponseMaxCompletionTokensMin = 256;
export const createThreadAndRunResponseParallelToolCallsDefault = true;export const createThreadAndRunResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const createThreadAndRunResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run']).describe('The object type, which is always `thread.run`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run was created.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'),
  "status": zod.enum(['queued', 'in_progress', 'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', 'incomplete', 'expired']).describe('The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'),
  "required_action": zod.object({
  "type": zod.enum(['submit_tool_outputs']).describe('For now, this is always `submit_tool_outputs`.'),
  "submit_tool_outputs": zod.object({
  "tool_calls": zod.array(zod.object({
  "id": zod.string().describe('The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'),
  "type": zod.enum(['function']).describe('The type of tool call the output is required for. For now, this is always `function`.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments that the model expects you to pass to the function.')
}).describe('The function definition.')
}).describe('Tool call objects')).describe('A list of the relevant tool calls.')
}).describe('Details on the tool outputs needed for this run to continue.')
}).nullable().describe('Details on the action required to continue the run. Will be `null` if no action is required.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt']).describe('One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).nullable().describe('The last error associated with this run. Will be `null` if there are no errors.'),
  "expires_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run will expire.'),
  "started_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was started.'),
  "cancelled_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was cancelled.'),
  "failed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run failed.'),
  "completed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was completed.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_completion_tokens', 'max_prompt_tokens']).optional().describe('The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.')
}).nullable().describe('Details on why the run is incomplete. Will be `null` if the run is not incomplete.'),
  "model": zod.string().describe('The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "instructions": zod.string().describe('The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(createThreadAndRunResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(createThreadAndRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(createThreadAndRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(createThreadAndRunResponseToolsMax).optional().describe('The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).').or(zod.null()),
  "temperature": zod.number().nullish().describe('The sampling temperature used for this run. If not set, defaults to 1.'),
  "top_p": zod.number().nullish().describe('The nucleus sampling value used for this run. If not set, defaults to 1.'),
  "max_prompt_tokens": zod.number().min(createThreadAndRunResponseMaxPromptTokensMin).nullable().describe('The maximum number of prompt tokens specified to have been used over the course of the run.\n'),
  "max_completion_tokens": zod.number().min(createThreadAndRunResponseMaxCompletionTokensMin).nullable().describe('The maximum number of completion tokens specified to have been used over the course of the run.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
}).describe('Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Retrieves a thread.
 * @summary Retrieve thread
 */
export const getThreadParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to retrieve.')
})

export const getThreadResponseToolResourcesCodeInterpreterFileIdsDefault = [];
export const getThreadResponseToolResourcesCodeInterpreterFileIdsMax = 20;
export const getThreadResponseToolResourcesFileSearchVectorStoreIdsMax = 1;


export const getThreadResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread']).describe('The object type, which is always `thread`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the thread was created.'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(getThreadResponseToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(getThreadResponseToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n')
}).optional()
}).describe('A set of resources that are made available to the assistant\'s tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('Represents a thread that contains [messages](https://platform.openai.com/docs/api-reference/messages).')

/**
 * Modifies a thread.
 * @summary Modify thread
 */
export const modifyThreadParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to modify. Only the `metadata` can be modified.')
})

export const modifyThreadBodyToolResourcesCodeInterpreterFileIdsDefault = [];
export const modifyThreadBodyToolResourcesCodeInterpreterFileIdsMax = 20;
export const modifyThreadBodyToolResourcesFileSearchVectorStoreIdsMax = 1;


export const modifyThreadBody = zod.object({
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(modifyThreadBodyToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(modifyThreadBodyToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n')
}).optional()
}).describe('A set of resources that are made available to the assistant\'s tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

export const modifyThreadResponseToolResourcesCodeInterpreterFileIdsDefault = [];
export const modifyThreadResponseToolResourcesCodeInterpreterFileIdsMax = 20;
export const modifyThreadResponseToolResourcesFileSearchVectorStoreIdsMax = 1;


export const modifyThreadResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread']).describe('The object type, which is always `thread`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the thread was created.'),
  "tool_resources": zod.object({
  "code_interpreter": zod.object({
  "file_ids": zod.array(zod.string()).max(modifyThreadResponseToolResourcesCodeInterpreterFileIdsMax).optional().describe('A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.\n')
}).optional(),
  "file_search": zod.object({
  "vector_store_ids": zod.array(zod.string()).max(modifyThreadResponseToolResourcesFileSearchVectorStoreIdsMax).optional().describe('The [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.\n')
}).optional()
}).describe('A set of resources that are made available to the assistant\'s tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.\n').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('Represents a thread that contains [messages](https://platform.openai.com/docs/api-reference/messages).')

/**
 * Delete a thread.
 * @summary Delete thread
 */
export const deleteThreadParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to delete.')
})

export const deleteThreadResponse = zod.object({
  "id": zod.string(),
  "deleted": zod.boolean(),
  "object": zod.enum(['thread.deleted'])
})

/**
 * Returns a list of messages for a given thread.
 * @summary List messages
 */
export const listMessagesParams = zod.object({
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) the messages belong to.')
})

export const listMessagesQueryLimitDefault = 20;export const listMessagesQueryOrderDefault = "desc";

export const listMessagesQueryParams = zod.object({
  "limit": zod.number().optional().describe('A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n'),
  "order": zod.enum(['asc', 'desc']).optional().describe('Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n'),
  "after": zod.string().optional().describe('A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n'),
  "before": zod.string().optional().describe('A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n'),
  "run_id": zod.string().optional().describe('Filter messages by the run ID that generated them.\n')
})

export const listMessagesResponseDataItemContentItemImageFileDetailDefault = "auto";export const listMessagesResponseDataItemContentItemImageUrlDetailDefault = "auto";export const listMessagesResponseDataItemContentItemTextAnnotationsItemStartIndexMin = 0;
export const listMessagesResponseDataItemContentItemTextAnnotationsItemEndIndexMin = 0;
export const listMessagesResponseDataItemContentItemTextAnnotationsItemStartIndexMinOne = 0;
export const listMessagesResponseDataItemContentItemTextAnnotationsItemEndIndexMinOne = 0;


export const listMessagesResponse = zod.object({
  "object": zod.string(),
  "data": zod.array(zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.message']).describe('The object type, which is always `thread.message`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was created.'),
  "thread_id": zod.string().describe('The [thread](https://platform.openai.com/docs/api-reference/threads) ID that this message belongs to.'),
  "status": zod.enum(['in_progress', 'incomplete', 'completed']).describe('The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['content_filter', 'max_tokens', 'run_cancelled', 'run_expired', 'run_failed']).describe('The reason the message is incomplete.')
}).describe('On an incomplete message, details about why the message is incomplete.').or(zod.null()),
  "completed_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was completed.').or(zod.null()),
  "incomplete_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was marked as incomplete.').or(zod.null()),
  "role": zod.enum(['user', 'assistant']).describe('The entity that produced the message. One of `user` or `assistant`.'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.object({
  "value": zod.string().describe('The data that makes up the text.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).describe('Always `file_citation`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_citation": zod.object({
  "file_id": zod.string().describe('The ID of the specific File the citation is from.')
}),
  "start_index": zod.number().min(listMessagesResponseDataItemContentItemTextAnnotationsItemStartIndexMin),
  "end_index": zod.number().min(listMessagesResponseDataItemContentItemTextAnnotationsItemEndIndexMin)
}).describe('A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the \"file_search\" tool to search files.'),zod.object({
  "type": zod.enum(['file_path']).describe('Always `file_path`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_path": zod.object({
  "file_id": zod.string().describe('The ID of the file that was generated.')
}),
  "start_index": zod.number().min(listMessagesResponseDataItemContentItemTextAnnotationsItemStartIndexMinOne),
  "end_index": zod.number().min(listMessagesResponseDataItemContentItemTextAnnotationsItemEndIndexMinOne)
}).describe('A URL for the file that\'s generated when the assistant used the `code_interpreter` tool to generate a file.')]))
})
}).describe('The text content that is part of a message.'),zod.object({
  "type": zod.enum(['refusal']).describe('Always `refusal`.'),
  "refusal": zod.string()
}).describe('The refusal content generated by the assistant.')])).describe('The content of the message in array of text and/or images.'),
  "assistant_id": zod.string().describe('If applicable, the ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) that authored this message.').or(zod.null()),
  "run_id": zod.string().describe('The ID of the [run](https://platform.openai.com/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.').or(zod.null()),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}).or(zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
}))).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they were added to.').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('Represents a message within a [thread](https://platform.openai.com/docs/api-reference/threads).')),
  "first_id": zod.string(),
  "last_id": zod.string(),
  "has_more": zod.boolean()
})

/**
 * Create a message.
 * @summary Create message
 */
export const createMessageParams = zod.object({
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to create a message for.')
})

export const createMessageBodyContentItemImageFileDetailDefault = "auto";export const createMessageBodyContentItemImageUrlDetailDefault = "auto";

export const createMessageBody = zod.object({
  "role": zod.enum(['user', 'assistant']).describe('The role of the entity that is creating the message. Allowed values include:\n- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.\n- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.\n'),
  "content": zod.string().describe('The text contents of the message.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.string().describe('Text content to be sent to the model')
}).describe('The text content that is part of a message.')])).min(1).describe('An array of content parts with a defined type, each can be of type `text` or images can be passed with `image_url` or `image_file`. Image types are only supported on [Vision-compatible models](https://platform.openai.com/docs/models).')),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
})])).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they should be added to.').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

export const createMessageResponseContentItemImageFileDetailDefault = "auto";export const createMessageResponseContentItemImageUrlDetailDefault = "auto";export const createMessageResponseContentItemTextAnnotationsItemStartIndexMin = 0;
export const createMessageResponseContentItemTextAnnotationsItemEndIndexMin = 0;
export const createMessageResponseContentItemTextAnnotationsItemStartIndexMinOne = 0;
export const createMessageResponseContentItemTextAnnotationsItemEndIndexMinOne = 0;


export const createMessageResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.message']).describe('The object type, which is always `thread.message`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was created.'),
  "thread_id": zod.string().describe('The [thread](https://platform.openai.com/docs/api-reference/threads) ID that this message belongs to.'),
  "status": zod.enum(['in_progress', 'incomplete', 'completed']).describe('The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['content_filter', 'max_tokens', 'run_cancelled', 'run_expired', 'run_failed']).describe('The reason the message is incomplete.')
}).describe('On an incomplete message, details about why the message is incomplete.').or(zod.null()),
  "completed_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was completed.').or(zod.null()),
  "incomplete_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was marked as incomplete.').or(zod.null()),
  "role": zod.enum(['user', 'assistant']).describe('The entity that produced the message. One of `user` or `assistant`.'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.object({
  "value": zod.string().describe('The data that makes up the text.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).describe('Always `file_citation`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_citation": zod.object({
  "file_id": zod.string().describe('The ID of the specific File the citation is from.')
}),
  "start_index": zod.number().min(createMessageResponseContentItemTextAnnotationsItemStartIndexMin),
  "end_index": zod.number().min(createMessageResponseContentItemTextAnnotationsItemEndIndexMin)
}).describe('A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the \"file_search\" tool to search files.'),zod.object({
  "type": zod.enum(['file_path']).describe('Always `file_path`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_path": zod.object({
  "file_id": zod.string().describe('The ID of the file that was generated.')
}),
  "start_index": zod.number().min(createMessageResponseContentItemTextAnnotationsItemStartIndexMinOne),
  "end_index": zod.number().min(createMessageResponseContentItemTextAnnotationsItemEndIndexMinOne)
}).describe('A URL for the file that\'s generated when the assistant used the `code_interpreter` tool to generate a file.')]))
})
}).describe('The text content that is part of a message.'),zod.object({
  "type": zod.enum(['refusal']).describe('Always `refusal`.'),
  "refusal": zod.string()
}).describe('The refusal content generated by the assistant.')])).describe('The content of the message in array of text and/or images.'),
  "assistant_id": zod.string().describe('If applicable, the ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) that authored this message.').or(zod.null()),
  "run_id": zod.string().describe('The ID of the [run](https://platform.openai.com/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.').or(zod.null()),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}).or(zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
}))).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they were added to.').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('Represents a message within a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Retrieve a message.
 * @summary Retrieve message
 */
export const getMessageParams = zod.object({
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this message belongs.'),
  "message_id": zod.string().describe('The ID of the message to retrieve.')
})

export const getMessageResponseContentItemImageFileDetailDefault = "auto";export const getMessageResponseContentItemImageUrlDetailDefault = "auto";export const getMessageResponseContentItemTextAnnotationsItemStartIndexMin = 0;
export const getMessageResponseContentItemTextAnnotationsItemEndIndexMin = 0;
export const getMessageResponseContentItemTextAnnotationsItemStartIndexMinOne = 0;
export const getMessageResponseContentItemTextAnnotationsItemEndIndexMinOne = 0;


export const getMessageResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.message']).describe('The object type, which is always `thread.message`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was created.'),
  "thread_id": zod.string().describe('The [thread](https://platform.openai.com/docs/api-reference/threads) ID that this message belongs to.'),
  "status": zod.enum(['in_progress', 'incomplete', 'completed']).describe('The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['content_filter', 'max_tokens', 'run_cancelled', 'run_expired', 'run_failed']).describe('The reason the message is incomplete.')
}).describe('On an incomplete message, details about why the message is incomplete.').or(zod.null()),
  "completed_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was completed.').or(zod.null()),
  "incomplete_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was marked as incomplete.').or(zod.null()),
  "role": zod.enum(['user', 'assistant']).describe('The entity that produced the message. One of `user` or `assistant`.'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.object({
  "value": zod.string().describe('The data that makes up the text.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).describe('Always `file_citation`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_citation": zod.object({
  "file_id": zod.string().describe('The ID of the specific File the citation is from.')
}),
  "start_index": zod.number().min(getMessageResponseContentItemTextAnnotationsItemStartIndexMin),
  "end_index": zod.number().min(getMessageResponseContentItemTextAnnotationsItemEndIndexMin)
}).describe('A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the \"file_search\" tool to search files.'),zod.object({
  "type": zod.enum(['file_path']).describe('Always `file_path`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_path": zod.object({
  "file_id": zod.string().describe('The ID of the file that was generated.')
}),
  "start_index": zod.number().min(getMessageResponseContentItemTextAnnotationsItemStartIndexMinOne),
  "end_index": zod.number().min(getMessageResponseContentItemTextAnnotationsItemEndIndexMinOne)
}).describe('A URL for the file that\'s generated when the assistant used the `code_interpreter` tool to generate a file.')]))
})
}).describe('The text content that is part of a message.'),zod.object({
  "type": zod.enum(['refusal']).describe('Always `refusal`.'),
  "refusal": zod.string()
}).describe('The refusal content generated by the assistant.')])).describe('The content of the message in array of text and/or images.'),
  "assistant_id": zod.string().describe('If applicable, the ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) that authored this message.').or(zod.null()),
  "run_id": zod.string().describe('The ID of the [run](https://platform.openai.com/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.').or(zod.null()),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}).or(zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
}))).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they were added to.').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('Represents a message within a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Modifies a message.
 * @summary Modify message
 */
export const modifyMessageParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to which this message belongs.'),
  "message_id": zod.string().describe('The ID of the message to modify.')
})

export const modifyMessageBody = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

export const modifyMessageResponseContentItemImageFileDetailDefault = "auto";export const modifyMessageResponseContentItemImageUrlDetailDefault = "auto";export const modifyMessageResponseContentItemTextAnnotationsItemStartIndexMin = 0;
export const modifyMessageResponseContentItemTextAnnotationsItemEndIndexMin = 0;
export const modifyMessageResponseContentItemTextAnnotationsItemStartIndexMinOne = 0;
export const modifyMessageResponseContentItemTextAnnotationsItemEndIndexMinOne = 0;


export const modifyMessageResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.message']).describe('The object type, which is always `thread.message`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was created.'),
  "thread_id": zod.string().describe('The [thread](https://platform.openai.com/docs/api-reference/threads) ID that this message belongs to.'),
  "status": zod.enum(['in_progress', 'incomplete', 'completed']).describe('The status of the message, which can be either `in_progress`, `incomplete`, or `completed`.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['content_filter', 'max_tokens', 'run_cancelled', 'run_expired', 'run_failed']).describe('The reason the message is incomplete.')
}).describe('On an incomplete message, details about why the message is incomplete.').or(zod.null()),
  "completed_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was completed.').or(zod.null()),
  "incomplete_at": zod.number().describe('The Unix timestamp (in seconds) for when the message was marked as incomplete.').or(zod.null()),
  "role": zod.enum(['user', 'assistant']).describe('The entity that produced the message. One of `user` or `assistant`.'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.object({
  "value": zod.string().describe('The data that makes up the text.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).describe('Always `file_citation`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_citation": zod.object({
  "file_id": zod.string().describe('The ID of the specific File the citation is from.')
}),
  "start_index": zod.number().min(modifyMessageResponseContentItemTextAnnotationsItemStartIndexMin),
  "end_index": zod.number().min(modifyMessageResponseContentItemTextAnnotationsItemEndIndexMin)
}).describe('A citation within the message that points to a specific quote from a specific File associated with the assistant or the message. Generated when the assistant uses the \"file_search\" tool to search files.'),zod.object({
  "type": zod.enum(['file_path']).describe('Always `file_path`.'),
  "text": zod.string().describe('The text in the message content that needs to be replaced.'),
  "file_path": zod.object({
  "file_id": zod.string().describe('The ID of the file that was generated.')
}),
  "start_index": zod.number().min(modifyMessageResponseContentItemTextAnnotationsItemStartIndexMinOne),
  "end_index": zod.number().min(modifyMessageResponseContentItemTextAnnotationsItemEndIndexMinOne)
}).describe('A URL for the file that\'s generated when the assistant used the `code_interpreter` tool to generate a file.')]))
})
}).describe('The text content that is part of a message.'),zod.object({
  "type": zod.enum(['refusal']).describe('Always `refusal`.'),
  "refusal": zod.string()
}).describe('The refusal content generated by the assistant.')])).describe('The content of the message in array of text and/or images.'),
  "assistant_id": zod.string().describe('If applicable, the ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) that authored this message.').or(zod.null()),
  "run_id": zod.string().describe('The ID of the [run](https://platform.openai.com/docs/api-reference/runs) associated with the creation of this message. Value is `null` when messages are created manually using the create message or create thread endpoints.').or(zod.null()),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}).or(zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
}))).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they were added to.').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null())
}).describe('Represents a message within a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Deletes a message.
 * @summary Delete message
 */
export const deleteMessageParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to which this message belongs.'),
  "message_id": zod.string().describe('The ID of the message to delete.')
})

export const deleteMessageResponse = zod.object({
  "id": zod.string(),
  "deleted": zod.boolean(),
  "object": zod.enum(['thread.message.deleted'])
})

/**
 * Returns a list of runs belonging to a thread.
 * @summary List runs
 */
export const listRunsParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread the run belongs to.')
})

export const listRunsQueryLimitDefault = 20;export const listRunsQueryOrderDefault = "desc";

export const listRunsQueryParams = zod.object({
  "limit": zod.number().optional().describe('A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n'),
  "order": zod.enum(['asc', 'desc']).optional().describe('Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n'),
  "after": zod.string().optional().describe('A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n'),
  "before": zod.string().optional().describe('A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n')
})

export const listRunsResponseDataItemToolsItemFileSearchMaxNumResultsMax = 50;
export const listRunsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const listRunsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const listRunsResponseDataItemToolsItemFunctionStrictDefaultOne = false;export const listRunsResponseDataItemToolsDefault = [];
export const listRunsResponseDataItemToolsMax = 20;
export const listRunsResponseDataItemMaxPromptTokensMin = 256;
export const listRunsResponseDataItemMaxCompletionTokensMin = 256;
export const listRunsResponseDataItemParallelToolCallsDefault = true;export const listRunsResponseDataItemResponseFormatJsonSchemaStrictDefaultOne = false;

export const listRunsResponse = zod.object({
  "object": zod.string(),
  "data": zod.array(zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run']).describe('The object type, which is always `thread.run`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run was created.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'),
  "status": zod.enum(['queued', 'in_progress', 'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', 'incomplete', 'expired']).describe('The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'),
  "required_action": zod.object({
  "type": zod.enum(['submit_tool_outputs']).describe('For now, this is always `submit_tool_outputs`.'),
  "submit_tool_outputs": zod.object({
  "tool_calls": zod.array(zod.object({
  "id": zod.string().describe('The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'),
  "type": zod.enum(['function']).describe('The type of tool call the output is required for. For now, this is always `function`.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments that the model expects you to pass to the function.')
}).describe('The function definition.')
}).describe('Tool call objects')).describe('A list of the relevant tool calls.')
}).describe('Details on the tool outputs needed for this run to continue.')
}).nullable().describe('Details on the action required to continue the run. Will be `null` if no action is required.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt']).describe('One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).nullable().describe('The last error associated with this run. Will be `null` if there are no errors.'),
  "expires_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run will expire.'),
  "started_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was started.'),
  "cancelled_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was cancelled.'),
  "failed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run failed.'),
  "completed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was completed.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_completion_tokens', 'max_prompt_tokens']).optional().describe('The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.')
}).nullable().describe('Details on why the run is incomplete. Will be `null` if the run is not incomplete.'),
  "model": zod.string().describe('The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "instructions": zod.string().describe('The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(listRunsResponseDataItemToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(listRunsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMin).max(listRunsResponseDataItemToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(listRunsResponseDataItemToolsMax).optional().describe('The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).').or(zod.null()),
  "temperature": zod.number().nullish().describe('The sampling temperature used for this run. If not set, defaults to 1.'),
  "top_p": zod.number().nullish().describe('The nucleus sampling value used for this run. If not set, defaults to 1.'),
  "max_prompt_tokens": zod.number().min(listRunsResponseDataItemMaxPromptTokensMin).nullable().describe('The maximum number of prompt tokens specified to have been used over the course of the run.\n'),
  "max_completion_tokens": zod.number().min(listRunsResponseDataItemMaxCompletionTokensMin).nullable().describe('The maximum number of completion tokens specified to have been used over the course of the run.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
}).describe('Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).')),
  "first_id": zod.string(),
  "last_id": zod.string(),
  "has_more": zod.boolean()
})

/**
 * Create a run.
 * @summary Create run
 */
export const createRunParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to run.')
})

export const createRunQueryParams = zod.object({
  "include[]": zod.array(zod.enum(['step_details.tool_calls[*].file_search.results[*].content'])).optional().describe('A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
})

export const createRunBodyReasoningEffortDefaultOne = "medium";export const createRunBodyAdditionalMessagesItemContentItemImageFileDetailDefault = "auto";export const createRunBodyAdditionalMessagesItemContentItemImageUrlDetailDefault = "auto";export const createRunBodyToolsItemFileSearchMaxNumResultsMax = 50;
export const createRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const createRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const createRunBodyToolsItemFunctionStrictDefaultOne = false;export const createRunBodyToolsMax = 20;
export const createRunBodyTemperatureDefault = 1;
export const createRunBodyTemperatureMin = 0;

export const createRunBodyTemperatureMax = 2;
export const createRunBodyTopPDefault = 1;
export const createRunBodyTopPMin = 0;

export const createRunBodyTopPMax = 1;
export const createRunBodyMaxPromptTokensMin = 256;
export const createRunBodyMaxCompletionTokensMin = 256;
export const createRunBodyParallelToolCallsDefault = true;export const createRunBodyResponseFormatJsonSchemaStrictDefaultOne = false;

export const createRunBody = zod.object({
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to execute this run.'),
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'o3-mini', 'o3-mini-2025-01-31', 'o1', 'o1-2024-12-17', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4.5-preview', 'gpt-4.5-preview-2025-02-27', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).nullish().describe('The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to be used to execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the model associated with the assistant will be used.'),
  "reasoning_effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "instructions": zod.string().nullish().describe('Overrides the [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for modifying the behavior on a per-run basis.'),
  "additional_instructions": zod.string().nullish().describe('Appends additional instructions at the end of the instructions for the run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.'),
  "additional_messages": zod.array(zod.object({
  "role": zod.enum(['user', 'assistant']).describe('The role of the entity that is creating the message. Allowed values include:\n- `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.\n- `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.\n'),
  "content": zod.string().describe('The text contents of the message.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['image_file']).describe('Always `image_file`.'),
  "image_file": zod.object({
  "file_id": zod.string().describe('The [File](https://platform.openai.com/docs/api-reference/files) ID of the image in the message content. Set `purpose=\"vision\"` when uploading the File if you need to later display the file content.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image if specified by the user. `low` uses fewer tokens, you can opt in to high resolution using `high`.')
})
}).describe('References an image [File](https://platform.openai.com/docs/api-reference/files) in the content of a message.'),zod.object({
  "type": zod.enum(['image_url']).describe('The type of the content part.'),
  "image_url": zod.object({
  "url": zod.string().url().describe('The external URL of the image, must be a supported image types: jpeg, jpg, png, gif, webp.'),
  "detail": zod.enum(['auto', 'low', 'high']).optional().describe('Specifies the detail level of the image. `low` uses fewer tokens, you can opt in to high resolution using `high`. Default value is `auto`')
})
}).describe('References an image URL in the content of a message.'),zod.object({
  "type": zod.enum(['text']).describe('Always `text`.'),
  "text": zod.string().describe('Text content to be sent to the model')
}).describe('The text content that is part of a message.')])).min(1).describe('An array of content parts with a defined type, each can be of type `text` or images can be passed with `image_url` or `image_file`. Image types are only supported on [Vision-compatible models](https://platform.openai.com/docs/models).')),
  "attachments": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The ID of the file to attach to the message.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`')
})])).optional().describe('The tools to add this file to.')
})).describe('A list of files attached to the message, and the tools they should be added to.').or(zod.null()).optional(),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})).nullish().describe('Adds additional messages to the thread before creating the run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(createRunBodyToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(createRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMin).max(createRunBodyToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(createRunBodyToolsMax).nullish().describe('Override the tools the assistant can use for this run. This is useful for modifying the behavior on a per-run basis.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(createRunBodyTemperatureMin).max(createRunBodyTemperatureMax).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n'),
  "top_p": zod.number().min(createRunBodyTopPMin).max(createRunBodyTopPMax).optional().describe('An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n'),
  "stream": zod.boolean().nullish().describe('If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n'),
  "max_prompt_tokens": zod.number().min(createRunBodyMaxPromptTokensMin).nullish().describe('The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n'),
  "max_completion_tokens": zod.number().min(createRunBodyMaxCompletionTokensMin).nullish().describe('The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()).optional(),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()).optional(),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).optional().describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
})

export const createRunResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const createRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const createRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const createRunResponseToolsItemFunctionStrictDefaultOne = false;export const createRunResponseToolsDefault = [];
export const createRunResponseToolsMax = 20;
export const createRunResponseMaxPromptTokensMin = 256;
export const createRunResponseMaxCompletionTokensMin = 256;
export const createRunResponseParallelToolCallsDefault = true;export const createRunResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const createRunResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run']).describe('The object type, which is always `thread.run`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run was created.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'),
  "status": zod.enum(['queued', 'in_progress', 'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', 'incomplete', 'expired']).describe('The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'),
  "required_action": zod.object({
  "type": zod.enum(['submit_tool_outputs']).describe('For now, this is always `submit_tool_outputs`.'),
  "submit_tool_outputs": zod.object({
  "tool_calls": zod.array(zod.object({
  "id": zod.string().describe('The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'),
  "type": zod.enum(['function']).describe('The type of tool call the output is required for. For now, this is always `function`.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments that the model expects you to pass to the function.')
}).describe('The function definition.')
}).describe('Tool call objects')).describe('A list of the relevant tool calls.')
}).describe('Details on the tool outputs needed for this run to continue.')
}).nullable().describe('Details on the action required to continue the run. Will be `null` if no action is required.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt']).describe('One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).nullable().describe('The last error associated with this run. Will be `null` if there are no errors.'),
  "expires_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run will expire.'),
  "started_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was started.'),
  "cancelled_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was cancelled.'),
  "failed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run failed.'),
  "completed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was completed.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_completion_tokens', 'max_prompt_tokens']).optional().describe('The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.')
}).nullable().describe('Details on why the run is incomplete. Will be `null` if the run is not incomplete.'),
  "model": zod.string().describe('The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "instructions": zod.string().describe('The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(createRunResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(createRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(createRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(createRunResponseToolsMax).optional().describe('The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).').or(zod.null()),
  "temperature": zod.number().nullish().describe('The sampling temperature used for this run. If not set, defaults to 1.'),
  "top_p": zod.number().nullish().describe('The nucleus sampling value used for this run. If not set, defaults to 1.'),
  "max_prompt_tokens": zod.number().min(createRunResponseMaxPromptTokensMin).nullable().describe('The maximum number of prompt tokens specified to have been used over the course of the run.\n'),
  "max_completion_tokens": zod.number().min(createRunResponseMaxCompletionTokensMin).nullable().describe('The maximum number of completion tokens specified to have been used over the course of the run.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
}).describe('Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Retrieves a run.
 * @summary Retrieve run
 */
export const getRunParams = zod.object({
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.'),
  "run_id": zod.string().describe('The ID of the run to retrieve.')
})

export const getRunResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const getRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const getRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const getRunResponseToolsItemFunctionStrictDefaultOne = false;export const getRunResponseToolsDefault = [];
export const getRunResponseToolsMax = 20;
export const getRunResponseMaxPromptTokensMin = 256;
export const getRunResponseMaxCompletionTokensMin = 256;
export const getRunResponseParallelToolCallsDefault = true;export const getRunResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const getRunResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run']).describe('The object type, which is always `thread.run`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run was created.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'),
  "status": zod.enum(['queued', 'in_progress', 'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', 'incomplete', 'expired']).describe('The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'),
  "required_action": zod.object({
  "type": zod.enum(['submit_tool_outputs']).describe('For now, this is always `submit_tool_outputs`.'),
  "submit_tool_outputs": zod.object({
  "tool_calls": zod.array(zod.object({
  "id": zod.string().describe('The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'),
  "type": zod.enum(['function']).describe('The type of tool call the output is required for. For now, this is always `function`.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments that the model expects you to pass to the function.')
}).describe('The function definition.')
}).describe('Tool call objects')).describe('A list of the relevant tool calls.')
}).describe('Details on the tool outputs needed for this run to continue.')
}).nullable().describe('Details on the action required to continue the run. Will be `null` if no action is required.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt']).describe('One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).nullable().describe('The last error associated with this run. Will be `null` if there are no errors.'),
  "expires_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run will expire.'),
  "started_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was started.'),
  "cancelled_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was cancelled.'),
  "failed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run failed.'),
  "completed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was completed.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_completion_tokens', 'max_prompt_tokens']).optional().describe('The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.')
}).nullable().describe('Details on why the run is incomplete. Will be `null` if the run is not incomplete.'),
  "model": zod.string().describe('The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "instructions": zod.string().describe('The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(getRunResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(getRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(getRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(getRunResponseToolsMax).optional().describe('The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).').or(zod.null()),
  "temperature": zod.number().nullish().describe('The sampling temperature used for this run. If not set, defaults to 1.'),
  "top_p": zod.number().nullish().describe('The nucleus sampling value used for this run. If not set, defaults to 1.'),
  "max_prompt_tokens": zod.number().min(getRunResponseMaxPromptTokensMin).nullable().describe('The maximum number of prompt tokens specified to have been used over the course of the run.\n'),
  "max_completion_tokens": zod.number().min(getRunResponseMaxCompletionTokensMin).nullable().describe('The maximum number of completion tokens specified to have been used over the course of the run.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
}).describe('Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Modifies a run.
 * @summary Modify run
 */
export const modifyRunParams = zod.object({
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.'),
  "run_id": zod.string().describe('The ID of the run to modify.')
})

export const modifyRunBody = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional()
})

export const modifyRunResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const modifyRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const modifyRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const modifyRunResponseToolsItemFunctionStrictDefaultOne = false;export const modifyRunResponseToolsDefault = [];
export const modifyRunResponseToolsMax = 20;
export const modifyRunResponseMaxPromptTokensMin = 256;
export const modifyRunResponseMaxCompletionTokensMin = 256;
export const modifyRunResponseParallelToolCallsDefault = true;export const modifyRunResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const modifyRunResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run']).describe('The object type, which is always `thread.run`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run was created.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'),
  "status": zod.enum(['queued', 'in_progress', 'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', 'incomplete', 'expired']).describe('The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'),
  "required_action": zod.object({
  "type": zod.enum(['submit_tool_outputs']).describe('For now, this is always `submit_tool_outputs`.'),
  "submit_tool_outputs": zod.object({
  "tool_calls": zod.array(zod.object({
  "id": zod.string().describe('The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'),
  "type": zod.enum(['function']).describe('The type of tool call the output is required for. For now, this is always `function`.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments that the model expects you to pass to the function.')
}).describe('The function definition.')
}).describe('Tool call objects')).describe('A list of the relevant tool calls.')
}).describe('Details on the tool outputs needed for this run to continue.')
}).nullable().describe('Details on the action required to continue the run. Will be `null` if no action is required.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt']).describe('One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).nullable().describe('The last error associated with this run. Will be `null` if there are no errors.'),
  "expires_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run will expire.'),
  "started_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was started.'),
  "cancelled_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was cancelled.'),
  "failed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run failed.'),
  "completed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was completed.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_completion_tokens', 'max_prompt_tokens']).optional().describe('The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.')
}).nullable().describe('Details on why the run is incomplete. Will be `null` if the run is not incomplete.'),
  "model": zod.string().describe('The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "instructions": zod.string().describe('The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(modifyRunResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(modifyRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(modifyRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(modifyRunResponseToolsMax).optional().describe('The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).').or(zod.null()),
  "temperature": zod.number().nullish().describe('The sampling temperature used for this run. If not set, defaults to 1.'),
  "top_p": zod.number().nullish().describe('The nucleus sampling value used for this run. If not set, defaults to 1.'),
  "max_prompt_tokens": zod.number().min(modifyRunResponseMaxPromptTokensMin).nullable().describe('The maximum number of prompt tokens specified to have been used over the course of the run.\n'),
  "max_completion_tokens": zod.number().min(modifyRunResponseMaxCompletionTokensMin).nullable().describe('The maximum number of completion tokens specified to have been used over the course of the run.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
}).describe('Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Cancels a run that is `in_progress`.
 * @summary Cancel a run
 */
export const cancelRunParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to which this run belongs.'),
  "run_id": zod.string().describe('The ID of the run to cancel.')
})

export const cancelRunResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const cancelRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const cancelRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const cancelRunResponseToolsItemFunctionStrictDefaultOne = false;export const cancelRunResponseToolsDefault = [];
export const cancelRunResponseToolsMax = 20;
export const cancelRunResponseMaxPromptTokensMin = 256;
export const cancelRunResponseMaxCompletionTokensMin = 256;
export const cancelRunResponseParallelToolCallsDefault = true;export const cancelRunResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const cancelRunResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run']).describe('The object type, which is always `thread.run`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run was created.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'),
  "status": zod.enum(['queued', 'in_progress', 'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', 'incomplete', 'expired']).describe('The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'),
  "required_action": zod.object({
  "type": zod.enum(['submit_tool_outputs']).describe('For now, this is always `submit_tool_outputs`.'),
  "submit_tool_outputs": zod.object({
  "tool_calls": zod.array(zod.object({
  "id": zod.string().describe('The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'),
  "type": zod.enum(['function']).describe('The type of tool call the output is required for. For now, this is always `function`.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments that the model expects you to pass to the function.')
}).describe('The function definition.')
}).describe('Tool call objects')).describe('A list of the relevant tool calls.')
}).describe('Details on the tool outputs needed for this run to continue.')
}).nullable().describe('Details on the action required to continue the run. Will be `null` if no action is required.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt']).describe('One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).nullable().describe('The last error associated with this run. Will be `null` if there are no errors.'),
  "expires_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run will expire.'),
  "started_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was started.'),
  "cancelled_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was cancelled.'),
  "failed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run failed.'),
  "completed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was completed.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_completion_tokens', 'max_prompt_tokens']).optional().describe('The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.')
}).nullable().describe('Details on why the run is incomplete. Will be `null` if the run is not incomplete.'),
  "model": zod.string().describe('The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "instructions": zod.string().describe('The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(cancelRunResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(cancelRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(cancelRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(cancelRunResponseToolsMax).optional().describe('The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).').or(zod.null()),
  "temperature": zod.number().nullish().describe('The sampling temperature used for this run. If not set, defaults to 1.'),
  "top_p": zod.number().nullish().describe('The nucleus sampling value used for this run. If not set, defaults to 1.'),
  "max_prompt_tokens": zod.number().min(cancelRunResponseMaxPromptTokensMin).nullable().describe('The maximum number of prompt tokens specified to have been used over the course of the run.\n'),
  "max_completion_tokens": zod.number().min(cancelRunResponseMaxCompletionTokensMin).nullable().describe('The maximum number of completion tokens specified to have been used over the course of the run.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
}).describe('Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).')

/**
 * Returns a list of run steps belonging to a run.
 * @summary List run steps
 */
export const listRunStepsParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread the run and run steps belong to.'),
  "run_id": zod.string().describe('The ID of the run the run steps belong to.')
})

export const listRunStepsQueryLimitDefault = 20;export const listRunStepsQueryOrderDefault = "desc";

export const listRunStepsQueryParams = zod.object({
  "limit": zod.number().optional().describe('A limit on the number of objects to be returned. Limit can range between 1 and 100, and the default is 20.\n'),
  "order": zod.enum(['asc', 'desc']).optional().describe('Sort order by the `created_at` timestamp of the objects. `asc` for ascending order and `desc` for descending order.\n'),
  "after": zod.string().optional().describe('A cursor for use in pagination. `after` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can include after=obj_foo in order to fetch the next page of the list.\n'),
  "before": zod.string().optional().describe('A cursor for use in pagination. `before` is an object ID that defines your place in the list. For instance, if you make a list request and receive 100 objects, starting with obj_foo, your subsequent call can include before=obj_foo in order to fetch the previous page of the list.\n'),
  "include[]": zod.array(zod.enum(['step_details.tool_calls[*].file_search.results[*].content'])).optional().describe('A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
})

export const listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchResultsItemScoreMin = 0;

export const listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchResultsItemScoreMax = 1;


export const listRunStepsResponse = zod.object({
  "object": zod.string(),
  "data": zod.array(zod.object({
  "id": zod.string().describe('The identifier of the run step, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run.step']).describe('The object type, which is always `thread.run.step`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step was created.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) associated with the run step.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.'),
  "run_id": zod.string().describe('The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that this run step is a part of.'),
  "type": zod.enum(['message_creation', 'tool_calls']).describe('The type of run step, which can be either `message_creation` or `tool_calls`.'),
  "status": zod.enum(['in_progress', 'cancelled', 'failed', 'completed', 'expired']).describe('The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.'),
  "step_details": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message_creation']).describe('Always `message_creation`.'),
  "message_creation": zod.object({
  "message_id": zod.string().describe('The ID of the message that was created by this run step.')
})
}).describe('Details of the message creation by the run step.'),zod.object({
  "type": zod.enum(['tool_calls']).describe('Always `tool_calls`.'),
  "tool_calls": zod.array(zod.discriminatedUnion('type', [zod.object({
  "id": zod.string().describe('The ID of the tool call.'),
  "type": zod.enum(['code_interpreter']).describe('The type of tool call. This is always going to be `code_interpreter` for this type of tool call.'),
  "code_interpreter": zod.object({
  "input": zod.string().describe('The input to the Code Interpreter tool call.'),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).describe('Always `logs`.'),
  "logs": zod.string().describe('The text output from the Code Interpreter tool call.')
}).describe('Text output from the Code Interpreter tool call as part of a run step.'),zod.object({
  "type": zod.enum(['image']).describe('Always `image`.'),
  "image": zod.object({
  "file_id": zod.string().describe('The [file](https://platform.openai.com/docs/api-reference/files) ID of the image.')
})
})])).describe('The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.')
}).describe('The Code Interpreter tool call definition.')
}).describe('Details of the Code Interpreter tool call the run step was involved in.'),zod.object({
  "id": zod.string().describe('The ID of the tool call object.'),
  "type": zod.enum(['file_search']).describe('The type of tool call. This is always going to be `file_search` for this type of tool call.'),
  "file_search": zod.object({
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMin).max(listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search.'),
  "results": zod.array(zod.object({
  "file_id": zod.string().describe('The ID of the file that result was found in.'),
  "file_name": zod.string().describe('The name of the file that result was found in.'),
  "score": zod.number().min(listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchResultsItemScoreMin).max(listRunStepsResponseDataItemStepDetailsToolCallsItemFileSearchResultsItemScoreMax).describe('The score of the result. All values must be a floating point number between 0 and 1.'),
  "content": zod.array(zod.object({
  "type": zod.enum(['text']).optional().describe('The type of the content.'),
  "text": zod.string().optional().describe('The text content of the file.')
})).optional().describe('The content of the result that was found. The content is only included if requested via the include query parameter.')
}).describe('A result instance of the file search.')).optional().describe('The results of the file search.')
}).describe('For now, this is always going to be an empty object.')
}),zod.object({
  "id": zod.string().describe('The ID of the tool call object.'),
  "type": zod.enum(['function']).describe('The type of tool call. This is always going to be `function` for this type of tool call.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments passed to the function.'),
  "output": zod.string().describe('The output of the function. This will be `null` if the outputs have not been [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) yet.').or(zod.null())
}).describe('The definition of the function that was called.')
})])).describe('An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.\n')
}).describe('Details of the tool call.')]).describe('The details of the run step.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded']).describe('One of `server_error` or `rate_limit_exceeded`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).describe('The last error associated with this run step. Will be `null` if there are no errors.').or(zod.null()),
  "expired_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.').or(zod.null()),
  "cancelled_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step was cancelled.').or(zod.null()),
  "failed_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step failed.').or(zod.null()),
  "completed_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step completed.').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run step.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run step.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run step. This value will be `null` while the run step\'s status is `in_progress`.').or(zod.null())
}).describe('Represents a step in execution of a run.\n')),
  "first_id": zod.string(),
  "last_id": zod.string(),
  "has_more": zod.boolean()
})

/**
 * Retrieves a run step.
 * @summary Retrieve run step
 */
export const getRunStepParams = zod.object({
  "thread_id": zod.string().describe('The ID of the thread to which the run and run step belongs.'),
  "run_id": zod.string().describe('The ID of the run to which the run step belongs.'),
  "step_id": zod.string().describe('The ID of the run step to retrieve.')
})

export const getRunStepQueryParams = zod.object({
  "include[]": zod.array(zod.enum(['step_details.tool_calls[*].file_search.results[*].content'])).optional().describe('A list of additional fields to include in the response. Currently the only supported value is `step_details.tool_calls[*].file_search.results[*].content` to fetch the file search result content.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
})

export const getRunStepResponseStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const getRunStepResponseStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const getRunStepResponseStepDetailsToolCallsItemFileSearchResultsItemScoreMin = 0;

export const getRunStepResponseStepDetailsToolCallsItemFileSearchResultsItemScoreMax = 1;


export const getRunStepResponse = zod.object({
  "id": zod.string().describe('The identifier of the run step, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run.step']).describe('The object type, which is always `thread.run.step`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step was created.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) associated with the run step.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was run.'),
  "run_id": zod.string().describe('The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that this run step is a part of.'),
  "type": zod.enum(['message_creation', 'tool_calls']).describe('The type of run step, which can be either `message_creation` or `tool_calls`.'),
  "status": zod.enum(['in_progress', 'cancelled', 'failed', 'completed', 'expired']).describe('The status of the run step, which can be either `in_progress`, `cancelled`, `failed`, `completed`, or `expired`.'),
  "step_details": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message_creation']).describe('Always `message_creation`.'),
  "message_creation": zod.object({
  "message_id": zod.string().describe('The ID of the message that was created by this run step.')
})
}).describe('Details of the message creation by the run step.'),zod.object({
  "type": zod.enum(['tool_calls']).describe('Always `tool_calls`.'),
  "tool_calls": zod.array(zod.discriminatedUnion('type', [zod.object({
  "id": zod.string().describe('The ID of the tool call.'),
  "type": zod.enum(['code_interpreter']).describe('The type of tool call. This is always going to be `code_interpreter` for this type of tool call.'),
  "code_interpreter": zod.object({
  "input": zod.string().describe('The input to the Code Interpreter tool call.'),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).describe('Always `logs`.'),
  "logs": zod.string().describe('The text output from the Code Interpreter tool call.')
}).describe('Text output from the Code Interpreter tool call as part of a run step.'),zod.object({
  "type": zod.enum(['image']).describe('Always `image`.'),
  "image": zod.object({
  "file_id": zod.string().describe('The [file](https://platform.openai.com/docs/api-reference/files) ID of the image.')
})
})])).describe('The outputs from the Code Interpreter tool call. Code Interpreter can output one or more items, including text (`logs`) or images (`image`). Each of these are represented by a different object type.')
}).describe('The Code Interpreter tool call definition.')
}).describe('Details of the Code Interpreter tool call the run step was involved in.'),zod.object({
  "id": zod.string().describe('The ID of the tool call object.'),
  "type": zod.enum(['file_search']).describe('The type of tool call. This is always going to be `file_search` for this type of tool call.'),
  "file_search": zod.object({
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(getRunStepResponseStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMin).max(getRunStepResponseStepDetailsToolCallsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search.'),
  "results": zod.array(zod.object({
  "file_id": zod.string().describe('The ID of the file that result was found in.'),
  "file_name": zod.string().describe('The name of the file that result was found in.'),
  "score": zod.number().min(getRunStepResponseStepDetailsToolCallsItemFileSearchResultsItemScoreMin).max(getRunStepResponseStepDetailsToolCallsItemFileSearchResultsItemScoreMax).describe('The score of the result. All values must be a floating point number between 0 and 1.'),
  "content": zod.array(zod.object({
  "type": zod.enum(['text']).optional().describe('The type of the content.'),
  "text": zod.string().optional().describe('The text content of the file.')
})).optional().describe('The content of the result that was found. The content is only included if requested via the include query parameter.')
}).describe('A result instance of the file search.')).optional().describe('The results of the file search.')
}).describe('For now, this is always going to be an empty object.')
}),zod.object({
  "id": zod.string().describe('The ID of the tool call object.'),
  "type": zod.enum(['function']).describe('The type of tool call. This is always going to be `function` for this type of tool call.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments passed to the function.'),
  "output": zod.string().describe('The output of the function. This will be `null` if the outputs have not been [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) yet.').or(zod.null())
}).describe('The definition of the function that was called.')
})])).describe('An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.\n')
}).describe('Details of the tool call.')]).describe('The details of the run step.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded']).describe('One of `server_error` or `rate_limit_exceeded`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).describe('The last error associated with this run step. Will be `null` if there are no errors.').or(zod.null()),
  "expired_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step expired. A step is considered expired if the parent run is expired.').or(zod.null()),
  "cancelled_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step was cancelled.').or(zod.null()),
  "failed_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step failed.').or(zod.null()),
  "completed_at": zod.number().describe('The Unix timestamp (in seconds) for when the run step completed.').or(zod.null()),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run step.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run step.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run step. This value will be `null` while the run step\'s status is `in_progress`.').or(zod.null())
}).describe('Represents a step in execution of a run.\n')

/**
 * When a run has the `status: "requires_action"` and `required_action.type` is `submit_tool_outputs`, this endpoint can be used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single request.

 * @summary Submit tool outputs to run
 */
export const submitToolOuputsToRunParams = zod.object({
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) to which this run belongs.'),
  "run_id": zod.string().describe('The ID of the run that requires the tool output submission.')
})

export const submitToolOuputsToRunBody = zod.object({
  "tool_outputs": zod.array(zod.object({
  "tool_call_id": zod.string().optional().describe('The ID of the tool call in the `required_action` object within the run object the output is being submitted for.'),
  "output": zod.string().optional().describe('The output of the tool call to be submitted to continue the run.')
})).describe('A list of tools for which the outputs are being submitted.'),
  "stream": zod.boolean().describe('If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.\n').or(zod.null()).optional()
})

export const submitToolOuputsToRunResponseToolsItemFileSearchMaxNumResultsMax = 50;
export const submitToolOuputsToRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin = 0;

export const submitToolOuputsToRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax = 1;
export const submitToolOuputsToRunResponseToolsItemFunctionStrictDefaultOne = false;export const submitToolOuputsToRunResponseToolsDefault = [];
export const submitToolOuputsToRunResponseToolsMax = 20;
export const submitToolOuputsToRunResponseMaxPromptTokensMin = 256;
export const submitToolOuputsToRunResponseMaxCompletionTokensMin = 256;
export const submitToolOuputsToRunResponseParallelToolCallsDefault = true;export const submitToolOuputsToRunResponseResponseFormatJsonSchemaStrictDefaultOne = false;

export const submitToolOuputsToRunResponse = zod.object({
  "id": zod.string().describe('The identifier, which can be referenced in API endpoints.'),
  "object": zod.enum(['thread.run']).describe('The object type, which is always `thread.run`.'),
  "created_at": zod.number().describe('The Unix timestamp (in seconds) for when the run was created.'),
  "thread_id": zod.string().describe('The ID of the [thread](https://platform.openai.com/docs/api-reference/threads) that was executed on as a part of this run.'),
  "assistant_id": zod.string().describe('The ID of the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for execution of this run.'),
  "status": zod.enum(['queued', 'in_progress', 'requires_action', 'cancelling', 'cancelled', 'failed', 'completed', 'incomplete', 'expired']).describe('The status of the run, which can be either `queued`, `in_progress`, `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`, `incomplete`, or `expired`.'),
  "required_action": zod.object({
  "type": zod.enum(['submit_tool_outputs']).describe('For now, this is always `submit_tool_outputs`.'),
  "submit_tool_outputs": zod.object({
  "tool_calls": zod.array(zod.object({
  "id": zod.string().describe('The ID of the tool call. This ID must be referenced when you submit the tool outputs in using the [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs) endpoint.'),
  "type": zod.enum(['function']).describe('The type of tool call the output is required for. For now, this is always `function`.'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function.'),
  "arguments": zod.string().describe('The arguments that the model expects you to pass to the function.')
}).describe('The function definition.')
}).describe('Tool call objects')).describe('A list of the relevant tool calls.')
}).describe('Details on the tool outputs needed for this run to continue.')
}).nullable().describe('Details on the action required to continue the run. Will be `null` if no action is required.'),
  "last_error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt']).describe('One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'),
  "message": zod.string().describe('A human-readable description of the error.')
}).nullable().describe('The last error associated with this run. Will be `null` if there are no errors.'),
  "expires_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run will expire.'),
  "started_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was started.'),
  "cancelled_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was cancelled.'),
  "failed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run failed.'),
  "completed_at": zod.number().nullable().describe('The Unix timestamp (in seconds) for when the run was completed.'),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_completion_tokens', 'max_prompt_tokens']).optional().describe('The reason why the run is incomplete. This will point to which specific token limit was reached over the course of the run.')
}).nullable().describe('Details on why the run is incomplete. Will be `null` if the run is not incomplete.'),
  "model": zod.string().describe('The model that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "instructions": zod.string().describe('The instructions that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of tool being defined: `code_interpreter`')
}),zod.object({
  "type": zod.enum(['file_search']).describe('The type of tool being defined: `file_search`'),
  "file_search": zod.object({
  "max_num_results": zod.number().min(1).max(submitToolOuputsToRunResponseToolsItemFileSearchMaxNumResultsMax).optional().describe('The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive.\n\nNote that the file search tool may output fewer than `max_num_results` results. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default_2024_08_21']).optional().describe('The ranker to use for the file search. If not specified will use the `auto` ranker.'),
  "score_threshold": zod.number().min(submitToolOuputsToRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMin).max(submitToolOuputsToRunResponseToolsItemFileSearchRankingOptionsScoreThresholdMax).describe('The score threshold for the file search. All values must be a floating point number between 0 and 1.')
}).optional().describe('The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0.\n\nSee the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.\n')
}).optional().describe('Overrides for the file search tool.')
}),zod.object({
  "type": zod.enum(['function']).describe('The type of tool being defined: `function`'),
  "function": zod.object({
  "description": zod.string().optional().describe('A description of what the function does, used by the model to choose when and how to call the function.'),
  "name": zod.string().describe('The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.'),
  "parameters": zod.record(zod.string(), zod.any()).optional().describe('The parameters the functions accepts, described as a JSON Schema object. See the [guide](https://platform.openai.com/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.\n\nOmitting `parameters` defines a function with an empty parameter list.'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](https://platform.openai.com/docs/guides/function-calling).').or(zod.null()).optional()
})
})])).max(submitToolOuputsToRunResponseToolsMax).optional().describe('The list of tools that the [assistant](https://platform.openai.com/docs/api-reference/assistants) used for this run.'),
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()),
  "usage": zod.object({
  "completion_tokens": zod.number().describe('Number of completion tokens used over the course of the run.'),
  "prompt_tokens": zod.number().describe('Number of prompt tokens used over the course of the run.'),
  "total_tokens": zod.number().describe('Total number of tokens used (prompt + completion).')
}).describe('Usage statistics related to the run. This value will be `null` if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.).').or(zod.null()),
  "temperature": zod.number().nullish().describe('The sampling temperature used for this run. If not set, defaults to 1.'),
  "top_p": zod.number().nullish().describe('The nucleus sampling value used for this run. If not set, defaults to 1.'),
  "max_prompt_tokens": zod.number().min(submitToolOuputsToRunResponseMaxPromptTokensMin).nullable().describe('The maximum number of prompt tokens specified to have been used over the course of the run.\n'),
  "max_completion_tokens": zod.number().min(submitToolOuputsToRunResponseMaxCompletionTokensMin).nullable().describe('The maximum number of completion tokens specified to have been used over the course of the run.\n'),
  "truncation_strategy": zod.object({
  "type": zod.enum(['auto', 'last_messages']).describe('The truncation strategy to use for the thread. The default is `auto`. If set to `last_messages`, the thread will be truncated to the n most recent messages in the thread. When set to `auto`, messages in the middle of the thread will be dropped to fit the context length of the model, `max_prompt_tokens`.'),
  "last_messages": zod.number().min(1).describe('The number of most recent messages from the thread when constructing the context for the run.').or(zod.null()).optional()
}).describe('Controls for how a thread will be truncated prior to the run. Use this to control the initial context window of the run.').and(zod.any().nullable()),
  "tool_choice": zod.enum(['none', 'auto', 'required']).describe('`none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.\n').or(zod.object({
  "type": zod.enum(['function', 'code_interpreter', 'file_search']).describe('The type of the tool. If type is `function`, the function name must be set'),
  "function": zod.object({
  "name": zod.string().describe('The name of the function to call.')
}).optional()
}).describe('Specifies a tool the model should use. Use to force the model to call a specific tool.')).describe('Controls which (if any) tool is called by the model.\n`none` means the model will not call any tools and instead generates a message.\n`auto` is the default value and means the model can pick between generating a message or calling one or more tools.\n`required` means the model must call one or more tools before responding to the user.\nSpecifying a particular tool like `{\"type\": \"file_search\"}` or `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to call that tool.\n').and(zod.any().nullable()),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to enable [parallel function calling](https://platform.openai.com/docs/guides/function-calling#configuring-parallel-function-calling) during tool use.'),
  "response_format": zod.enum(['auto']).describe('`auto` is the default value\n').or(zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n')).or(zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')).or(zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "json_schema": zod.object({
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).optional().describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('Structured Outputs configuration options, including a JSON Schema.\n')
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n')).describe('Specifies the format that the model must output. Compatible with [GPT-4o](https://platform.openai.com/docs/models#gpt-4o), [GPT-4 Turbo](https://platform.openai.com/docs/models#gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n\nSetting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured Outputs which ensures the model will match your supplied JSON schema. Learn more in the [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nSetting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the message the model generates is valid JSON.\n\n**Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly \"stuck\" request. Also note that the message content may be partially cut off if `finish_reason=\"length\"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.\n')
}).describe('Represents an execution run on a [thread](https://platform.openai.com/docs/api-reference/threads).')

