/**
 * Generated by orval v7.7.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import {
  z as zod
} from 'zod';


/**
 * Creates an edited or extended image given one or more source images and a prompt. This endpoint only supports `gpt-image-1` and `dall-e-2`.
 * @summary Create image edit
 */
export const createImageEditBodyImageMaxTwo = 16;
export const createImageEditBodyBackgroundDefault = "auto";export const createImageEditBodyNDefault = 1;
export const createImageEditBodyNMax = 10;
export const createImageEditBodySizeDefault = "1024x1024";export const createImageEditBodyResponseFormatDefault = "url";export const createImageEditBodyOutputFormatDefault = "png";export const createImageEditBodyOutputCompressionDefault = 100;export const createImageEditBodyStreamDefault = false;export const createImageEditBodyPartialImagesDefaultOne = 0;export const createImageEditBodyPartialImagesMinOne = 0;
export const createImageEditBodyPartialImagesMaxOne = 3;
export const createImageEditBodyQualityDefault = "auto";

export const createImageEditBody = zod.object({
  "image": zod.instanceof(File).or(zod.array(zod.instanceof(File)).max(createImageEditBodyImageMaxTwo)).describe('The image(s) to edit. Must be a supported image file or an array of images.\n\nFor `gpt-image-1`, each image should be a `png`, `webp`, or `jpg` file less\nthan 50MB. You can provide up to 16 images.\n\nFor `dall-e-2`, you can only provide one image, and it should be a square\n`png` file less than 4MB.\n'),
  "prompt": zod.string().describe('A text description of the desired image(s). The maximum length is 1000 characters for `dall-e-2`, and 32000 characters for `gpt-image-1`.'),
  "mask": zod.instanceof(File).optional().describe('An additional image whose fully transparent areas (e.g. where alpha is zero) indicate where `image` should be edited. If there are multiple images provided, the mask will be applied on the first image. Must be a valid PNG file, less than 4MB, and have the same dimensions as `image`.'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Allows to set transparency for the background of the generated image(s).\nThis parameter is only supported for `gpt-image-1`. Must be one of\n`transparent`, `opaque` or `auto` (default value). When `auto` is used, the\nmodel will automatically determine the best background for the image.\n\nIf `transparent`, the output format needs to support transparency, so it\nshould be set to either `png` (default value) or `webp`.\n'),
  "model": zod.string().or(zod.enum(['dall-e-2', 'gpt-image-1', 'gpt-image-1-mini'])).nullish().describe('The model to use for image generation. Only `dall-e-2` and `gpt-image-1` are supported. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.'),
  "n": zod.number().min(1).max(createImageEditBodyNMax).optional().describe('The number of images to generate. Must be between 1 and 10.'),
  "size": zod.enum(['256x256', '512x512', '1024x1024', '1536x1024', '1024x1536', 'auto']).optional().describe('The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, and one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`.'),
  "response_format": zod.enum(['url', 'b64_json']).optional().describe('The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter is only supported for `dall-e-2`, as `gpt-image-1` will always return base64-encoded images.'),
  "output_format": zod.enum(['png', 'jpeg', 'webp']).optional().describe('The format in which the generated images are returned. This parameter is\nonly supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.\nThe default value is `png`.\n'),
  "output_compression": zod.number().optional().describe('The compression level (0-100%) for the generated images. This parameter\nis only supported for `gpt-image-1` with the `webp` or `jpeg` output\nformats, and defaults to 100.\n'),
  "user": zod.string().optional().describe('A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "stream": zod.boolean().nullish().describe('Edit the image in streaming mode. Defaults to `false`. See the\n[Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.\n'),
  "partial_images": zod.number().min(createImageEditBodyPartialImagesMinOne).max(createImageEditBodyPartialImagesMaxOne).optional().describe('The number of partial images to generate. This parameter is used for\nstreaming responses that return partial images. Value must be between 0 and 3.\nWhen set to 0, the response will be a single image sent in one streaming event.\n\nNote that the final image may be sent before the full number of partial images\nare generated if the full image is generated more quickly.\n').or(zod.null()).optional(),
  "quality": zod.enum(['standard', 'low', 'medium', 'high', 'auto']).optional().describe('The quality of the image that will be generated. `high`, `medium` and `low` are only supported for `gpt-image-1`. `dall-e-2` only supports `standard` quality. Defaults to `auto`.\n')
})

export const createImageEditResponse = zod.object({
  "created": zod.number().describe('The Unix timestamp (in seconds) of when the image was created.'),
  "data": zod.array(zod.object({
  "b64_json": zod.string().optional().describe('The base64-encoded JSON of the generated image. Default value for `gpt-image-1`, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.'),
  "url": zod.string().optional().describe('When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for `gpt-image-1`.'),
  "revised_prompt": zod.string().optional().describe('For `dall-e-3` only, the revised prompt that was used to generate the image.')
}).describe('Represents the content or the URL of an image generated by the OpenAI API.')).optional().describe('The list of generated images.'),
  "background": zod.enum(['transparent', 'opaque']).optional().describe('The background parameter used for the image generation. Either `transparent` or `opaque`.'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the image generation. Either `png`, `webp`, or `jpeg`.'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024']).optional().describe('The size of the image generated. Either `1024x1024`, `1024x1536`, or `1536x1024`.'),
  "quality": zod.enum(['low', 'medium', 'high']).optional().describe('The quality of the image generated. Either `low`, `medium`, or `high`.'),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of tokens (images and text) in the input prompt.'),
  "total_tokens": zod.number().describe('The total number of tokens (images and text) used for the image generation.'),
  "output_tokens": zod.number().describe('The number of output tokens generated by the model.'),
  "input_tokens_details": zod.object({
  "text_tokens": zod.number().describe('The number of text tokens in the input prompt.'),
  "image_tokens": zod.number().describe('The number of image tokens in the input prompt.')
}).describe('The input tokens detailed information for the image generation.')
}).optional().describe('For `gpt-image-1` only, the token usage information for the image generation.')
}).describe('The response from the image generation endpoint.')

/**
 * Creates an image given a prompt. [Learn more](https://platform.openai.com/docs/guides/images).

 * @summary Create image
 */
export const createImageBodyNDefault = 1;
export const createImageBodyNMax = 10;
export const createImageBodyQualityDefault = "auto";export const createImageBodyResponseFormatDefault = "url";export const createImageBodyOutputFormatDefault = "png";export const createImageBodyOutputCompressionDefault = 100;export const createImageBodyStreamDefault = false;export const createImageBodyPartialImagesDefaultOne = 0;export const createImageBodyPartialImagesMinOne = 0;
export const createImageBodyPartialImagesMaxOne = 3;
export const createImageBodySizeDefault = "auto";export const createImageBodyModerationDefault = "auto";export const createImageBodyBackgroundDefault = "auto";export const createImageBodyStyleDefault = "vivid";

export const createImageBody = zod.object({
  "prompt": zod.string().describe('A text description of the desired image(s). The maximum length is 32000 characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters for `dall-e-3`.'),
  "model": zod.string().or(zod.enum(['dall-e-2', 'dall-e-3', 'gpt-image-1', 'gpt-image-1-mini'])).nullish().describe('The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to `gpt-image-1` is used.'),
  "n": zod.number().min(1).max(createImageBodyNMax).optional().describe('The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only `n=1` is supported.'),
  "quality": zod.enum(['standard', 'hd', 'low', 'medium', 'high', 'auto']).optional().describe('The quality of the image that will be generated.\n\n- `auto` (default value) will automatically select the best quality for the given model.\n- `high`, `medium` and `low` are supported for `gpt-image-1`.\n- `hd` and `standard` are supported for `dall-e-3`.\n- `standard` is the only option for `dall-e-2`.\n'),
  "response_format": zod.enum(['url', 'b64_json']).optional().describe('The format in which generated images with `dall-e-2` and `dall-e-3` are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated. This parameter isn\'t supported for `gpt-image-1` which will always return base64-encoded images.'),
  "output_format": zod.enum(['png', 'jpeg', 'webp']).optional().describe('The format in which the generated images are returned. This parameter is only supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.'),
  "output_compression": zod.number().optional().describe('The compression level (0-100%) for the generated images. This parameter is only supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and defaults to 100.'),
  "stream": zod.boolean().nullish().describe('Generate the image in streaming mode. Defaults to `false`. See the\n[Image generation guide](https://platform.openai.com/docs/guides/image-generation) for more information.\nThis parameter is only supported for `gpt-image-1`.\n'),
  "partial_images": zod.number().min(createImageBodyPartialImagesMinOne).max(createImageBodyPartialImagesMaxOne).optional().describe('The number of partial images to generate. This parameter is used for\nstreaming responses that return partial images. Value must be between 0 and 3.\nWhen set to 0, the response will be a single image sent in one streaming event.\n\nNote that the final image may be sent before the full number of partial images\nare generated if the full image is generated more quickly.\n').or(zod.null()).optional(),
  "size": zod.enum(['auto', '1024x1024', '1536x1024', '1024x1536', '256x256', '512x512', '1792x1024', '1024x1792']).optional().describe('The size of the generated images. Must be one of `1024x1024`, `1536x1024` (landscape), `1024x1536` (portrait), or `auto` (default value) for `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.'),
  "moderation": zod.enum(['low', 'auto']).optional().describe('Control the content-moderation level for images generated by `gpt-image-1`. Must be either `low` for less restrictive filtering or `auto` (default value).'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Allows to set transparency for the background of the generated image(s).\nThis parameter is only supported for `gpt-image-1`. Must be one of\n`transparent`, `opaque` or `auto` (default value). When `auto` is used, the\nmodel will automatically determine the best background for the image.\n\nIf `transparent`, the output format needs to support transparency, so it\nshould be set to either `png` (default value) or `webp`.\n'),
  "style": zod.enum(['vivid', 'natural']).optional().describe('The style of the generated images. This parameter is only supported for `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.'),
  "user": zod.string().optional().describe('A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n')
})

export const createImageResponse = zod.object({
  "created": zod.number().describe('The Unix timestamp (in seconds) of when the image was created.'),
  "data": zod.array(zod.object({
  "b64_json": zod.string().optional().describe('The base64-encoded JSON of the generated image. Default value for `gpt-image-1`, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.'),
  "url": zod.string().optional().describe('When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for `gpt-image-1`.'),
  "revised_prompt": zod.string().optional().describe('For `dall-e-3` only, the revised prompt that was used to generate the image.')
}).describe('Represents the content or the URL of an image generated by the OpenAI API.')).optional().describe('The list of generated images.'),
  "background": zod.enum(['transparent', 'opaque']).optional().describe('The background parameter used for the image generation. Either `transparent` or `opaque`.'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the image generation. Either `png`, `webp`, or `jpeg`.'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024']).optional().describe('The size of the image generated. Either `1024x1024`, `1024x1536`, or `1536x1024`.'),
  "quality": zod.enum(['low', 'medium', 'high']).optional().describe('The quality of the image generated. Either `low`, `medium`, or `high`.'),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of tokens (images and text) in the input prompt.'),
  "total_tokens": zod.number().describe('The total number of tokens (images and text) used for the image generation.'),
  "output_tokens": zod.number().describe('The number of output tokens generated by the model.'),
  "input_tokens_details": zod.object({
  "text_tokens": zod.number().describe('The number of text tokens in the input prompt.'),
  "image_tokens": zod.number().describe('The number of image tokens in the input prompt.')
}).describe('The input tokens detailed information for the image generation.')
}).optional().describe('For `gpt-image-1` only, the token usage information for the image generation.')
}).describe('The response from the image generation endpoint.')

/**
 * Creates a variation of a given image. This endpoint only supports `dall-e-2`.
 * @summary Create image variation
 */
export const createImageVariationBodyNDefault = 1;
export const createImageVariationBodyNMax = 10;
export const createImageVariationBodyResponseFormatDefault = "url";export const createImageVariationBodySizeDefault = "1024x1024";

export const createImageVariationBody = zod.object({
  "image": zod.instanceof(File).describe('The image to use as the basis for the variation(s). Must be a valid PNG file, less than 4MB, and square.'),
  "model": zod.string().or(zod.enum(['dall-e-2'])).nullish().describe('The model to use for image generation. Only `dall-e-2` is supported at this time.'),
  "n": zod.number().min(1).max(createImageVariationBodyNMax).optional().describe('The number of images to generate. Must be between 1 and 10.'),
  "response_format": zod.enum(['url', 'b64_json']).optional().describe('The format in which the generated images are returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes after the image has been generated.'),
  "size": zod.enum(['256x256', '512x512', '1024x1024']).optional().describe('The size of the generated images. Must be one of `256x256`, `512x512`, or `1024x1024`.'),
  "user": zod.string().optional().describe('A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n')
})

export const createImageVariationResponse = zod.object({
  "created": zod.number().describe('The Unix timestamp (in seconds) of when the image was created.'),
  "data": zod.array(zod.object({
  "b64_json": zod.string().optional().describe('The base64-encoded JSON of the generated image. Default value for `gpt-image-1`, and only present if `response_format` is set to `b64_json` for `dall-e-2` and `dall-e-3`.'),
  "url": zod.string().optional().describe('When using `dall-e-2` or `dall-e-3`, the URL of the generated image if `response_format` is set to `url` (default value). Unsupported for `gpt-image-1`.'),
  "revised_prompt": zod.string().optional().describe('For `dall-e-3` only, the revised prompt that was used to generate the image.')
}).describe('Represents the content or the URL of an image generated by the OpenAI API.')).optional().describe('The list of generated images.'),
  "background": zod.enum(['transparent', 'opaque']).optional().describe('The background parameter used for the image generation. Either `transparent` or `opaque`.'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the image generation. Either `png`, `webp`, or `jpeg`.'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024']).optional().describe('The size of the image generated. Either `1024x1024`, `1024x1536`, or `1536x1024`.'),
  "quality": zod.enum(['low', 'medium', 'high']).optional().describe('The quality of the image generated. Either `low`, `medium`, or `high`.'),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of tokens (images and text) in the input prompt.'),
  "total_tokens": zod.number().describe('The total number of tokens (images and text) used for the image generation.'),
  "output_tokens": zod.number().describe('The number of output tokens generated by the model.'),
  "input_tokens_details": zod.object({
  "text_tokens": zod.number().describe('The number of text tokens in the input prompt.'),
  "image_tokens": zod.number().describe('The number of image tokens in the input prompt.')
}).describe('The input tokens detailed information for the image generation.')
}).optional().describe('For `gpt-image-1` only, the token usage information for the image generation.')
}).describe('The response from the image generation endpoint.')

