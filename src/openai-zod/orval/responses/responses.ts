/**
 * Generated by orval v7.7.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import {
  z as zod
} from 'zod';


/**
 * Creates a model response. Provide [text](https://platform.openai.com/docs/guides/text) or
[image](https://platform.openai.com/docs/guides/images) inputs to generate [text](https://platform.openai.com/docs/guides/text)
or [JSON](https://platform.openai.com/docs/guides/structured-outputs) outputs. Have the model call
your own [custom code](https://platform.openai.com/docs/guides/function-calling) or use built-in
[tools](https://platform.openai.com/docs/guides/tools) like [web search](https://platform.openai.com/docs/guides/tools-web-search)
or [file search](https://platform.openai.com/docs/guides/tools-file-search) to use your own data
as input for the model's response.

 * @summary Create a model response
 */
export const createResponseBodyTopLogprobsMinOne = 0;
export const createResponseBodyTopLogprobsMaxOne = 20;
export const createResponseBodyTemperatureDefaultOne = 1;export const createResponseBodyTemperatureMinOne = 0;
export const createResponseBodyTemperatureMaxOne = 2;
export const createResponseBodyTopPDefaultOne = 1;export const createResponseBodyTopPMinOne = 0;
export const createResponseBodyTopPMaxOne = 1;
export const createResponseBodyServiceTierDefaultOne = "auto";export const createResponseBodyTopLogprobsMinThree = 0;

export const createResponseBodyTopLogprobsMaxThree = 20;
export const createResponseBodyReasoningEffortDefaultOne = "medium";export const createResponseBodyBackgroundDefaultOne = false;export const createResponseBodyTextFormatStrictDefaultOne = false;export const createResponseBodyTextVerbosityDefaultOne = "medium";export const createResponseBodyToolsItemTypeDefault = "function";export const createResponseBodyToolsItemTypeDefaultOne = "file_search";export const createResponseBodyToolsItemFiltersTypeDefault = "eq";export const createResponseBodyToolsItemFiltersFiltersItemTypeDefault = "eq";export const createResponseBodyToolsItemTypeDefaultTwo = "computer_use_preview";export const createResponseBodyToolsItemTypeDefaultThree = "web_search";export const createResponseBodyToolsItemFiltersAllowedDomainsDefaultOne = [];export const createResponseBodyToolsItemUserLocationTypeDefault = "approximate";export const createResponseBodyToolsItemSearchContextSizeDefault = "medium";export const createResponseBodyToolsItemRequireApprovalDefaultOne = "always";export const createResponseBodyToolsItemContainerTypeDefault = "auto";export const createResponseBodyToolsItemContainerFileIdsMax = 50;
export const createResponseBodyToolsItemModelDefault = "gpt-image-1";export const createResponseBodyToolsItemQualityDefault = "auto";export const createResponseBodyToolsItemSizeDefault = "auto";export const createResponseBodyToolsItemOutputFormatDefault = "png";export const createResponseBodyToolsItemOutputCompressionDefault = 100;
export const createResponseBodyToolsItemOutputCompressionMin = 0;

export const createResponseBodyToolsItemOutputCompressionMax = 100;
export const createResponseBodyToolsItemModerationDefault = "auto";export const createResponseBodyToolsItemBackgroundDefault = "auto";export const createResponseBodyToolsItemPartialImagesDefault = 0;
export const createResponseBodyToolsItemPartialImagesMin = 0;

export const createResponseBodyToolsItemPartialImagesMax = 3;
export const createResponseBodyToolsItemTypeDefaultSeven = "local_shell";export const createResponseBodyToolsItemTypeDefaultEight = "custom";export const createResponseBodyToolsItemFormatTypeDefault = "text";export const createResponseBodyToolsItemFormatTypeDefaultOne = "grammar";export const createResponseBodyToolsItemTypeDefaultNine = "web_search_preview";export const createResponseBodyToolsItemUserLocationTypeDefaultOne = "approximate";export const createResponseBodyPromptVariablesTypeDefault = "input_text";export const createResponseBodyPromptVariablesTypeDefaultOne = "input_image";export const createResponseBodyPromptVariablesTypeDefaultTwo = "input_file";export const createResponseBodyTruncationDefaultOne = "disabled";export const createResponseBodyInputItemContentItemTypeDefault = "input_text";export const createResponseBodyInputItemContentItemTypeDefaultOne = "input_image";export const createResponseBodyInputItemContentItemTypeDefaultTwo = "input_file";export const createResponseBodyInputItemContentItemTypeDefaultFour = "input_text";export const createResponseBodyInputItemContentItemTypeDefaultFive = "input_image";export const createResponseBodyInputItemContentItemTypeDefaultSix = "input_file";export const createResponseBodyInputItemContentItemTypeDefaultEight = "output_text";export const createResponseBodyInputItemContentItemAnnotationsItemTypeDefault = "file_citation";export const createResponseBodyInputItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const createResponseBodyInputItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const createResponseBodyInputItemContentItemTypeDefaultNine = "refusal";export const createResponseBodyInputItemResultsItemAttributesMaxThree = 512;
export const createResponseBodyInputItemTypeDefaultFour = "computer_call";export const createResponseBodyInputItemActionTypeDefault = "click";export const createResponseBodyInputItemActionTypeDefaultOne = "double_click";export const createResponseBodyInputItemActionTypeDefaultTwo = "drag";export const createResponseBodyInputItemActionTypeDefaultThree = "keypress";export const createResponseBodyInputItemActionTypeDefaultFour = "move";export const createResponseBodyInputItemActionTypeDefaultFive = "screenshot";export const createResponseBodyInputItemActionTypeDefaultSix = "scroll";export const createResponseBodyInputItemActionTypeDefaultSeven = "type";export const createResponseBodyInputItemActionTypeDefaultEight = "wait";export const createResponseBodyInputItemCallIdMaxOne = 64;
export const createResponseBodyInputItemTypeDefaultFive = "computer_call_output";export const createResponseBodyInputItemOutputTypeDefault = "computer_screenshot";export const createResponseBodyInputItemCallIdMaxThree = 64;
export const createResponseBodyInputItemTypeDefaultEight = "function_call_output";export const createResponseBodyInputItemOutputMaxTwo = 10485760;
export const createResponseBodyInputItemOutputItemTypeDefault = "input_text";export const createResponseBodyInputItemOutputItemTextMax = 10485760;
export const createResponseBodyInputItemOutputItemTypeDefaultOne = "input_image";export const createResponseBodyInputItemOutputItemImageUrlMaxOne = 20971520;
export const createResponseBodyInputItemOutputItemTypeDefaultTwo = "input_file";export const createResponseBodyInputItemOutputItemFileDataMaxOne = 33554432;
export const createResponseBodyInputItemSummaryItemTypeDefault = "summary_text";export const createResponseBodyInputItemContentItemTypeDefaultOnezero = "reasoning_text";export const createResponseBodyInputItemTypeDefaultOneone = "code_interpreter_call";export const createResponseBodyInputItemOutputsItemTypeDefault = "logs";export const createResponseBodyInputItemOutputsItemTypeDefaultOne = "image";export const createResponseBodyInputItemActionTypeDefaultOnetwo = "exec";export const createResponseBodyInputItemOutputItemTypeDefaultThree = "input_text";export const createResponseBodyInputItemOutputItemTypeDefaultFour = "input_image";export const createResponseBodyInputItemOutputItemTypeDefaultFive = "input_file";export const createResponseBodyInputItemTypeDefaultTwoone = "item_reference";export const createResponseBodyParallelToolCallsDefaultOne = true;export const createResponseBodyStoreDefaultOne = true;export const createResponseBodyStreamDefaultOne = false;

export const createResponseBody = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "top_logprobs": zod.number().min(createResponseBodyTopLogprobsMinOne).max(createResponseBodyTopLogprobsMaxOne).describe('An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(createResponseBodyTemperatureMinOne).max(createResponseBodyTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(createResponseBodyTopPMinOne).max(createResponseBodyTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.\n').or(zod.null()).optional(),
  "user": zod.string().optional().describe('This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations.\nA stable identifier for your end-users.\nUsed to boost cache hit rates by better bucketing similar requests and  to help OpenAI detect and prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "safety_identifier": zod.string().optional().describe('A stable identifier used to help detect users of your application that may be violating OpenAI\'s usage policies.\nThe IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "prompt_cache_key": zod.string().optional().describe('Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n'),
  "service_tier": zod.enum(['auto', 'default', 'flex', 'scale', 'priority']).optional().describe('Specifies the processing type used for serving the request.\n  - If set to \'auto\', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use \'default\'.\n  - If set to \'default\', then the request will be processed with the standard pricing and performance for the selected model.\n  - If set to \'[flex](https://platform.openai.com/docs/guides/flex-processing)\' or \'[priority](https://openai.com/api-priority-processing/)\', then the request will be processed with the corresponding service tier.\n  - When not set, the default behavior is \'auto\'.\n\n  When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.\n').or(zod.null()).optional()
}).and(zod.object({
  "top_logprobs": zod.number().min(createResponseBodyTopLogprobsMinThree).max(createResponseBodyTopLogprobsMaxThree).optional().describe('An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n')
})).and(zod.object({
  "previous_response_id": zod.string().describe('The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](https://platform.openai.com/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.\n').or(zod.null()).optional(),
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-5-chat-latest', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'o4-mini', 'o4-mini-2025-04-16', 'o3', 'o3-2025-04-16', 'o3-mini', 'o3-mini-2025-01-31', 'o1', 'o1-2024-12-17', 'o1-preview', 'o1-preview-2024-09-12', 'o1-mini', 'o1-mini-2024-09-12', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-audio-preview', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-audio-preview-2025-06-03', 'gpt-4o-mini-audio-preview', 'gpt-4o-mini-audio-preview-2024-12-17', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-mini-search-preview-2025-03-11', 'chatgpt-4o-latest', 'codex-mini-latest', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).or(zod.enum(['o1-pro', 'o1-pro-2025-03-19', 'o3-pro', 'o3-pro-2025-06-10', 'o3-deep-research', 'o3-deep-research-2025-06-26', 'o4-mini-deep-research', 'o4-mini-deep-research-2025-06-26', 'computer-use-preview', 'computer-use-preview-2025-03-11', 'gpt-5-codex', 'gpt-5-pro', 'gpt-5-pro-2025-10-06'])).optional(),
  "reasoning": zod.object({
  "effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "summary": zod.enum(['auto', 'concise', 'detailed']).describe('A summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional(),
  "generate_summary": zod.enum(['auto', 'concise', 'detailed']).describe('**Deprecated:** use `summary` instead.\n\nA summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional()
}).describe('**gpt-5 and o-series models only**\n\nConfiguration options for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "background": zod.boolean().optional().describe('Whether to run the model response in the background.\n[Learn more](https://platform.openai.com/docs/guides/background).\n').or(zod.null()).optional(),
  "max_output_tokens": zod.number().describe('An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "max_tool_calls": zod.number().describe('The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.\n').or(zod.null()).optional(),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "verbosity": zod.enum(['low', 'medium', 'high']).optional().describe('Constrains the verbosity of the model\'s response. Lower values will result in\nmore concise responses, while higher values will result in more verbose responses.\nCurrently supported values are `low`, `medium`, and `high`.\n').or(zod.null()).optional()
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(createResponseBodyToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(createResponseBodyToolsItemOutputCompressionMin).max(createResponseBodyToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(createResponseBodyToolsItemPartialImagesMin).max(createResponseBodyToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nWe support the following categories of tools:\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **MCP Tools**: Integrations with third-party systems via custom MCP servers\n  or predefined connectors such as Google Drive and SharePoint. Learn more about\n  [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code with strongly typed arguments\n  and outputs. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling). You can also use\n  custom tools to call your own code.\n'),
  "tool_choice": zod.discriminatedUnion('type', [.enum(['none', 'auto', 'required']).describe('Controls which (if any) tool is called by the model.\n\n`none` means the model will not call any tool and instead generates a message.\n\n`auto` means the model can pick between generating a message or calling one or\nmore tools.\n\n`required` means the model must call one or more tools.\n'),zod.object({
  "type": zod.enum(['allowed_tools']).describe('Allowed tool configuration type. Always `allowed_tools`.'),
  "mode": zod.enum(['auto', 'required']).describe('Constrains the tools available to the model to a pre-defined set.\n\n`auto` allows the model to pick from among the allowed tools and generate a\nmessage.\n\n`required` requires the model to call one or more of the allowed tools.\n'),
  "tools": zod.array(zod.record(zod.string(), zod.any()).describe('A tool definition that the model should be allowed to call.\n')).describe('A list of tool definitions that the model should be allowed to call.\n\nFor the Responses API, the list of tool definitions might look like:\n```json\n[\n  { \"type\": \"function\", \"name\": \"get_weather\" },\n  { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n  { \"type\": \"image_generation\" }\n]\n```\n')
}).describe('Constrains the tools available to the model to a pre-defined set.\n'),zod.object({
  "type": zod.enum(['file_search', 'web_search_preview', 'computer_use_preview', 'web_search_preview_2025_03_11', 'image_generation', 'code_interpreter']).describe('The type of hosted tool the model should to use. Learn more about\n[built-in tools](https://platform.openai.com/docs/guides/tools).\n\nAllowed values are:\n- `file_search`\n- `web_search_preview`\n- `computer_use_preview`\n- `code_interpreter`\n- `image_generation`\n')
}).describe('Indicates that the model should use a built-in tool to generate a response.\n[Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n'),zod.object({
  "type": zod.enum(['function']).describe('For function calling, the type is always `function`.'),
  "name": zod.string().describe('The name of the function to call.')
}).describe('Use this option to force the model to call a specific function.\n'),zod.object({
  "type": zod.enum(['mcp']).describe('For MCP tools, the type is always `mcp`.'),
  "server_label": zod.string().describe('The label of the MCP server to use.\n'),
  "name": zod.string().describe('The name of the tool to call on the server.\n').or(zod.null()).optional()
}).describe('Use this option to force the model to call a specific tool on a remote MCP server.\n'),zod.object({
  "type": zod.enum(['custom']).describe('For custom tool calling, the type is always `custom`.'),
  "name": zod.string().describe('The name of the custom tool to call.')
}).describe('Use this option to force the model to call a specific custom tool.\n')]).optional().describe('How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call.\n'),
  "prompt": zod.object({
  "id": zod.string().describe('The unique identifier of the prompt template to use.'),
  "version": zod.string().describe('Optional version of the prompt template.').or(zod.null()).optional(),
  "variables": zod.record(zod.string(), zod.string().or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).')).or(zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'))).describe('Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.\n').or(zod.null()).optional()
}).describe('Reference to a prompt template and its variables.\n[Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n').or(zod.null()).optional(),
  "truncation": zod.enum(['auto', 'disabled']).optional().describe('The truncation strategy to use for the model response.\n- `auto`: If the input to this Response exceeds\n  the model\'s context window size, the model will truncate the\n  response to fit the context window by dropping items from the beginning of the conversation.\n- `disabled` (default): If the input size will exceed the context window\n  size for a model, the request will fail with a 400 error.\n').or(zod.null()).optional()
})).and(zod.object({
  "input": zod.string().describe('A text input to the model, equivalent to a text input with the\n`user` role.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'),zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always set to `message`.\n'),
  "role": zod.enum(['user', 'system', 'developer']).describe('The role of the message input. One of `user`, `system`, or `developer`.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(createResponseBodyInputItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "id": zod.string().describe('The ID of the computer tool call output.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createResponseBodyInputItemCallIdMaxOne).describe('The ID of the computer tool call that produced the output.'),
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The safety checks reported by the API that have been acknowledged by the developer.').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a computer tool call.'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the function tool call output. Populated when this item is returned via API.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createResponseBodyInputItemCallIdMaxThree).describe('The unique ID of the function tool call generated by the model.'),
  "type": zod.enum(['function_call_output']).optional().describe('The type of the function tool call output. Always `function_call_output`.'),
  "output": zod.string().max(createResponseBodyInputItemOutputMaxTwo).describe('A JSON string of the output of the function tool call.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().max(createResponseBodyInputItemOutputItemTextMax).describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().max(createResponseBodyInputItemOutputItemImageUrlMaxOne).describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto']).or(zod.null()).optional()
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision)'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().describe('The name of the file to be sent to the model.').or(zod.null()).optional(),
  "file_data": zod.string().max(createResponseBodyInputItemOutputItemFileDataMaxOne).describe('The base64-encoded data of the file to be sent to the model.').or(zod.null()).optional(),
  "file_url": zod.string().describe('The URL of the file to be sent to the model.').or(zod.null()).optional()
}).describe('A file input to the model.')]))).describe('Text, image, or file output of the function tool call.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a function tool call.'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n').or(zod.null()).optional(),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')]).describe('Content item used to generate a response.\n'),zod.object({
  "type": zod.enum(['item_reference']).optional().describe('The type of item to reference. Always `item_reference`.').or(zod.null()).optional(),
  "id": zod.string().describe('The ID of the item to reference.')
}).describe('An internal identifier for an item to reference.')])).describe('A list of one or many input items to the model, containing\ndifferent content types.\n')).optional().describe('Text, image, or file inputs to the model, used to generate a response.\n\nLearn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Image inputs](https://platform.openai.com/docs/guides/images)\n- [File inputs](https://platform.openai.com/docs/guides/pdf-files)\n- [Conversation state](https://platform.openai.com/docs/guides/conversation-state)\n- [Function calling](https://platform.openai.com/docs/guides/function-calling)\n'),
  "include": zod.array(zod.enum(['file_search_call.results', 'web_search_call.results', 'web_search_call.action.sources', 'message.input_image.image_url', 'computer_call_output.output.image_url', 'code_interpreter_call.outputs', 'reasoning.encrypted_content', 'message.output_text.logprobs']).describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).')).describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).').or(zod.null()).optional(),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to allow the model to run tool calls in parallel.\n').or(zod.null()).optional(),
  "store": zod.boolean().optional().describe('Whether to store the generated model response for later retrieval via\nAPI.\n').or(zod.null()).optional(),
  "instructions": zod.string().describe('A system (or developer) message inserted into the model\'s context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.\n').or(zod.null()).optional(),
  "stream": zod.boolean().optional().describe('If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\nfor more information.\n').or(zod.null()).optional(),
  "stream_options": zod.object({
  "include_obfuscation": zod.boolean().optional().describe('When true, stream obfuscation will be enabled. Stream obfuscation adds\nrandom characters to an `obfuscation` field on streaming delta events to\nnormalize payload sizes as a mitigation to certain side-channel attacks.\nThese obfuscation fields are included by default, but add a small amount\nof overhead to the data stream. You can set `include_obfuscation` to\nfalse to optimize for bandwidth if you trust the network links between\nyour application and the OpenAI API.\n')
}).describe('Options for streaming responses. Only set this when you set `stream: true`.\n').or(zod.null()).optional(),
  "conversation": zod.string().describe('The unique ID of the conversation.\n').or(zod.object({
  "id": zod.string().describe('The unique ID of the conversation.')
}).describe('The conversation that this response belongs to.')).describe('The conversation that this response belongs to. Items from this conversation are prepended to `input_items` for this response request.\nInput items and output items from this response are automatically added to this conversation after this response completes.\n').or(zod.null()).optional()
}))

export const createResponseResponseTopLogprobsMinOne = 0;
export const createResponseResponseTopLogprobsMaxOne = 20;
export const createResponseResponseTemperatureDefaultOne = 1;export const createResponseResponseTemperatureMinOne = 0;
export const createResponseResponseTemperatureMaxOne = 2;
export const createResponseResponseTopPDefaultOne = 1;export const createResponseResponseTopPMinOne = 0;
export const createResponseResponseTopPMaxOne = 1;
export const createResponseResponseServiceTierDefaultOne = "auto";export const createResponseResponseReasoningEffortDefaultOne = "medium";export const createResponseResponseBackgroundDefaultOne = false;export const createResponseResponseTextFormatStrictDefaultOne = false;export const createResponseResponseTextVerbosityDefaultOne = "medium";export const createResponseResponseToolsItemTypeDefault = "function";export const createResponseResponseToolsItemTypeDefaultOne = "file_search";export const createResponseResponseToolsItemFiltersTypeDefault = "eq";export const createResponseResponseToolsItemFiltersFiltersItemTypeDefault = "eq";export const createResponseResponseToolsItemTypeDefaultTwo = "computer_use_preview";export const createResponseResponseToolsItemTypeDefaultThree = "web_search";export const createResponseResponseToolsItemFiltersAllowedDomainsDefaultOne = [];export const createResponseResponseToolsItemUserLocationTypeDefault = "approximate";export const createResponseResponseToolsItemSearchContextSizeDefault = "medium";export const createResponseResponseToolsItemRequireApprovalDefaultOne = "always";export const createResponseResponseToolsItemContainerTypeDefault = "auto";export const createResponseResponseToolsItemContainerFileIdsMax = 50;
export const createResponseResponseToolsItemModelDefault = "gpt-image-1";export const createResponseResponseToolsItemQualityDefault = "auto";export const createResponseResponseToolsItemSizeDefault = "auto";export const createResponseResponseToolsItemOutputFormatDefault = "png";export const createResponseResponseToolsItemOutputCompressionDefault = 100;
export const createResponseResponseToolsItemOutputCompressionMin = 0;

export const createResponseResponseToolsItemOutputCompressionMax = 100;
export const createResponseResponseToolsItemModerationDefault = "auto";export const createResponseResponseToolsItemBackgroundDefault = "auto";export const createResponseResponseToolsItemPartialImagesDefault = 0;
export const createResponseResponseToolsItemPartialImagesMin = 0;

export const createResponseResponseToolsItemPartialImagesMax = 3;
export const createResponseResponseToolsItemTypeDefaultSeven = "local_shell";export const createResponseResponseToolsItemTypeDefaultEight = "custom";export const createResponseResponseToolsItemFormatTypeDefault = "text";export const createResponseResponseToolsItemFormatTypeDefaultOne = "grammar";export const createResponseResponseToolsItemTypeDefaultNine = "web_search_preview";export const createResponseResponseToolsItemUserLocationTypeDefaultOne = "approximate";export const createResponseResponsePromptVariablesTypeDefault = "input_text";export const createResponseResponsePromptVariablesTypeDefaultOne = "input_image";export const createResponseResponsePromptVariablesTypeDefaultTwo = "input_file";export const createResponseResponseTruncationDefaultOne = "disabled";export const createResponseResponseOutputItemContentItemTypeDefault = "output_text";export const createResponseResponseOutputItemContentItemAnnotationsItemTypeDefault = "file_citation";export const createResponseResponseOutputItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const createResponseResponseOutputItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const createResponseResponseOutputItemContentItemTypeDefaultOne = "refusal";export const createResponseResponseOutputItemResultsItemAttributesMaxThree = 512;
export const createResponseResponseOutputItemTypeDefaultFour = "computer_call";export const createResponseResponseOutputItemActionTypeDefaultThree = "click";export const createResponseResponseOutputItemActionTypeDefaultFour = "double_click";export const createResponseResponseOutputItemActionTypeDefaultFive = "drag";export const createResponseResponseOutputItemActionTypeDefaultSix = "keypress";export const createResponseResponseOutputItemActionTypeDefaultSeven = "move";export const createResponseResponseOutputItemActionTypeDefaultEight = "screenshot";export const createResponseResponseOutputItemActionTypeDefaultNine = "scroll";export const createResponseResponseOutputItemActionTypeDefaultOnezero = "type";export const createResponseResponseOutputItemActionTypeDefaultOneone = "wait";export const createResponseResponseOutputItemSummaryItemTypeDefault = "summary_text";export const createResponseResponseOutputItemContentItemTypeDefaultTwo = "reasoning_text";export const createResponseResponseOutputItemTypeDefaultSeven = "code_interpreter_call";export const createResponseResponseOutputItemOutputsItemTypeDefault = "logs";export const createResponseResponseOutputItemOutputsItemTypeDefaultOne = "image";export const createResponseResponseOutputItemActionTypeDefaultOnetwo = "exec";export const createResponseResponseInstructionsItemContentItemTypeDefault = "input_text";export const createResponseResponseInstructionsItemContentItemTypeDefaultOne = "input_image";export const createResponseResponseInstructionsItemContentItemTypeDefaultTwo = "input_file";export const createResponseResponseInstructionsItemContentItemTypeDefaultFour = "input_text";export const createResponseResponseInstructionsItemContentItemTypeDefaultFive = "input_image";export const createResponseResponseInstructionsItemContentItemTypeDefaultSix = "input_file";export const createResponseResponseInstructionsItemContentItemTypeDefaultEight = "output_text";export const createResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefault = "file_citation";export const createResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const createResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const createResponseResponseInstructionsItemContentItemTypeDefaultNine = "refusal";export const createResponseResponseInstructionsItemResultsItemAttributesMaxThree = 512;
export const createResponseResponseInstructionsItemTypeDefaultFour = "computer_call";export const createResponseResponseInstructionsItemActionTypeDefault = "click";export const createResponseResponseInstructionsItemActionTypeDefaultOne = "double_click";export const createResponseResponseInstructionsItemActionTypeDefaultTwo = "drag";export const createResponseResponseInstructionsItemActionTypeDefaultThree = "keypress";export const createResponseResponseInstructionsItemActionTypeDefaultFour = "move";export const createResponseResponseInstructionsItemActionTypeDefaultFive = "screenshot";export const createResponseResponseInstructionsItemActionTypeDefaultSix = "scroll";export const createResponseResponseInstructionsItemActionTypeDefaultSeven = "type";export const createResponseResponseInstructionsItemActionTypeDefaultEight = "wait";export const createResponseResponseInstructionsItemCallIdMaxOne = 64;
export const createResponseResponseInstructionsItemTypeDefaultFive = "computer_call_output";export const createResponseResponseInstructionsItemOutputTypeDefault = "computer_screenshot";export const createResponseResponseInstructionsItemCallIdMaxThree = 64;
export const createResponseResponseInstructionsItemTypeDefaultEight = "function_call_output";export const createResponseResponseInstructionsItemOutputMaxTwo = 10485760;
export const createResponseResponseInstructionsItemOutputItemTypeDefault = "input_text";export const createResponseResponseInstructionsItemOutputItemTextMax = 10485760;
export const createResponseResponseInstructionsItemOutputItemTypeDefaultOne = "input_image";export const createResponseResponseInstructionsItemOutputItemImageUrlMaxOne = 20971520;
export const createResponseResponseInstructionsItemOutputItemTypeDefaultTwo = "input_file";export const createResponseResponseInstructionsItemOutputItemFileDataMaxOne = 33554432;
export const createResponseResponseInstructionsItemSummaryItemTypeDefault = "summary_text";export const createResponseResponseInstructionsItemContentItemTypeDefaultOnezero = "reasoning_text";export const createResponseResponseInstructionsItemTypeDefaultOneone = "code_interpreter_call";export const createResponseResponseInstructionsItemOutputsItemTypeDefault = "logs";export const createResponseResponseInstructionsItemOutputsItemTypeDefaultOne = "image";export const createResponseResponseInstructionsItemActionTypeDefaultOnetwo = "exec";export const createResponseResponseInstructionsItemOutputItemTypeDefaultThree = "input_text";export const createResponseResponseInstructionsItemOutputItemTypeDefaultFour = "input_image";export const createResponseResponseInstructionsItemOutputItemTypeDefaultFive = "input_file";export const createResponseResponseInstructionsItemTypeDefaultTwoone = "item_reference";export const createResponseResponseParallelToolCallsDefault = true;

export const createResponseResponse = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "top_logprobs": zod.number().min(createResponseResponseTopLogprobsMinOne).max(createResponseResponseTopLogprobsMaxOne).describe('An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(createResponseResponseTemperatureMinOne).max(createResponseResponseTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(createResponseResponseTopPMinOne).max(createResponseResponseTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.\n').or(zod.null()).optional(),
  "user": zod.string().optional().describe('This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations.\nA stable identifier for your end-users.\nUsed to boost cache hit rates by better bucketing similar requests and  to help OpenAI detect and prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "safety_identifier": zod.string().optional().describe('A stable identifier used to help detect users of your application that may be violating OpenAI\'s usage policies.\nThe IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "prompt_cache_key": zod.string().optional().describe('Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n'),
  "service_tier": zod.enum(['auto', 'default', 'flex', 'scale', 'priority']).optional().describe('Specifies the processing type used for serving the request.\n  - If set to \'auto\', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use \'default\'.\n  - If set to \'default\', then the request will be processed with the standard pricing and performance for the selected model.\n  - If set to \'[flex](https://platform.openai.com/docs/guides/flex-processing)\' or \'[priority](https://openai.com/api-priority-processing/)\', then the request will be processed with the corresponding service tier.\n  - When not set, the default behavior is \'auto\'.\n\n  When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.\n').or(zod.null()).optional()
}).and(zod.object({
  "previous_response_id": zod.string().describe('The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](https://platform.openai.com/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.\n').or(zod.null()).optional(),
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-5-chat-latest', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'o4-mini', 'o4-mini-2025-04-16', 'o3', 'o3-2025-04-16', 'o3-mini', 'o3-mini-2025-01-31', 'o1', 'o1-2024-12-17', 'o1-preview', 'o1-preview-2024-09-12', 'o1-mini', 'o1-mini-2024-09-12', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-audio-preview', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-audio-preview-2025-06-03', 'gpt-4o-mini-audio-preview', 'gpt-4o-mini-audio-preview-2024-12-17', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-mini-search-preview-2025-03-11', 'chatgpt-4o-latest', 'codex-mini-latest', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).or(zod.enum(['o1-pro', 'o1-pro-2025-03-19', 'o3-pro', 'o3-pro-2025-06-10', 'o3-deep-research', 'o3-deep-research-2025-06-26', 'o4-mini-deep-research', 'o4-mini-deep-research-2025-06-26', 'computer-use-preview', 'computer-use-preview-2025-03-11', 'gpt-5-codex', 'gpt-5-pro', 'gpt-5-pro-2025-10-06'])).optional(),
  "reasoning": zod.object({
  "effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "summary": zod.enum(['auto', 'concise', 'detailed']).describe('A summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional(),
  "generate_summary": zod.enum(['auto', 'concise', 'detailed']).describe('**Deprecated:** use `summary` instead.\n\nA summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional()
}).describe('**gpt-5 and o-series models only**\n\nConfiguration options for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "background": zod.boolean().optional().describe('Whether to run the model response in the background.\n[Learn more](https://platform.openai.com/docs/guides/background).\n').or(zod.null()).optional(),
  "max_output_tokens": zod.number().describe('An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "max_tool_calls": zod.number().describe('The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.\n').or(zod.null()).optional(),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "verbosity": zod.enum(['low', 'medium', 'high']).optional().describe('Constrains the verbosity of the model\'s response. Lower values will result in\nmore concise responses, while higher values will result in more verbose responses.\nCurrently supported values are `low`, `medium`, and `high`.\n').or(zod.null()).optional()
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(createResponseResponseToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(createResponseResponseToolsItemOutputCompressionMin).max(createResponseResponseToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(createResponseResponseToolsItemPartialImagesMin).max(createResponseResponseToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nWe support the following categories of tools:\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **MCP Tools**: Integrations with third-party systems via custom MCP servers\n  or predefined connectors such as Google Drive and SharePoint. Learn more about\n  [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code with strongly typed arguments\n  and outputs. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling). You can also use\n  custom tools to call your own code.\n'),
  "tool_choice": zod.discriminatedUnion('type', [.enum(['none', 'auto', 'required']).describe('Controls which (if any) tool is called by the model.\n\n`none` means the model will not call any tool and instead generates a message.\n\n`auto` means the model can pick between generating a message or calling one or\nmore tools.\n\n`required` means the model must call one or more tools.\n'),zod.object({
  "type": zod.enum(['allowed_tools']).describe('Allowed tool configuration type. Always `allowed_tools`.'),
  "mode": zod.enum(['auto', 'required']).describe('Constrains the tools available to the model to a pre-defined set.\n\n`auto` allows the model to pick from among the allowed tools and generate a\nmessage.\n\n`required` requires the model to call one or more of the allowed tools.\n'),
  "tools": zod.array(zod.record(zod.string(), zod.any()).describe('A tool definition that the model should be allowed to call.\n')).describe('A list of tool definitions that the model should be allowed to call.\n\nFor the Responses API, the list of tool definitions might look like:\n```json\n[\n  { \"type\": \"function\", \"name\": \"get_weather\" },\n  { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n  { \"type\": \"image_generation\" }\n]\n```\n')
}).describe('Constrains the tools available to the model to a pre-defined set.\n'),zod.object({
  "type": zod.enum(['file_search', 'web_search_preview', 'computer_use_preview', 'web_search_preview_2025_03_11', 'image_generation', 'code_interpreter']).describe('The type of hosted tool the model should to use. Learn more about\n[built-in tools](https://platform.openai.com/docs/guides/tools).\n\nAllowed values are:\n- `file_search`\n- `web_search_preview`\n- `computer_use_preview`\n- `code_interpreter`\n- `image_generation`\n')
}).describe('Indicates that the model should use a built-in tool to generate a response.\n[Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n'),zod.object({
  "type": zod.enum(['function']).describe('For function calling, the type is always `function`.'),
  "name": zod.string().describe('The name of the function to call.')
}).describe('Use this option to force the model to call a specific function.\n'),zod.object({
  "type": zod.enum(['mcp']).describe('For MCP tools, the type is always `mcp`.'),
  "server_label": zod.string().describe('The label of the MCP server to use.\n'),
  "name": zod.string().describe('The name of the tool to call on the server.\n').or(zod.null()).optional()
}).describe('Use this option to force the model to call a specific tool on a remote MCP server.\n'),zod.object({
  "type": zod.enum(['custom']).describe('For custom tool calling, the type is always `custom`.'),
  "name": zod.string().describe('The name of the custom tool to call.')
}).describe('Use this option to force the model to call a specific custom tool.\n')]).optional().describe('How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call.\n'),
  "prompt": zod.object({
  "id": zod.string().describe('The unique identifier of the prompt template to use.'),
  "version": zod.string().describe('Optional version of the prompt template.').or(zod.null()).optional(),
  "variables": zod.record(zod.string(), zod.string().or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).')).or(zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'))).describe('Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.\n').or(zod.null()).optional()
}).describe('Reference to a prompt template and its variables.\n[Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n').or(zod.null()).optional(),
  "truncation": zod.enum(['auto', 'disabled']).optional().describe('The truncation strategy to use for the model response.\n- `auto`: If the input to this Response exceeds\n  the model\'s context window size, the model will truncate the\n  response to fit the context window by dropping items from the beginning of the conversation.\n- `disabled` (default): If the input size will exceed the context window\n  size for a model, the request will fail with a 400 error.\n').or(zod.null()).optional()
})).and(zod.object({
  "id": zod.string().describe('Unique identifier for this Response.\n'),
  "object": zod.enum(['response']).describe('The object type of this resource - always set to `response`.\n'),
  "status": zod.enum(['completed', 'failed', 'in_progress', 'cancelled', 'queued', 'incomplete']).optional().describe('The status of the response generation. One of `completed`, `failed`,\n`in_progress`, `cancelled`, `queued`, or `incomplete`.\n'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) of when this Response was created.\n'),
  "error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt', 'vector_store_timeout', 'invalid_image', 'invalid_image_format', 'invalid_base64_image', 'invalid_image_url', 'image_too_large', 'image_too_small', 'image_parse_error', 'image_content_policy_violation', 'invalid_image_mode', 'image_file_too_large', 'unsupported_image_media_type', 'empty_image_file', 'failed_to_download_image', 'image_file_not_found']).describe('The error code for the response.\n'),
  "message": zod.string().describe('A human-readable description of the error.\n')
}).describe('An error object returned when the model fails to generate a Response.\n').or(zod.null()),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_output_tokens', 'content_filter']).optional().describe('The reason why the response is incomplete.')
}).describe('Details about why the response is incomplete.\n').or(zod.null()),
  "output": zod.array(zod.discriminatedUnion('type', [zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(createResponseResponseOutputItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')])).describe('An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model\'s response.\n- Rather than accessing the first item in the `output` array and\n  assuming it\'s an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs.\n'),
  "instructions": zod.string().describe('A text input to the model, equivalent to a text input with the\n`developer` role.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'),zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always set to `message`.\n'),
  "role": zod.enum(['user', 'system', 'developer']).describe('The role of the message input. One of `user`, `system`, or `developer`.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(createResponseResponseInstructionsItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "id": zod.string().describe('The ID of the computer tool call output.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createResponseResponseInstructionsItemCallIdMaxOne).describe('The ID of the computer tool call that produced the output.'),
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The safety checks reported by the API that have been acknowledged by the developer.').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a computer tool call.'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the function tool call output. Populated when this item is returned via API.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(createResponseResponseInstructionsItemCallIdMaxThree).describe('The unique ID of the function tool call generated by the model.'),
  "type": zod.enum(['function_call_output']).optional().describe('The type of the function tool call output. Always `function_call_output`.'),
  "output": zod.string().max(createResponseResponseInstructionsItemOutputMaxTwo).describe('A JSON string of the output of the function tool call.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().max(createResponseResponseInstructionsItemOutputItemTextMax).describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().max(createResponseResponseInstructionsItemOutputItemImageUrlMaxOne).describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto']).or(zod.null()).optional()
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision)'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().describe('The name of the file to be sent to the model.').or(zod.null()).optional(),
  "file_data": zod.string().max(createResponseResponseInstructionsItemOutputItemFileDataMaxOne).describe('The base64-encoded data of the file to be sent to the model.').or(zod.null()).optional(),
  "file_url": zod.string().describe('The URL of the file to be sent to the model.').or(zod.null()).optional()
}).describe('A file input to the model.')]))).describe('Text, image, or file output of the function tool call.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a function tool call.'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n').or(zod.null()).optional(),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')]).describe('Content item used to generate a response.\n'),zod.object({
  "type": zod.enum(['item_reference']).optional().describe('The type of item to reference. Always `item_reference`.').or(zod.null()).optional(),
  "id": zod.string().describe('The ID of the item to reference.')
}).describe('An internal identifier for an item to reference.')])).describe('A list of one or many input items to the model, containing\ndifferent content types.\n')).describe('A system (or developer) message inserted into the model\'s context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.\n').or(zod.null()),
  "output_text": zod.string().describe('SDK-only convenience property that contains the aggregated text output\nfrom all `output_text` items in the `output` array, if any are present.\nSupported in the Python and JavaScript SDKs.\n').or(zod.null()).optional(),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of input tokens.'),
  "input_tokens_details": zod.object({
  "cached_tokens": zod.number().describe('The number of tokens that were retrieved from the cache.\n[More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n')
}).describe('A detailed breakdown of the input tokens.'),
  "output_tokens": zod.number().describe('The number of output tokens.'),
  "output_tokens_details": zod.object({
  "reasoning_tokens": zod.number().describe('The number of reasoning tokens.')
}).describe('A detailed breakdown of the output tokens.'),
  "total_tokens": zod.number().describe('The total number of tokens used.')
}).optional().describe('Represents token usage details including input tokens, output tokens,\na breakdown of output tokens, and the total tokens used.\n'),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to allow the model to run tool calls in parallel.\n'),
  "conversation": zod.object({
  "id": zod.string().describe('The unique ID of the conversation.')
}).describe('The conversation that this response belongs to. Input items and output items from this response are automatically added to this conversation.').or(zod.null()).optional()
}))

/**
 * Retrieves a model response with the given ID.

 * @summary Get a model response
 */
export const getResponseParams = zod.object({
  "response_id": zod.string().describe('The ID of the response to retrieve.')
})

export const getResponseQueryParams = zod.object({
  "include": zod.array(zod.enum(['file_search_call.results', 'web_search_call.results', 'web_search_call.action.sources', 'message.input_image.image_url', 'computer_call_output.output.image_url', 'code_interpreter_call.outputs', 'reasoning.encrypted_content', 'message.output_text.logprobs']).describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).')).optional().describe('Additional fields to include in the response. See the `include`\nparameter for Response creation above for more information.\n'),
  "stream": zod.boolean().optional().describe('If set to true, the model response data will be streamed to the client\nas it is generated using [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format).\nSee the [Streaming section below](https://platform.openai.com/docs/api-reference/responses-streaming)\nfor more information.\n'),
  "starting_after": zod.number().optional().describe('The sequence number of the event after which to start streaming.\n'),
  "include_obfuscation": zod.boolean().optional().describe('When true, stream obfuscation will be enabled. Stream obfuscation adds\nrandom characters to an `obfuscation` field on streaming delta events\nto normalize payload sizes as a mitigation to certain side-channel\nattacks. These obfuscation fields are included by default, but add a\nsmall amount of overhead to the data stream. You can set\n`include_obfuscation` to false to optimize for bandwidth if you trust\nthe network links between your application and the OpenAI API.\n')
})

export const getResponseResponseTopLogprobsMinOne = 0;
export const getResponseResponseTopLogprobsMaxOne = 20;
export const getResponseResponseTemperatureDefaultOne = 1;export const getResponseResponseTemperatureMinOne = 0;
export const getResponseResponseTemperatureMaxOne = 2;
export const getResponseResponseTopPDefaultOne = 1;export const getResponseResponseTopPMinOne = 0;
export const getResponseResponseTopPMaxOne = 1;
export const getResponseResponseServiceTierDefaultOne = "auto";export const getResponseResponseReasoningEffortDefaultOne = "medium";export const getResponseResponseBackgroundDefaultOne = false;export const getResponseResponseTextFormatStrictDefaultOne = false;export const getResponseResponseTextVerbosityDefaultOne = "medium";export const getResponseResponseToolsItemTypeDefault = "function";export const getResponseResponseToolsItemTypeDefaultOne = "file_search";export const getResponseResponseToolsItemFiltersTypeDefault = "eq";export const getResponseResponseToolsItemFiltersFiltersItemTypeDefault = "eq";export const getResponseResponseToolsItemTypeDefaultTwo = "computer_use_preview";export const getResponseResponseToolsItemTypeDefaultThree = "web_search";export const getResponseResponseToolsItemFiltersAllowedDomainsDefaultOne = [];export const getResponseResponseToolsItemUserLocationTypeDefault = "approximate";export const getResponseResponseToolsItemSearchContextSizeDefault = "medium";export const getResponseResponseToolsItemRequireApprovalDefaultOne = "always";export const getResponseResponseToolsItemContainerTypeDefault = "auto";export const getResponseResponseToolsItemContainerFileIdsMax = 50;
export const getResponseResponseToolsItemModelDefault = "gpt-image-1";export const getResponseResponseToolsItemQualityDefault = "auto";export const getResponseResponseToolsItemSizeDefault = "auto";export const getResponseResponseToolsItemOutputFormatDefault = "png";export const getResponseResponseToolsItemOutputCompressionDefault = 100;
export const getResponseResponseToolsItemOutputCompressionMin = 0;

export const getResponseResponseToolsItemOutputCompressionMax = 100;
export const getResponseResponseToolsItemModerationDefault = "auto";export const getResponseResponseToolsItemBackgroundDefault = "auto";export const getResponseResponseToolsItemPartialImagesDefault = 0;
export const getResponseResponseToolsItemPartialImagesMin = 0;

export const getResponseResponseToolsItemPartialImagesMax = 3;
export const getResponseResponseToolsItemTypeDefaultSeven = "local_shell";export const getResponseResponseToolsItemTypeDefaultEight = "custom";export const getResponseResponseToolsItemFormatTypeDefault = "text";export const getResponseResponseToolsItemFormatTypeDefaultOne = "grammar";export const getResponseResponseToolsItemTypeDefaultNine = "web_search_preview";export const getResponseResponseToolsItemUserLocationTypeDefaultOne = "approximate";export const getResponseResponsePromptVariablesTypeDefault = "input_text";export const getResponseResponsePromptVariablesTypeDefaultOne = "input_image";export const getResponseResponsePromptVariablesTypeDefaultTwo = "input_file";export const getResponseResponseTruncationDefaultOne = "disabled";export const getResponseResponseOutputItemContentItemTypeDefault = "output_text";export const getResponseResponseOutputItemContentItemAnnotationsItemTypeDefault = "file_citation";export const getResponseResponseOutputItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const getResponseResponseOutputItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const getResponseResponseOutputItemContentItemTypeDefaultOne = "refusal";export const getResponseResponseOutputItemResultsItemAttributesMaxThree = 512;
export const getResponseResponseOutputItemTypeDefaultFour = "computer_call";export const getResponseResponseOutputItemActionTypeDefaultThree = "click";export const getResponseResponseOutputItemActionTypeDefaultFour = "double_click";export const getResponseResponseOutputItemActionTypeDefaultFive = "drag";export const getResponseResponseOutputItemActionTypeDefaultSix = "keypress";export const getResponseResponseOutputItemActionTypeDefaultSeven = "move";export const getResponseResponseOutputItemActionTypeDefaultEight = "screenshot";export const getResponseResponseOutputItemActionTypeDefaultNine = "scroll";export const getResponseResponseOutputItemActionTypeDefaultOnezero = "type";export const getResponseResponseOutputItemActionTypeDefaultOneone = "wait";export const getResponseResponseOutputItemSummaryItemTypeDefault = "summary_text";export const getResponseResponseOutputItemContentItemTypeDefaultTwo = "reasoning_text";export const getResponseResponseOutputItemTypeDefaultSeven = "code_interpreter_call";export const getResponseResponseOutputItemOutputsItemTypeDefault = "logs";export const getResponseResponseOutputItemOutputsItemTypeDefaultOne = "image";export const getResponseResponseOutputItemActionTypeDefaultOnetwo = "exec";export const getResponseResponseInstructionsItemContentItemTypeDefault = "input_text";export const getResponseResponseInstructionsItemContentItemTypeDefaultOne = "input_image";export const getResponseResponseInstructionsItemContentItemTypeDefaultTwo = "input_file";export const getResponseResponseInstructionsItemContentItemTypeDefaultFour = "input_text";export const getResponseResponseInstructionsItemContentItemTypeDefaultFive = "input_image";export const getResponseResponseInstructionsItemContentItemTypeDefaultSix = "input_file";export const getResponseResponseInstructionsItemContentItemTypeDefaultEight = "output_text";export const getResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefault = "file_citation";export const getResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const getResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const getResponseResponseInstructionsItemContentItemTypeDefaultNine = "refusal";export const getResponseResponseInstructionsItemResultsItemAttributesMaxThree = 512;
export const getResponseResponseInstructionsItemTypeDefaultFour = "computer_call";export const getResponseResponseInstructionsItemActionTypeDefault = "click";export const getResponseResponseInstructionsItemActionTypeDefaultOne = "double_click";export const getResponseResponseInstructionsItemActionTypeDefaultTwo = "drag";export const getResponseResponseInstructionsItemActionTypeDefaultThree = "keypress";export const getResponseResponseInstructionsItemActionTypeDefaultFour = "move";export const getResponseResponseInstructionsItemActionTypeDefaultFive = "screenshot";export const getResponseResponseInstructionsItemActionTypeDefaultSix = "scroll";export const getResponseResponseInstructionsItemActionTypeDefaultSeven = "type";export const getResponseResponseInstructionsItemActionTypeDefaultEight = "wait";export const getResponseResponseInstructionsItemCallIdMaxOne = 64;
export const getResponseResponseInstructionsItemTypeDefaultFive = "computer_call_output";export const getResponseResponseInstructionsItemOutputTypeDefault = "computer_screenshot";export const getResponseResponseInstructionsItemCallIdMaxThree = 64;
export const getResponseResponseInstructionsItemTypeDefaultEight = "function_call_output";export const getResponseResponseInstructionsItemOutputMaxTwo = 10485760;
export const getResponseResponseInstructionsItemOutputItemTypeDefault = "input_text";export const getResponseResponseInstructionsItemOutputItemTextMax = 10485760;
export const getResponseResponseInstructionsItemOutputItemTypeDefaultOne = "input_image";export const getResponseResponseInstructionsItemOutputItemImageUrlMaxOne = 20971520;
export const getResponseResponseInstructionsItemOutputItemTypeDefaultTwo = "input_file";export const getResponseResponseInstructionsItemOutputItemFileDataMaxOne = 33554432;
export const getResponseResponseInstructionsItemSummaryItemTypeDefault = "summary_text";export const getResponseResponseInstructionsItemContentItemTypeDefaultOnezero = "reasoning_text";export const getResponseResponseInstructionsItemTypeDefaultOneone = "code_interpreter_call";export const getResponseResponseInstructionsItemOutputsItemTypeDefault = "logs";export const getResponseResponseInstructionsItemOutputsItemTypeDefaultOne = "image";export const getResponseResponseInstructionsItemActionTypeDefaultOnetwo = "exec";export const getResponseResponseInstructionsItemOutputItemTypeDefaultThree = "input_text";export const getResponseResponseInstructionsItemOutputItemTypeDefaultFour = "input_image";export const getResponseResponseInstructionsItemOutputItemTypeDefaultFive = "input_file";export const getResponseResponseInstructionsItemTypeDefaultTwoone = "item_reference";export const getResponseResponseParallelToolCallsDefault = true;

export const getResponseResponse = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "top_logprobs": zod.number().min(getResponseResponseTopLogprobsMinOne).max(getResponseResponseTopLogprobsMaxOne).describe('An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(getResponseResponseTemperatureMinOne).max(getResponseResponseTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(getResponseResponseTopPMinOne).max(getResponseResponseTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.\n').or(zod.null()).optional(),
  "user": zod.string().optional().describe('This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations.\nA stable identifier for your end-users.\nUsed to boost cache hit rates by better bucketing similar requests and  to help OpenAI detect and prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "safety_identifier": zod.string().optional().describe('A stable identifier used to help detect users of your application that may be violating OpenAI\'s usage policies.\nThe IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "prompt_cache_key": zod.string().optional().describe('Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n'),
  "service_tier": zod.enum(['auto', 'default', 'flex', 'scale', 'priority']).optional().describe('Specifies the processing type used for serving the request.\n  - If set to \'auto\', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use \'default\'.\n  - If set to \'default\', then the request will be processed with the standard pricing and performance for the selected model.\n  - If set to \'[flex](https://platform.openai.com/docs/guides/flex-processing)\' or \'[priority](https://openai.com/api-priority-processing/)\', then the request will be processed with the corresponding service tier.\n  - When not set, the default behavior is \'auto\'.\n\n  When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.\n').or(zod.null()).optional()
}).and(zod.object({
  "previous_response_id": zod.string().describe('The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](https://platform.openai.com/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.\n').or(zod.null()).optional(),
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-5-chat-latest', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'o4-mini', 'o4-mini-2025-04-16', 'o3', 'o3-2025-04-16', 'o3-mini', 'o3-mini-2025-01-31', 'o1', 'o1-2024-12-17', 'o1-preview', 'o1-preview-2024-09-12', 'o1-mini', 'o1-mini-2024-09-12', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-audio-preview', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-audio-preview-2025-06-03', 'gpt-4o-mini-audio-preview', 'gpt-4o-mini-audio-preview-2024-12-17', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-mini-search-preview-2025-03-11', 'chatgpt-4o-latest', 'codex-mini-latest', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).or(zod.enum(['o1-pro', 'o1-pro-2025-03-19', 'o3-pro', 'o3-pro-2025-06-10', 'o3-deep-research', 'o3-deep-research-2025-06-26', 'o4-mini-deep-research', 'o4-mini-deep-research-2025-06-26', 'computer-use-preview', 'computer-use-preview-2025-03-11', 'gpt-5-codex', 'gpt-5-pro', 'gpt-5-pro-2025-10-06'])).optional(),
  "reasoning": zod.object({
  "effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "summary": zod.enum(['auto', 'concise', 'detailed']).describe('A summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional(),
  "generate_summary": zod.enum(['auto', 'concise', 'detailed']).describe('**Deprecated:** use `summary` instead.\n\nA summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional()
}).describe('**gpt-5 and o-series models only**\n\nConfiguration options for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "background": zod.boolean().optional().describe('Whether to run the model response in the background.\n[Learn more](https://platform.openai.com/docs/guides/background).\n').or(zod.null()).optional(),
  "max_output_tokens": zod.number().describe('An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "max_tool_calls": zod.number().describe('The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.\n').or(zod.null()).optional(),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "verbosity": zod.enum(['low', 'medium', 'high']).optional().describe('Constrains the verbosity of the model\'s response. Lower values will result in\nmore concise responses, while higher values will result in more verbose responses.\nCurrently supported values are `low`, `medium`, and `high`.\n').or(zod.null()).optional()
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(getResponseResponseToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(getResponseResponseToolsItemOutputCompressionMin).max(getResponseResponseToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(getResponseResponseToolsItemPartialImagesMin).max(getResponseResponseToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nWe support the following categories of tools:\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **MCP Tools**: Integrations with third-party systems via custom MCP servers\n  or predefined connectors such as Google Drive and SharePoint. Learn more about\n  [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code with strongly typed arguments\n  and outputs. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling). You can also use\n  custom tools to call your own code.\n'),
  "tool_choice": zod.discriminatedUnion('type', [.enum(['none', 'auto', 'required']).describe('Controls which (if any) tool is called by the model.\n\n`none` means the model will not call any tool and instead generates a message.\n\n`auto` means the model can pick between generating a message or calling one or\nmore tools.\n\n`required` means the model must call one or more tools.\n'),zod.object({
  "type": zod.enum(['allowed_tools']).describe('Allowed tool configuration type. Always `allowed_tools`.'),
  "mode": zod.enum(['auto', 'required']).describe('Constrains the tools available to the model to a pre-defined set.\n\n`auto` allows the model to pick from among the allowed tools and generate a\nmessage.\n\n`required` requires the model to call one or more of the allowed tools.\n'),
  "tools": zod.array(zod.record(zod.string(), zod.any()).describe('A tool definition that the model should be allowed to call.\n')).describe('A list of tool definitions that the model should be allowed to call.\n\nFor the Responses API, the list of tool definitions might look like:\n```json\n[\n  { \"type\": \"function\", \"name\": \"get_weather\" },\n  { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n  { \"type\": \"image_generation\" }\n]\n```\n')
}).describe('Constrains the tools available to the model to a pre-defined set.\n'),zod.object({
  "type": zod.enum(['file_search', 'web_search_preview', 'computer_use_preview', 'web_search_preview_2025_03_11', 'image_generation', 'code_interpreter']).describe('The type of hosted tool the model should to use. Learn more about\n[built-in tools](https://platform.openai.com/docs/guides/tools).\n\nAllowed values are:\n- `file_search`\n- `web_search_preview`\n- `computer_use_preview`\n- `code_interpreter`\n- `image_generation`\n')
}).describe('Indicates that the model should use a built-in tool to generate a response.\n[Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n'),zod.object({
  "type": zod.enum(['function']).describe('For function calling, the type is always `function`.'),
  "name": zod.string().describe('The name of the function to call.')
}).describe('Use this option to force the model to call a specific function.\n'),zod.object({
  "type": zod.enum(['mcp']).describe('For MCP tools, the type is always `mcp`.'),
  "server_label": zod.string().describe('The label of the MCP server to use.\n'),
  "name": zod.string().describe('The name of the tool to call on the server.\n').or(zod.null()).optional()
}).describe('Use this option to force the model to call a specific tool on a remote MCP server.\n'),zod.object({
  "type": zod.enum(['custom']).describe('For custom tool calling, the type is always `custom`.'),
  "name": zod.string().describe('The name of the custom tool to call.')
}).describe('Use this option to force the model to call a specific custom tool.\n')]).optional().describe('How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call.\n'),
  "prompt": zod.object({
  "id": zod.string().describe('The unique identifier of the prompt template to use.'),
  "version": zod.string().describe('Optional version of the prompt template.').or(zod.null()).optional(),
  "variables": zod.record(zod.string(), zod.string().or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).')).or(zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'))).describe('Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.\n').or(zod.null()).optional()
}).describe('Reference to a prompt template and its variables.\n[Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n').or(zod.null()).optional(),
  "truncation": zod.enum(['auto', 'disabled']).optional().describe('The truncation strategy to use for the model response.\n- `auto`: If the input to this Response exceeds\n  the model\'s context window size, the model will truncate the\n  response to fit the context window by dropping items from the beginning of the conversation.\n- `disabled` (default): If the input size will exceed the context window\n  size for a model, the request will fail with a 400 error.\n').or(zod.null()).optional()
})).and(zod.object({
  "id": zod.string().describe('Unique identifier for this Response.\n'),
  "object": zod.enum(['response']).describe('The object type of this resource - always set to `response`.\n'),
  "status": zod.enum(['completed', 'failed', 'in_progress', 'cancelled', 'queued', 'incomplete']).optional().describe('The status of the response generation. One of `completed`, `failed`,\n`in_progress`, `cancelled`, `queued`, or `incomplete`.\n'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) of when this Response was created.\n'),
  "error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt', 'vector_store_timeout', 'invalid_image', 'invalid_image_format', 'invalid_base64_image', 'invalid_image_url', 'image_too_large', 'image_too_small', 'image_parse_error', 'image_content_policy_violation', 'invalid_image_mode', 'image_file_too_large', 'unsupported_image_media_type', 'empty_image_file', 'failed_to_download_image', 'image_file_not_found']).describe('The error code for the response.\n'),
  "message": zod.string().describe('A human-readable description of the error.\n')
}).describe('An error object returned when the model fails to generate a Response.\n').or(zod.null()),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_output_tokens', 'content_filter']).optional().describe('The reason why the response is incomplete.')
}).describe('Details about why the response is incomplete.\n').or(zod.null()),
  "output": zod.array(zod.discriminatedUnion('type', [zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(getResponseResponseOutputItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')])).describe('An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model\'s response.\n- Rather than accessing the first item in the `output` array and\n  assuming it\'s an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs.\n'),
  "instructions": zod.string().describe('A text input to the model, equivalent to a text input with the\n`developer` role.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'),zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always set to `message`.\n'),
  "role": zod.enum(['user', 'system', 'developer']).describe('The role of the message input. One of `user`, `system`, or `developer`.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(getResponseResponseInstructionsItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "id": zod.string().describe('The ID of the computer tool call output.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(getResponseResponseInstructionsItemCallIdMaxOne).describe('The ID of the computer tool call that produced the output.'),
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The safety checks reported by the API that have been acknowledged by the developer.').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a computer tool call.'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the function tool call output. Populated when this item is returned via API.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(getResponseResponseInstructionsItemCallIdMaxThree).describe('The unique ID of the function tool call generated by the model.'),
  "type": zod.enum(['function_call_output']).optional().describe('The type of the function tool call output. Always `function_call_output`.'),
  "output": zod.string().max(getResponseResponseInstructionsItemOutputMaxTwo).describe('A JSON string of the output of the function tool call.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().max(getResponseResponseInstructionsItemOutputItemTextMax).describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().max(getResponseResponseInstructionsItemOutputItemImageUrlMaxOne).describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto']).or(zod.null()).optional()
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision)'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().describe('The name of the file to be sent to the model.').or(zod.null()).optional(),
  "file_data": zod.string().max(getResponseResponseInstructionsItemOutputItemFileDataMaxOne).describe('The base64-encoded data of the file to be sent to the model.').or(zod.null()).optional(),
  "file_url": zod.string().describe('The URL of the file to be sent to the model.').or(zod.null()).optional()
}).describe('A file input to the model.')]))).describe('Text, image, or file output of the function tool call.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a function tool call.'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n').or(zod.null()).optional(),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')]).describe('Content item used to generate a response.\n'),zod.object({
  "type": zod.enum(['item_reference']).optional().describe('The type of item to reference. Always `item_reference`.').or(zod.null()).optional(),
  "id": zod.string().describe('The ID of the item to reference.')
}).describe('An internal identifier for an item to reference.')])).describe('A list of one or many input items to the model, containing\ndifferent content types.\n')).describe('A system (or developer) message inserted into the model\'s context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.\n').or(zod.null()),
  "output_text": zod.string().describe('SDK-only convenience property that contains the aggregated text output\nfrom all `output_text` items in the `output` array, if any are present.\nSupported in the Python and JavaScript SDKs.\n').or(zod.null()).optional(),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of input tokens.'),
  "input_tokens_details": zod.object({
  "cached_tokens": zod.number().describe('The number of tokens that were retrieved from the cache.\n[More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n')
}).describe('A detailed breakdown of the input tokens.'),
  "output_tokens": zod.number().describe('The number of output tokens.'),
  "output_tokens_details": zod.object({
  "reasoning_tokens": zod.number().describe('The number of reasoning tokens.')
}).describe('A detailed breakdown of the output tokens.'),
  "total_tokens": zod.number().describe('The total number of tokens used.')
}).optional().describe('Represents token usage details including input tokens, output tokens,\na breakdown of output tokens, and the total tokens used.\n'),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to allow the model to run tool calls in parallel.\n'),
  "conversation": zod.object({
  "id": zod.string().describe('The unique ID of the conversation.')
}).describe('The conversation that this response belongs to. Input items and output items from this response are automatically added to this conversation.').or(zod.null()).optional()
}))

/**
 * Deletes a model response with the given ID.

 * @summary Delete a model response
 */
export const deleteResponseParams = zod.object({
  "response_id": zod.string().describe('The ID of the response to delete.')
})

/**
 * Cancels a model response with the given ID. Only responses created with
the `background` parameter set to `true` can be cancelled.
[Learn more](https://platform.openai.com/docs/guides/background).

 * @summary Cancel a response
 */
export const cancelResponseParams = zod.object({
  "response_id": zod.string().describe('The ID of the response to cancel.')
})

export const cancelResponseResponseTopLogprobsMinOne = 0;
export const cancelResponseResponseTopLogprobsMaxOne = 20;
export const cancelResponseResponseTemperatureDefaultOne = 1;export const cancelResponseResponseTemperatureMinOne = 0;
export const cancelResponseResponseTemperatureMaxOne = 2;
export const cancelResponseResponseTopPDefaultOne = 1;export const cancelResponseResponseTopPMinOne = 0;
export const cancelResponseResponseTopPMaxOne = 1;
export const cancelResponseResponseServiceTierDefaultOne = "auto";export const cancelResponseResponseReasoningEffortDefaultOne = "medium";export const cancelResponseResponseBackgroundDefaultOne = false;export const cancelResponseResponseTextFormatStrictDefaultOne = false;export const cancelResponseResponseTextVerbosityDefaultOne = "medium";export const cancelResponseResponseToolsItemTypeDefault = "function";export const cancelResponseResponseToolsItemTypeDefaultOne = "file_search";export const cancelResponseResponseToolsItemFiltersTypeDefault = "eq";export const cancelResponseResponseToolsItemFiltersFiltersItemTypeDefault = "eq";export const cancelResponseResponseToolsItemTypeDefaultTwo = "computer_use_preview";export const cancelResponseResponseToolsItemTypeDefaultThree = "web_search";export const cancelResponseResponseToolsItemFiltersAllowedDomainsDefaultOne = [];export const cancelResponseResponseToolsItemUserLocationTypeDefault = "approximate";export const cancelResponseResponseToolsItemSearchContextSizeDefault = "medium";export const cancelResponseResponseToolsItemRequireApprovalDefaultOne = "always";export const cancelResponseResponseToolsItemContainerTypeDefault = "auto";export const cancelResponseResponseToolsItemContainerFileIdsMax = 50;
export const cancelResponseResponseToolsItemModelDefault = "gpt-image-1";export const cancelResponseResponseToolsItemQualityDefault = "auto";export const cancelResponseResponseToolsItemSizeDefault = "auto";export const cancelResponseResponseToolsItemOutputFormatDefault = "png";export const cancelResponseResponseToolsItemOutputCompressionDefault = 100;
export const cancelResponseResponseToolsItemOutputCompressionMin = 0;

export const cancelResponseResponseToolsItemOutputCompressionMax = 100;
export const cancelResponseResponseToolsItemModerationDefault = "auto";export const cancelResponseResponseToolsItemBackgroundDefault = "auto";export const cancelResponseResponseToolsItemPartialImagesDefault = 0;
export const cancelResponseResponseToolsItemPartialImagesMin = 0;

export const cancelResponseResponseToolsItemPartialImagesMax = 3;
export const cancelResponseResponseToolsItemTypeDefaultSeven = "local_shell";export const cancelResponseResponseToolsItemTypeDefaultEight = "custom";export const cancelResponseResponseToolsItemFormatTypeDefault = "text";export const cancelResponseResponseToolsItemFormatTypeDefaultOne = "grammar";export const cancelResponseResponseToolsItemTypeDefaultNine = "web_search_preview";export const cancelResponseResponseToolsItemUserLocationTypeDefaultOne = "approximate";export const cancelResponseResponsePromptVariablesTypeDefault = "input_text";export const cancelResponseResponsePromptVariablesTypeDefaultOne = "input_image";export const cancelResponseResponsePromptVariablesTypeDefaultTwo = "input_file";export const cancelResponseResponseTruncationDefaultOne = "disabled";export const cancelResponseResponseOutputItemContentItemTypeDefault = "output_text";export const cancelResponseResponseOutputItemContentItemAnnotationsItemTypeDefault = "file_citation";export const cancelResponseResponseOutputItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const cancelResponseResponseOutputItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const cancelResponseResponseOutputItemContentItemTypeDefaultOne = "refusal";export const cancelResponseResponseOutputItemResultsItemAttributesMaxThree = 512;
export const cancelResponseResponseOutputItemTypeDefaultFour = "computer_call";export const cancelResponseResponseOutputItemActionTypeDefaultThree = "click";export const cancelResponseResponseOutputItemActionTypeDefaultFour = "double_click";export const cancelResponseResponseOutputItemActionTypeDefaultFive = "drag";export const cancelResponseResponseOutputItemActionTypeDefaultSix = "keypress";export const cancelResponseResponseOutputItemActionTypeDefaultSeven = "move";export const cancelResponseResponseOutputItemActionTypeDefaultEight = "screenshot";export const cancelResponseResponseOutputItemActionTypeDefaultNine = "scroll";export const cancelResponseResponseOutputItemActionTypeDefaultOnezero = "type";export const cancelResponseResponseOutputItemActionTypeDefaultOneone = "wait";export const cancelResponseResponseOutputItemSummaryItemTypeDefault = "summary_text";export const cancelResponseResponseOutputItemContentItemTypeDefaultTwo = "reasoning_text";export const cancelResponseResponseOutputItemTypeDefaultSeven = "code_interpreter_call";export const cancelResponseResponseOutputItemOutputsItemTypeDefault = "logs";export const cancelResponseResponseOutputItemOutputsItemTypeDefaultOne = "image";export const cancelResponseResponseOutputItemActionTypeDefaultOnetwo = "exec";export const cancelResponseResponseInstructionsItemContentItemTypeDefault = "input_text";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultOne = "input_image";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultTwo = "input_file";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultFour = "input_text";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultFive = "input_image";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultSix = "input_file";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultEight = "output_text";export const cancelResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefault = "file_citation";export const cancelResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const cancelResponseResponseInstructionsItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultNine = "refusal";export const cancelResponseResponseInstructionsItemResultsItemAttributesMaxThree = 512;
export const cancelResponseResponseInstructionsItemTypeDefaultFour = "computer_call";export const cancelResponseResponseInstructionsItemActionTypeDefault = "click";export const cancelResponseResponseInstructionsItemActionTypeDefaultOne = "double_click";export const cancelResponseResponseInstructionsItemActionTypeDefaultTwo = "drag";export const cancelResponseResponseInstructionsItemActionTypeDefaultThree = "keypress";export const cancelResponseResponseInstructionsItemActionTypeDefaultFour = "move";export const cancelResponseResponseInstructionsItemActionTypeDefaultFive = "screenshot";export const cancelResponseResponseInstructionsItemActionTypeDefaultSix = "scroll";export const cancelResponseResponseInstructionsItemActionTypeDefaultSeven = "type";export const cancelResponseResponseInstructionsItemActionTypeDefaultEight = "wait";export const cancelResponseResponseInstructionsItemCallIdMaxOne = 64;
export const cancelResponseResponseInstructionsItemTypeDefaultFive = "computer_call_output";export const cancelResponseResponseInstructionsItemOutputTypeDefault = "computer_screenshot";export const cancelResponseResponseInstructionsItemCallIdMaxThree = 64;
export const cancelResponseResponseInstructionsItemTypeDefaultEight = "function_call_output";export const cancelResponseResponseInstructionsItemOutputMaxTwo = 10485760;
export const cancelResponseResponseInstructionsItemOutputItemTypeDefault = "input_text";export const cancelResponseResponseInstructionsItemOutputItemTextMax = 10485760;
export const cancelResponseResponseInstructionsItemOutputItemTypeDefaultOne = "input_image";export const cancelResponseResponseInstructionsItemOutputItemImageUrlMaxOne = 20971520;
export const cancelResponseResponseInstructionsItemOutputItemTypeDefaultTwo = "input_file";export const cancelResponseResponseInstructionsItemOutputItemFileDataMaxOne = 33554432;
export const cancelResponseResponseInstructionsItemSummaryItemTypeDefault = "summary_text";export const cancelResponseResponseInstructionsItemContentItemTypeDefaultOnezero = "reasoning_text";export const cancelResponseResponseInstructionsItemTypeDefaultOneone = "code_interpreter_call";export const cancelResponseResponseInstructionsItemOutputsItemTypeDefault = "logs";export const cancelResponseResponseInstructionsItemOutputsItemTypeDefaultOne = "image";export const cancelResponseResponseInstructionsItemActionTypeDefaultOnetwo = "exec";export const cancelResponseResponseInstructionsItemOutputItemTypeDefaultThree = "input_text";export const cancelResponseResponseInstructionsItemOutputItemTypeDefaultFour = "input_image";export const cancelResponseResponseInstructionsItemOutputItemTypeDefaultFive = "input_file";export const cancelResponseResponseInstructionsItemTypeDefaultTwoone = "item_reference";export const cancelResponseResponseParallelToolCallsDefault = true;

export const cancelResponseResponse = zod.object({
  "metadata": zod.record(zod.string(), zod.string()).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard.\n\nKeys are strings with a maximum length of 64 characters. Values are strings\nwith a maximum length of 512 characters.\n').or(zod.null()).optional(),
  "top_logprobs": zod.number().min(cancelResponseResponseTopLogprobsMinOne).max(cancelResponseResponseTopLogprobsMaxOne).describe('An integer between 0 and 20 specifying the number of most likely tokens to\nreturn at each token position, each with an associated log probability.\n').or(zod.null()).optional(),
  "temperature": zod.number().min(cancelResponseResponseTemperatureMinOne).max(cancelResponseResponseTemperatureMaxOne).optional().describe('What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nWe generally recommend altering this or `top_p` but not both.\n').or(zod.null()).optional(),
  "top_p": zod.number().min(cancelResponseResponseTopPMinOne).max(cancelResponseResponseTopPMaxOne).optional().describe('An alternative to sampling with temperature, called nucleus sampling,\nwhere the model considers the results of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising the top 10% probability mass\nare considered.\n\nWe generally recommend altering this or `temperature` but not both.\n').or(zod.null()).optional(),
  "user": zod.string().optional().describe('This field is being replaced by `safety_identifier` and `prompt_cache_key`. Use `prompt_cache_key` instead to maintain caching optimizations.\nA stable identifier for your end-users.\nUsed to boost cache hit rates by better bucketing similar requests and  to help OpenAI detect and prevent abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "safety_identifier": zod.string().optional().describe('A stable identifier used to help detect users of your application that may be violating OpenAI\'s usage policies.\nThe IDs should be a string that uniquely identifies each user. We recommend hashing their username or email address, in order to avoid sending us any identifying information. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).\n'),
  "prompt_cache_key": zod.string().optional().describe('Used by OpenAI to cache responses for similar requests to optimize your cache hit rates. Replaces the `user` field. [Learn more](https://platform.openai.com/docs/guides/prompt-caching).\n'),
  "service_tier": zod.enum(['auto', 'default', 'flex', 'scale', 'priority']).optional().describe('Specifies the processing type used for serving the request.\n  - If set to \'auto\', then the request will be processed with the service tier configured in the Project settings. Unless otherwise configured, the Project will use \'default\'.\n  - If set to \'default\', then the request will be processed with the standard pricing and performance for the selected model.\n  - If set to \'[flex](https://platform.openai.com/docs/guides/flex-processing)\' or \'[priority](https://openai.com/api-priority-processing/)\', then the request will be processed with the corresponding service tier.\n  - When not set, the default behavior is \'auto\'.\n\n  When the `service_tier` parameter is set, the response body will include the `service_tier` value based on the processing mode actually used to serve the request. This response value may be different from the value set in the parameter.\n').or(zod.null()).optional()
}).and(zod.object({
  "previous_response_id": zod.string().describe('The unique ID of the previous response to the model. Use this to\ncreate multi-turn conversations. Learn more about\n[conversation state](https://platform.openai.com/docs/guides/conversation-state). Cannot be used in conjunction with `conversation`.\n').or(zod.null()).optional(),
  "model": zod.string().or(zod.enum(['gpt-5', 'gpt-5-mini', 'gpt-5-nano', 'gpt-5-2025-08-07', 'gpt-5-mini-2025-08-07', 'gpt-5-nano-2025-08-07', 'gpt-5-chat-latest', 'gpt-4.1', 'gpt-4.1-mini', 'gpt-4.1-nano', 'gpt-4.1-2025-04-14', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-nano-2025-04-14', 'o4-mini', 'o4-mini-2025-04-16', 'o3', 'o3-2025-04-16', 'o3-mini', 'o3-mini-2025-01-31', 'o1', 'o1-2024-12-17', 'o1-preview', 'o1-preview-2024-09-12', 'o1-mini', 'o1-mini-2024-09-12', 'gpt-4o', 'gpt-4o-2024-11-20', 'gpt-4o-2024-08-06', 'gpt-4o-2024-05-13', 'gpt-4o-audio-preview', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-audio-preview-2025-06-03', 'gpt-4o-mini-audio-preview', 'gpt-4o-mini-audio-preview-2024-12-17', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-mini-search-preview-2025-03-11', 'chatgpt-4o-latest', 'codex-mini-latest', 'gpt-4o-mini', 'gpt-4o-mini-2024-07-18', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-4-1106-preview', 'gpt-4-vision-preview', 'gpt-4', 'gpt-4-0314', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0314', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-0125', 'gpt-3.5-turbo-16k-0613'])).or(zod.enum(['o1-pro', 'o1-pro-2025-03-19', 'o3-pro', 'o3-pro-2025-06-10', 'o3-deep-research', 'o3-deep-research-2025-06-26', 'o4-mini-deep-research', 'o4-mini-deep-research-2025-06-26', 'computer-use-preview', 'computer-use-preview-2025-03-11', 'gpt-5-codex', 'gpt-5-pro', 'gpt-5-pro-2025-10-06'])).optional(),
  "reasoning": zod.object({
  "effort": zod.enum(['minimal', 'low', 'medium', 'high']).optional().describe('Constrains effort on reasoning for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\nCurrently supported values are `minimal`, `low`, `medium`, and `high`. Reducing\nreasoning effort can result in faster responses and fewer tokens used\non reasoning in a response.\n\nNote: The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.\n').or(zod.null()).optional(),
  "summary": zod.enum(['auto', 'concise', 'detailed']).describe('A summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional(),
  "generate_summary": zod.enum(['auto', 'concise', 'detailed']).describe('**Deprecated:** use `summary` instead.\n\nA summary of the reasoning performed by the model. This can be\nuseful for debugging and understanding the model\'s reasoning process.\nOne of `auto`, `concise`, or `detailed`.\n').or(zod.null()).optional()
}).describe('**gpt-5 and o-series models only**\n\nConfiguration options for\n[reasoning models](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "background": zod.boolean().optional().describe('Whether to run the model response in the background.\n[Learn more](https://platform.openai.com/docs/guides/background).\n').or(zod.null()).optional(),
  "max_output_tokens": zod.number().describe('An upper bound for the number of tokens that can be generated for a response, including visible output tokens and [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n').or(zod.null()).optional(),
  "max_tool_calls": zod.number().describe('The maximum number of total calls to built-in tools that can be processed in a response. This maximum number applies across all built-in tool calls, not per individual tool. Any further attempts to call a tool by the model will be ignored.\n').or(zod.null()).optional(),
  "text": zod.object({
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).describe('The type of response format being defined. Always `text`.')
}).describe('Default response format. Used to generate text responses.\n'),zod.object({
  "type": zod.enum(['json_schema']).describe('The type of response format being defined. Always `json_schema`.'),
  "description": zod.string().optional().describe('A description of what the response format is for, used by the model to\ndetermine how to respond in the format.\n'),
  "name": zod.string().describe('The name of the response format. Must be a-z, A-Z, 0-9, or contain\nunderscores and dashes, with a maximum length of 64.\n'),
  "schema": zod.record(zod.string(), zod.any()).describe('The schema for the response format, described as a JSON Schema object.\nLearn how to build JSON schemas [here](https://json-schema.org/).\n'),
  "strict": zod.boolean().optional().describe('Whether to enable strict schema adherence when generating the output.\nIf set to true, the model will always follow the exact schema defined\nin the `schema` field. Only a subset of JSON Schema is supported when\n`strict` is `true`. To learn more, read the [Structured Outputs\nguide](https://platform.openai.com/docs/guides/structured-outputs).\n').or(zod.null()).optional()
}).describe('JSON Schema response format. Used to generate structured JSON responses.\nLearn more about [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs).\n'),zod.object({
  "type": zod.enum(['json_object']).describe('The type of response format being defined. Always `json_object`.')
}).describe('JSON object response format. An older method of generating JSON responses.\nUsing `json_schema` is recommended for models that support it. Note that the\nmodel will not generate JSON without a system or user message instructing it\nto do so.\n')]).optional().describe('An object specifying the format that the model must output.\n\nConfiguring `{ \"type\": \"json_schema\" }` enables Structured Outputs,\nwhich ensures the model will match your supplied JSON schema. Learn more in the\n[Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n\nThe default format is `{ \"type\": \"text\" }` with no additional options.\n\n**Not recommended for gpt-4o and newer models:**\n\nSetting to `{ \"type\": \"json_object\" }` enables the older JSON mode, which\nensures the message the model generates is valid JSON. Using `json_schema`\nis preferred for models that support it.\n'),
  "verbosity": zod.enum(['low', 'medium', 'high']).optional().describe('Constrains the verbosity of the model\'s response. Lower values will result in\nmore concise responses, while higher values will result in more verbose responses.\nCurrently supported values are `low`, `medium`, and `high`.\n').or(zod.null()).optional()
}).optional().describe('Configuration options for a text response from the model. Can be plain\ntext or structured JSON data. Learn more:\n- [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\n- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)\n'),
  "tools": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['function']).optional().describe('The type of the function tool. Always `function`.'),
  "name": zod.string().describe('The name of the function to call.'),
  "description": zod.string().describe('A description of the function. Used by the model to determine whether or not to call the function.').or(zod.null()).optional(),
  "parameters": zod.record(zod.string(), zod.any()).describe('A JSON schema object describing the parameters of the function.').or(zod.null()),
  "strict": zod.boolean().describe('Whether to enforce strict parameter validation. Default `true`.').or(zod.null())
}).describe('Defines a function in your own code the model can choose to call. Learn more about [function calling](https://platform.openai.com/docs/guides/function-calling).'),zod.object({
  "type": zod.enum(['file_search']).optional().describe('The type of the file search tool. Always `file_search`.'),
  "vector_store_ids": zod.array(zod.string()).describe('The IDs of the vector stores to search.'),
  "max_num_results": zod.number().optional().describe('The maximum number of results to return. This number should be between 1 and 50 inclusive.'),
  "ranking_options": zod.object({
  "ranker": zod.enum(['auto', 'default-2024-11-15']).optional(),
  "score_threshold": zod.number().optional().describe('The score threshold for the file search, a number between 0 and 1. Numbers closer to 1 will attempt to return only the most relevant results, but may return fewer results.')
}).optional(),
  "filters": zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n').or(zod.object({
  "type": zod.enum(['and', 'or']).describe('Type of operation: `and` or `or`.'),
  "filters": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['eq', 'ne', 'gt', 'gte', 'lt', 'lte']).optional().describe('Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `in`, `nin`.\n- `eq`: equals\n- `ne`: not equal\n- `gt`: greater than\n- `gte`: greater than or equal\n- `lt`: less than\n- `lte`: less than or equal\n- `in`: in\n- `nin`: not in\n'),
  "key": zod.string().describe('The key to compare against the value.'),
  "value": zod.string().or(zod.number()).or(zod.boolean()).or(zod.array(zod.string().or(zod.number()))).describe('The value to compare against the attribute key; supports string, number, or boolean types.')
}).describe('A filter used to compare a specified attribute key to a given value using a defined comparison operation.\n'),.any()])).describe('Array of filters to combine. Items can be `ComparisonFilter` or `CompoundFilter`.')
}).describe('Combine multiple filters using `and` or `or`.')).or(zod.null()).optional()
}).describe('A tool that searches for relevant content from uploaded files. Learn more about the [file search tool](https://platform.openai.com/docs/guides/tools-file-search).'),zod.object({
  "type": zod.enum(['computer_use_preview']).optional().describe('The type of the computer use tool. Always `computer_use_preview`.'),
  "environment": zod.enum(['windows', 'mac', 'linux', 'ubuntu', 'browser']),
  "display_width": zod.number().describe('The width of the computer display.'),
  "display_height": zod.number().describe('The height of the computer display.')
}).describe('A tool that controls a virtual computer. Learn more about the [computer tool](https://platform.openai.com/docs/guides/tools-computer-use).'),zod.object({
  "type": zod.enum(['web_search', 'web_search_2025_08_26']).optional().describe('The type of the web search tool. One of `web_search` or `web_search_2025_08_26`.'),
  "filters": zod.object({
  "allowed_domains": zod.array(zod.string().describe('Allowed domain for the search.')).optional().describe('Allowed domains for the search. If not provided, all domains are allowed.\nSubdomains of the provided domains are allowed as well.\n\nExample: `[\"pubmed.ncbi.nlm.nih.gov\"]`\n').or(zod.null()).optional()
}).describe('Filters for the search.\n').or(zod.null()).optional(),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).describe('The approximate location of the user.\n').or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional().describe('High level guidance for the amount of context window space to use for the search. One of `low`, `medium`, or `high`. `medium` is the default.')
}).describe('Search the Internet for sources related to the prompt. Learn more about the\n[web search tool](https://platform.openai.com/docs/guides/tools-web-search).\n'),zod.object({
  "type": zod.enum(['mcp']).describe('The type of the MCP tool. Always `mcp`.'),
  "server_label": zod.string().describe('A label for this MCP server, used to identify it in tool calls.\n'),
  "server_url": zod.string().optional().describe('The URL for the MCP server. One of `server_url` or `connector_id` must be\nprovided.\n'),
  "connector_id": zod.enum(['connector_dropbox', 'connector_gmail', 'connector_googlecalendar', 'connector_googledrive', 'connector_microsoftteams', 'connector_outlookcalendar', 'connector_outlookemail', 'connector_sharepoint']).optional().describe('Identifier for service connectors, like those available in ChatGPT. One of\n`server_url` or `connector_id` must be provided. Learn more about service\nconnectors [here](https://platform.openai.com/docs/guides/tools-remote-mcp#connectors).\n\nCurrently supported `connector_id` values are:\n\n- Dropbox: `connector_dropbox`\n- Gmail: `connector_gmail`\n- Google Calendar: `connector_googlecalendar`\n- Google Drive: `connector_googledrive`\n- Microsoft Teams: `connector_microsoftteams`\n- Outlook Calendar: `connector_outlookcalendar`\n- Outlook Email: `connector_outlookemail`\n- SharePoint: `connector_sharepoint`\n'),
  "authorization": zod.string().optional().describe('An OAuth access token that can be used with a remote MCP server, either\nwith a custom MCP server URL or a service connector. Your application\nmust handle the OAuth authorization flow and provide the token here.\n'),
  "server_description": zod.string().optional().describe('Optional description of the MCP server, used to provide more context.\n'),
  "headers": zod.record(zod.string(), zod.string()).describe('Optional HTTP headers to send to the MCP server. Use for authentication\nor other purposes.\n').or(zod.null()).optional(),
  "allowed_tools": zod.array(zod.string()).describe('A string array of allowed tool names').or(zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).describe('A filter object to specify which tools are allowed.\n')).describe('List of allowed tool names or a filter object.\n').or(zod.null()).optional(),
  "require_approval": zod.object({
  "always": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n'),
  "never": zod.object({
  "tool_names": zod.array(zod.string()).optional().describe('List of allowed tool names.'),
  "read_only": zod.boolean().optional().describe('Indicates whether or not a tool modifies data or is read-only. If an\nMCP server is [annotated with `readOnlyHint`](https://modelcontextprotocol.io/specification/2025-06-18/schema#toolannotations-readonlyhint),\nit will match this filter.\n')
}).optional().describe('A filter object to specify which tools are allowed.\n')
}).describe('Specify which of the MCP server\'s tools require approval. Can be\n`always`, `never`, or a filter object associated with tools\nthat require approval.\n').or(zod.enum(['always', 'never']).describe('Specify a single approval policy for all tools. One of `always` or\n`never`. When set to `always`, all tools will require approval. When\nset to `never`, all tools will not require approval.\n')).optional().describe('Specify which of the MCP server\'s tools require approval.').or(zod.null()).optional()
}).describe('Give the model access to additional tools via remote Model Context Protocol\n(MCP) servers. [Learn more about MCP](https://platform.openai.com/docs/guides/tools-remote-mcp).\n'),zod.object({
  "type": zod.enum(['code_interpreter']).describe('The type of the code interpreter tool. Always `code_interpreter`.\n'),
  "container": zod.string().describe('The container ID.').or(zod.object({
  "type": zod.enum(['auto']).optional().describe('Always `auto`.'),
  "file_ids": zod.array(zod.string()).max(cancelResponseResponseToolsItemContainerFileIdsMax).optional().describe('An optional list of uploaded files to make available to your code.')
}).describe('Configuration for a code interpreter container. Optionally specify the IDs of the files to run the code on.')).describe('The code interpreter container. Can be a container ID or an object that\nspecifies uploaded file IDs to make available to your code.\n')
}).describe('A tool that runs Python code to help generate a response to a prompt.\n'),zod.object({
  "type": zod.enum(['image_generation']).describe('The type of the image generation tool. Always `image_generation`.\n'),
  "model": zod.enum(['gpt-image-1', 'gpt-image-1-mini']).optional().describe('The image generation model to use. Default: `gpt-image-1`.\n'),
  "quality": zod.enum(['low', 'medium', 'high', 'auto']).optional().describe('The quality of the generated image. One of `low`, `medium`, `high`,\nor `auto`. Default: `auto`.\n'),
  "size": zod.enum(['1024x1024', '1024x1536', '1536x1024', 'auto']).optional().describe('The size of the generated image. One of `1024x1024`, `1024x1536`,\n`1536x1024`, or `auto`. Default: `auto`.\n'),
  "output_format": zod.enum(['png', 'webp', 'jpeg']).optional().describe('The output format of the generated image. One of `png`, `webp`, or\n`jpeg`. Default: `png`.\n'),
  "output_compression": zod.number().min(cancelResponseResponseToolsItemOutputCompressionMin).max(cancelResponseResponseToolsItemOutputCompressionMax).optional().describe('Compression level for the output image. Default: 100.\n'),
  "moderation": zod.enum(['auto', 'low']).optional().describe('Moderation level for the generated image. Default: `auto`.\n'),
  "background": zod.enum(['transparent', 'opaque', 'auto']).optional().describe('Background type for the generated image. One of `transparent`,\n`opaque`, or `auto`. Default: `auto`.\n'),
  "input_fidelity": zod.enum(['high', 'low']).describe('\n            Control how much effort the model will exert to match the style and features, especially facial features, of input images. This parameter is only supported for `gpt-image-1`. Unsupported for `gpt-image-1-mini`. Supports `high` and `low`. Defaults to `low`.').or(zod.null()).optional(),
  "input_image_mask": zod.object({
  "image_url": zod.string().optional().describe('Base64-encoded mask image.\n'),
  "file_id": zod.string().optional().describe('File ID for the mask image.\n')
}).optional().describe('Optional mask for inpainting. Contains `image_url`\n(string, optional) and `file_id` (string, optional).\n'),
  "partial_images": zod.number().min(cancelResponseResponseToolsItemPartialImagesMin).max(cancelResponseResponseToolsItemPartialImagesMax).optional().describe('Number of partial images to generate in streaming mode, from 0 (default value) to 3.\n')
}).describe('A tool that generates images using a model like `gpt-image-1`.\n'),zod.object({
  "type": zod.enum(['local_shell']).optional().describe('The type of the local shell tool. Always `local_shell`.')
}),zod.object({
  "type": zod.enum(['custom']).optional().describe('The type of the custom tool. Always `custom`.'),
  "name": zod.string().describe('The name of the custom tool, used to identify it in tool calls.'),
  "description": zod.string().optional().describe('Optional description of the custom tool, used to provide more context.'),
  "format": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['text']).optional().describe('Unconstrained text format. Always `text`.')
}),zod.object({
  "type": zod.enum(['grammar']).optional().describe('Grammar format. Always `grammar`.'),
  "syntax": zod.enum(['lark', 'regex']),
  "definition": zod.string().describe('The grammar definition.')
})]).optional().describe('The input format for the custom tool. Default is unconstrained text.')
}),zod.object({
  "type": zod.enum(['web_search_preview', 'web_search_preview_2025_03_11']).optional().describe('The type of the web search tool. One of `web_search_preview` or `web_search_preview_2025_03_11`.'),
  "user_location": zod.object({
  "type": zod.enum(['approximate']).optional().describe('The type of location approximation. Always `approximate`.'),
  "country": zod.string().describe('The two-letter [ISO country code](https://en.wikipedia.org/wiki/ISO_3166-1) of the user, e.g. `US`.').or(zod.null()).optional(),
  "region": zod.string().describe('Free text input for the region of the user, e.g. `California`.').or(zod.null()).optional(),
  "city": zod.string().describe('Free text input for the city of the user, e.g. `San Francisco`.').or(zod.null()).optional(),
  "timezone": zod.string().describe('The [IANA timezone](https://timeapi.io/documentation/iana-timezones) of the user, e.g. `America/Los_Angeles`.').or(zod.null()).optional()
}).or(zod.null()).optional(),
  "search_context_size": zod.enum(['low', 'medium', 'high']).optional()
}).describe('This tool searches the web for relevant results to use in a response. Learn more about the [web search tool](https://platform.openai.com/docs/guides/tools-web-search).')]).describe('A tool that can be used to generate a response.\n')).optional().describe('An array of tools the model may call while generating a response. You\ncan specify which tool to use by setting the `tool_choice` parameter.\n\nWe support the following categories of tools:\n- **Built-in tools**: Tools that are provided by OpenAI that extend the\n  model\'s capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\n  or [file search](https://platform.openai.com/docs/guides/tools-file-search). Learn more about\n  [built-in tools](https://platform.openai.com/docs/guides/tools).\n- **MCP Tools**: Integrations with third-party systems via custom MCP servers\n  or predefined connectors such as Google Drive and SharePoint. Learn more about\n  [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp).\n- **Function calls (custom tools)**: Functions that are defined by you,\n  enabling the model to call your own code with strongly typed arguments\n  and outputs. Learn more about\n  [function calling](https://platform.openai.com/docs/guides/function-calling). You can also use\n  custom tools to call your own code.\n'),
  "tool_choice": zod.discriminatedUnion('type', [.enum(['none', 'auto', 'required']).describe('Controls which (if any) tool is called by the model.\n\n`none` means the model will not call any tool and instead generates a message.\n\n`auto` means the model can pick between generating a message or calling one or\nmore tools.\n\n`required` means the model must call one or more tools.\n'),zod.object({
  "type": zod.enum(['allowed_tools']).describe('Allowed tool configuration type. Always `allowed_tools`.'),
  "mode": zod.enum(['auto', 'required']).describe('Constrains the tools available to the model to a pre-defined set.\n\n`auto` allows the model to pick from among the allowed tools and generate a\nmessage.\n\n`required` requires the model to call one or more of the allowed tools.\n'),
  "tools": zod.array(zod.record(zod.string(), zod.any()).describe('A tool definition that the model should be allowed to call.\n')).describe('A list of tool definitions that the model should be allowed to call.\n\nFor the Responses API, the list of tool definitions might look like:\n```json\n[\n  { \"type\": \"function\", \"name\": \"get_weather\" },\n  { \"type\": \"mcp\", \"server_label\": \"deepwiki\" },\n  { \"type\": \"image_generation\" }\n]\n```\n')
}).describe('Constrains the tools available to the model to a pre-defined set.\n'),zod.object({
  "type": zod.enum(['file_search', 'web_search_preview', 'computer_use_preview', 'web_search_preview_2025_03_11', 'image_generation', 'code_interpreter']).describe('The type of hosted tool the model should to use. Learn more about\n[built-in tools](https://platform.openai.com/docs/guides/tools).\n\nAllowed values are:\n- `file_search`\n- `web_search_preview`\n- `computer_use_preview`\n- `code_interpreter`\n- `image_generation`\n')
}).describe('Indicates that the model should use a built-in tool to generate a response.\n[Learn more about built-in tools](https://platform.openai.com/docs/guides/tools).\n'),zod.object({
  "type": zod.enum(['function']).describe('For function calling, the type is always `function`.'),
  "name": zod.string().describe('The name of the function to call.')
}).describe('Use this option to force the model to call a specific function.\n'),zod.object({
  "type": zod.enum(['mcp']).describe('For MCP tools, the type is always `mcp`.'),
  "server_label": zod.string().describe('The label of the MCP server to use.\n'),
  "name": zod.string().describe('The name of the tool to call on the server.\n').or(zod.null()).optional()
}).describe('Use this option to force the model to call a specific tool on a remote MCP server.\n'),zod.object({
  "type": zod.enum(['custom']).describe('For custom tool calling, the type is always `custom`.'),
  "name": zod.string().describe('The name of the custom tool to call.')
}).describe('Use this option to force the model to call a specific custom tool.\n')]).optional().describe('How the model should select which tool (or tools) to use when generating\na response. See the `tools` parameter to see how to specify which tools\nthe model can call.\n'),
  "prompt": zod.object({
  "id": zod.string().describe('The unique identifier of the prompt template to use.'),
  "version": zod.string().describe('Optional version of the prompt template.').or(zod.null()).optional(),
  "variables": zod.record(zod.string(), zod.string().or(zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.')).or(zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).')).or(zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'))).describe('Optional map of values to substitute in for variables in your\nprompt. The substitution values can either be strings, or other\nResponse input types like images or files.\n').or(zod.null()).optional()
}).describe('Reference to a prompt template and its variables.\n[Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).\n').or(zod.null()).optional(),
  "truncation": zod.enum(['auto', 'disabled']).optional().describe('The truncation strategy to use for the model response.\n- `auto`: If the input to this Response exceeds\n  the model\'s context window size, the model will truncate the\n  response to fit the context window by dropping items from the beginning of the conversation.\n- `disabled` (default): If the input size will exceed the context window\n  size for a model, the request will fail with a 400 error.\n').or(zod.null()).optional()
})).and(zod.object({
  "id": zod.string().describe('Unique identifier for this Response.\n'),
  "object": zod.enum(['response']).describe('The object type of this resource - always set to `response`.\n'),
  "status": zod.enum(['completed', 'failed', 'in_progress', 'cancelled', 'queued', 'incomplete']).optional().describe('The status of the response generation. One of `completed`, `failed`,\n`in_progress`, `cancelled`, `queued`, or `incomplete`.\n'),
  "created_at": zod.number().describe('Unix timestamp (in seconds) of when this Response was created.\n'),
  "error": zod.object({
  "code": zod.enum(['server_error', 'rate_limit_exceeded', 'invalid_prompt', 'vector_store_timeout', 'invalid_image', 'invalid_image_format', 'invalid_base64_image', 'invalid_image_url', 'image_too_large', 'image_too_small', 'image_parse_error', 'image_content_policy_violation', 'invalid_image_mode', 'image_file_too_large', 'unsupported_image_media_type', 'empty_image_file', 'failed_to_download_image', 'image_file_not_found']).describe('The error code for the response.\n'),
  "message": zod.string().describe('A human-readable description of the error.\n')
}).describe('An error object returned when the model fails to generate a Response.\n').or(zod.null()),
  "incomplete_details": zod.object({
  "reason": zod.enum(['max_output_tokens', 'content_filter']).optional().describe('The reason why the response is incomplete.')
}).describe('Details about why the response is incomplete.\n').or(zod.null()),
  "output": zod.array(zod.discriminatedUnion('type', [zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(cancelResponseResponseOutputItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')])).describe('An array of content items generated by the model.\n\n- The length and order of items in the `output` array is dependent\n  on the model\'s response.\n- Rather than accessing the first item in the `output` array and\n  assuming it\'s an `assistant` message with the content generated by\n  the model, you might consider using the `output_text` property where\n  supported in SDKs.\n'),
  "instructions": zod.string().describe('A text input to the model, equivalent to a text input with the\n`developer` role.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "role": zod.enum(['user', 'assistant', 'system', 'developer']).describe('The role of the message input. One of `user`, `assistant`, `system`, or\n`developer`.\n'),
  "content": zod.string().describe('A text input to the model.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')).describe('Text, image, or audio input to the model, used to generate a response.\nCan also contain previous assistant responses.\n'),
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always `message`.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role. Messages with the\n`assistant` role are presumed to have been generated by the model in previous\ninteractions.\n'),zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always set to `message`.\n'),
  "role": zod.enum(['user', 'system', 'developer']).describe('The role of the message input. One of `user`, `system`, or `developer`.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(cancelResponseResponseInstructionsItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "id": zod.string().describe('The ID of the computer tool call output.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(cancelResponseResponseInstructionsItemCallIdMaxOne).describe('The ID of the computer tool call that produced the output.'),
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The safety checks reported by the API that have been acknowledged by the developer.').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a computer tool call.'),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the function tool call output. Populated when this item is returned via API.').or(zod.null()).optional(),
  "call_id": zod.string().min(1).max(cancelResponseResponseInstructionsItemCallIdMaxThree).describe('The unique ID of the function tool call generated by the model.'),
  "type": zod.enum(['function_call_output']).optional().describe('The type of the function tool call output. Always `function_call_output`.'),
  "output": zod.string().max(cancelResponseResponseInstructionsItemOutputMaxTwo).describe('A JSON string of the output of the function tool call.').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().max(cancelResponseResponseInstructionsItemOutputItemTextMax).describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().max(cancelResponseResponseInstructionsItemOutputItemImageUrlMaxOne).describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto']).or(zod.null()).optional()
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision)'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().describe('The name of the file to be sent to the model.').or(zod.null()).optional(),
  "file_data": zod.string().max(cancelResponseResponseInstructionsItemOutputItemFileDataMaxOne).describe('The base64-encoded data of the file to be sent to the model.').or(zod.null()).optional(),
  "file_url": zod.string().describe('The URL of the file to be sent to the model.').or(zod.null()).optional()
}).describe('A file input to the model.')]))).describe('Text, image, or file output of the function tool call.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).or(zod.null()).optional()
}).describe('The output of a function tool call.'),zod.object({
  "type": zod.enum(['reasoning']).describe('The type of the object. Always `reasoning`.\n'),
  "id": zod.string().describe('The unique identifier of the reasoning content.\n'),
  "encrypted_content": zod.string().describe('The encrypted content of the reasoning item - populated when a response is\ngenerated with `reasoning.encrypted_content` in the `include` parameter.\n').or(zod.null()).optional(),
  "summary": zod.array(zod.object({
  "type": zod.enum(['summary_text']).optional().describe('The type of the object. Always `summary_text`.'),
  "text": zod.string().describe('A summary of the reasoning output from the model so far.')
}).describe('A summary text from the model.')).describe('Reasoning summary content.\n'),
  "content": zod.array(zod.object({
  "type": zod.enum(['reasoning_text']).optional().describe('The type of the reasoning text. Always `reasoning_text`.'),
  "text": zod.string().describe('The reasoning text from the model.')
}).describe('Reasoning text from the model.')).optional().describe('Reasoning text content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A description of the chain of thought used by a reasoning model while generating\na response. Be sure to include these items in your `input` to the Responses API\nfor subsequent turns of a conversation if you are manually\n[managing context](https://platform.openai.com/docs/guides/conversation-state).\n'),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n').or(zod.null()).optional(),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n'),zod.object({
  "type": zod.enum(['custom_tool_call_output']).describe('The type of the custom tool call output. Always `custom_tool_call_output`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call output in the OpenAI platform.\n'),
  "call_id": zod.string().describe('The call ID, used to map this custom tool call output to a custom tool call.\n'),
  "output": zod.string().describe('A string of the output of the custom tool call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the custom tool call.\n')).describe('The output from the custom tool call generated by your code.\nCan be a string or an list of output content.\n')
}).describe('The output of a custom tool call from your code, being sent back to the model.\n'),zod.object({
  "type": zod.enum(['custom_tool_call']).describe('The type of the custom tool call. Always `custom_tool_call`.\n'),
  "id": zod.string().optional().describe('The unique ID of the custom tool call in the OpenAI platform.\n'),
  "call_id": zod.string().describe('An identifier used to map this custom tool call to a tool call output.\n'),
  "name": zod.string().describe('The name of the custom tool being called.\n'),
  "input": zod.string().describe('The input for the custom tool call generated by the model.\n')
}).describe('A call to a custom tool created by the model.\n')]).describe('Content item used to generate a response.\n'),zod.object({
  "type": zod.enum(['item_reference']).optional().describe('The type of item to reference. Always `item_reference`.').or(zod.null()).optional(),
  "id": zod.string().describe('The ID of the item to reference.')
}).describe('An internal identifier for an item to reference.')])).describe('A list of one or many input items to the model, containing\ndifferent content types.\n')).describe('A system (or developer) message inserted into the model\'s context.\n\nWhen using along with `previous_response_id`, the instructions from a previous\nresponse will not be carried over to the next response. This makes it simple\nto swap out system (or developer) messages in new responses.\n').or(zod.null()),
  "output_text": zod.string().describe('SDK-only convenience property that contains the aggregated text output\nfrom all `output_text` items in the `output` array, if any are present.\nSupported in the Python and JavaScript SDKs.\n').or(zod.null()).optional(),
  "usage": zod.object({
  "input_tokens": zod.number().describe('The number of input tokens.'),
  "input_tokens_details": zod.object({
  "cached_tokens": zod.number().describe('The number of tokens that were retrieved from the cache.\n[More on prompt caching](https://platform.openai.com/docs/guides/prompt-caching).\n')
}).describe('A detailed breakdown of the input tokens.'),
  "output_tokens": zod.number().describe('The number of output tokens.'),
  "output_tokens_details": zod.object({
  "reasoning_tokens": zod.number().describe('The number of reasoning tokens.')
}).describe('A detailed breakdown of the output tokens.'),
  "total_tokens": zod.number().describe('The total number of tokens used.')
}).optional().describe('Represents token usage details including input tokens, output tokens,\na breakdown of output tokens, and the total tokens used.\n'),
  "parallel_tool_calls": zod.boolean().optional().describe('Whether to allow the model to run tool calls in parallel.\n'),
  "conversation": zod.object({
  "id": zod.string().describe('The unique ID of the conversation.')
}).describe('The conversation that this response belongs to. Input items and output items from this response are automatically added to this conversation.').or(zod.null()).optional()
}))

/**
 * Returns a list of input items for a given response.
 * @summary List input items
 */
export const listInputItemsParams = zod.object({
  "response_id": zod.string().describe('The ID of the response to retrieve input items for.')
})

export const listInputItemsQueryLimitDefault = 20;

export const listInputItemsQueryParams = zod.object({
  "limit": zod.number().optional().describe('A limit on the number of objects to be returned. Limit can range between\n1 and 100, and the default is 20.\n'),
  "order": zod.enum(['asc', 'desc']).optional().describe('The order to return the input items in. Default is `desc`.\n- `asc`: Return the input items in ascending order.\n- `desc`: Return the input items in descending order.\n'),
  "after": zod.string().optional().describe('An item ID to list items after, used in pagination.\n'),
  "include": zod.array(zod.enum(['file_search_call.results', 'web_search_call.results', 'web_search_call.action.sources', 'message.input_image.image_url', 'computer_call_output.output.image_url', 'code_interpreter_call.outputs', 'reasoning.encrypted_content', 'message.output_text.logprobs']).describe('Specify additional output data to include in the model response. Currently supported values are:\n- `web_search_call.action.sources`: Include the sources of the web search tool call.\n- `code_interpreter_call.outputs`: Includes the outputs of python code execution in code interpreter tool call items.\n- `computer_call_output.output.image_url`: Include image urls from the computer call output.\n- `file_search_call.results`: Include the search results of the file search tool call.\n- `message.input_image.image_url`: Include image urls from the input message.\n- `message.output_text.logprobs`: Include logprobs with assistant messages.\n- `reasoning.encrypted_content`: Includes an encrypted version of reasoning tokens in reasoning item outputs. This enables reasoning items to be used in multi-turn conversations when using the Responses API statelessly (like when the `store` parameter is set to `false`, or when an organization is enrolled in the zero data retention program).')).optional().describe('Additional fields to include in the response. See the `include`\nparameter for Response creation above for more information.\n')
})

export const listInputItemsResponseDataItemContentItemTypeDefault = "input_text";export const listInputItemsResponseDataItemContentItemTypeDefaultOne = "input_image";export const listInputItemsResponseDataItemContentItemTypeDefaultTwo = "input_file";export const listInputItemsResponseDataItemContentItemTypeDefaultFour = "output_text";export const listInputItemsResponseDataItemContentItemAnnotationsItemTypeDefault = "file_citation";export const listInputItemsResponseDataItemContentItemAnnotationsItemTypeDefaultOne = "url_citation";export const listInputItemsResponseDataItemContentItemAnnotationsItemTypeDefaultTwo = "container_file_citation";export const listInputItemsResponseDataItemContentItemTypeDefaultFive = "refusal";export const listInputItemsResponseDataItemResultsItemAttributesMaxThree = 512;
export const listInputItemsResponseDataItemTypeDefaultThree = "computer_call";export const listInputItemsResponseDataItemActionTypeDefault = "click";export const listInputItemsResponseDataItemActionTypeDefaultOne = "double_click";export const listInputItemsResponseDataItemActionTypeDefaultTwo = "drag";export const listInputItemsResponseDataItemActionTypeDefaultThree = "keypress";export const listInputItemsResponseDataItemActionTypeDefaultFour = "move";export const listInputItemsResponseDataItemActionTypeDefaultFive = "screenshot";export const listInputItemsResponseDataItemActionTypeDefaultSix = "scroll";export const listInputItemsResponseDataItemActionTypeDefaultSeven = "type";export const listInputItemsResponseDataItemActionTypeDefaultEight = "wait";export const listInputItemsResponseDataItemTypeDefaultFour = "computer_call_output";export const listInputItemsResponseDataItemOutputTypeDefault = "computer_screenshot";export const listInputItemsResponseDataItemOutputItemTypeDefault = "input_text";export const listInputItemsResponseDataItemOutputItemTypeDefaultOne = "input_image";export const listInputItemsResponseDataItemOutputItemTypeDefaultTwo = "input_file";export const listInputItemsResponseDataItemTypeDefaultNine = "code_interpreter_call";export const listInputItemsResponseDataItemOutputsItemTypeDefault = "logs";export const listInputItemsResponseDataItemOutputsItemTypeDefaultOne = "image";export const listInputItemsResponseDataItemActionTypeDefaultOnetwo = "exec";

export const listInputItemsResponse = zod.object({
  "object": zod.any().describe('The type of object returned, must be `list`.'),
  "data": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['message']).optional().describe('The type of the message input. Always set to `message`.\n'),
  "role": zod.enum(['user', 'system', 'developer']).describe('The role of the message input. One of `user`, `system`, or `developer`.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.'),zod.object({
  "type": zod.enum(['input_audio']).describe('The type of the input item. Always `input_audio`.\n'),
  "input_audio": zod.object({
  "data": zod.string().describe('Base64-encoded audio data.\n'),
  "format": zod.enum(['mp3', 'wav']).describe('The format of the audio data. Currently supported formats are `mp3` and\n`wav`.\n')
})
}).describe('An audio input to the model.\n')])).describe('A list of one or many input items to the model, containing different content\ntypes.\n')
}).describe('A message input to the model with a role indicating instruction following\nhierarchy. Instructions given with the `developer` or `system` role take\nprecedence over instructions given with the `user` role.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the message input.\n')
})),zod.object({
  "id": zod.string().describe('The unique ID of the output message.\n'),
  "type": zod.enum(['message']).describe('The type of the output message. Always `message`.\n'),
  "role": zod.enum(['assistant']).describe('The role of the output message. Always `assistant`.\n'),
  "content": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['output_text']).optional().describe('The type of the output text. Always `output_text`.'),
  "text": zod.string().describe('The text output from the model.'),
  "annotations": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['file_citation']).optional().describe('The type of the file citation. Always `file_citation`.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "index": zod.number().describe('The index of the file in the list of files.'),
  "filename": zod.string().describe('The filename of the file cited.')
}).describe('A citation to a file.'),zod.object({
  "type": zod.enum(['url_citation']).optional().describe('The type of the URL citation. Always `url_citation`.'),
  "url": zod.string().describe('The URL of the web resource.'),
  "start_index": zod.number().describe('The index of the first character of the URL citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the URL citation in the message.'),
  "title": zod.string().describe('The title of the web resource.')
}).describe('A citation for a web resource used to generate a model response.'),zod.object({
  "type": zod.enum(['container_file_citation']).optional().describe('The type of the container file citation. Always `container_file_citation`.'),
  "container_id": zod.string().describe('The ID of the container file.'),
  "file_id": zod.string().describe('The ID of the file.'),
  "start_index": zod.number().describe('The index of the first character of the container file citation in the message.'),
  "end_index": zod.number().describe('The index of the last character of the container file citation in the message.'),
  "filename": zod.string().describe('The filename of the container file cited.')
}).describe('A citation for a container file used to generate a model response.'),zod.object({
  "type": zod.enum(['file_path']).describe('The type of the file path. Always `file_path`.\n'),
  "file_id": zod.string().describe('The ID of the file.\n'),
  "index": zod.number().describe('The index of the file in the list of files.\n')
}).describe('A path to a file.\n')])).describe('The annotations of the text output.'),
  "logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number()),
  "top_logprobs": zod.array(zod.object({
  "token": zod.string(),
  "logprob": zod.number(),
  "bytes": zod.array(zod.number())
}).describe('The top log probability of a token.'))
}).describe('The log probability of a token.')).optional()
}).describe('A text output from the model.'),zod.object({
  "type": zod.enum(['refusal']).optional().describe('The type of the refusal. Always `refusal`.'),
  "refusal": zod.string().describe('The refusal explanation from the model.')
}).describe('A refusal from the model.')])).describe('The content of the output message.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('An output message from the model.\n'),zod.object({
  "id": zod.string().describe('The unique ID of the file search tool call.\n'),
  "type": zod.enum(['file_search_call']).describe('The type of the file search tool call. Always `file_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'incomplete', 'failed']).describe('The status of the file search tool call. One of `in_progress`,\n`searching`, `incomplete` or `failed`,\n'),
  "queries": zod.array(zod.string()).describe('The queries used to search for files.\n'),
  "results": zod.array(zod.object({
  "file_id": zod.string().optional().describe('The unique ID of the file.\n'),
  "text": zod.string().optional().describe('The text that was retrieved from the file.\n'),
  "filename": zod.string().optional().describe('The name of the file.\n'),
  "attributes": zod.record(zod.string(), zod.string().max(listInputItemsResponseDataItemResultsItemAttributesMaxThree).or(zod.number()).or(zod.boolean())).describe('Set of 16 key-value pairs that can be attached to an object. This can be\nuseful for storing additional information about the object in a structured\nformat, and querying for objects via API or the dashboard. Keys are strings\nwith a maximum length of 64 characters. Values are strings with a maximum\nlength of 512 characters, booleans, or numbers.\n').or(zod.null()).optional(),
  "score": zod.number().optional().describe('The relevance score of the file - a value between 0 and 1.\n')
})).describe('The results of the file search tool call.\n').or(zod.null()).optional()
}).describe('The results of a file search tool call. See the\n[file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call']).optional().describe('The type of the computer call. Always `computer_call`.'),
  "id": zod.string().describe('The unique ID of the computer call.'),
  "call_id": zod.string().describe('An identifier used when responding to the tool call with output.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['click']).optional().describe('Specifies the event type. For a click action, this property is always `click`.'),
  "button": zod.enum(['left', 'right', 'wheel', 'back', 'forward']),
  "x": zod.number().describe('The x-coordinate where the click occurred.'),
  "y": zod.number().describe('The y-coordinate where the click occurred.')
}).describe('A click action.'),zod.object({
  "type": zod.enum(['double_click']).optional().describe('Specifies the event type. For a double click action, this property is always set to `double_click`.'),
  "x": zod.number().describe('The x-coordinate where the double click occurred.'),
  "y": zod.number().describe('The y-coordinate where the double click occurred.')
}).describe('A double click action.'),zod.object({
  "type": zod.enum(['drag']).optional().describe('Specifies the event type. For a drag action, this property is\nalways set to `drag`.\n'),
  "path": zod.array(zod.object({
  "x": zod.number().describe('The x-coordinate.'),
  "y": zod.number().describe('The y-coordinate.')
}).describe('An x/y coordinate pair, e.g. `{ x: 100, y: 200 }`.')).describe('An array of coordinates representing the path of the drag action. Coordinates will appear as an array\nof objects, eg\n```\n[\n  { x: 100, y: 200 },\n  { x: 200, y: 300 }\n]\n```\n')
}).describe('A drag action.\n'),zod.object({
  "type": zod.enum(['keypress']).optional().describe('Specifies the event type. For a keypress action, this property is always set to `keypress`.'),
  "keys": zod.array(zod.string().describe('One of the keys the model is requesting to be pressed.')).describe('The combination of keys the model is requesting to be pressed. This is an array of strings, each representing a key.')
}).describe('A collection of keypresses the model would like to perform.'),zod.object({
  "type": zod.enum(['move']).optional().describe('Specifies the event type. For a move action, this property is\nalways set to `move`.\n'),
  "x": zod.number().describe('The x-coordinate to move to.\n'),
  "y": zod.number().describe('The y-coordinate to move to.\n')
}).describe('A mouse move action.\n'),zod.object({
  "type": zod.enum(['screenshot']).optional().describe('Specifies the event type. For a screenshot action, this property is\nalways set to `screenshot`.\n')
}).describe('A screenshot action.\n'),zod.object({
  "type": zod.enum(['scroll']).optional().describe('Specifies the event type. For a scroll action, this property is\nalways set to `scroll`.\n'),
  "x": zod.number().describe('The x-coordinate where the scroll occurred.\n'),
  "y": zod.number().describe('The y-coordinate where the scroll occurred.\n'),
  "scroll_x": zod.number().describe('The horizontal scroll distance.\n'),
  "scroll_y": zod.number().describe('The vertical scroll distance.\n')
}).describe('A scroll action.\n'),zod.object({
  "type": zod.enum(['type']).optional().describe('Specifies the event type. For a type action, this property is\nalways set to `type`.\n'),
  "text": zod.string().describe('The text to type.\n')
}).describe('An action to type in text.\n'),zod.object({
  "type": zod.enum(['wait']).optional().describe('Specifies the event type. For a wait action, this property is\nalways set to `wait`.\n')
}).describe('A wait action.\n')]),
  "pending_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).describe('The pending safety checks for the computer call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to a computer use tool. See the\n[computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.\n'),zod.object({
  "type": zod.enum(['computer_call_output']).optional().describe('The type of the computer tool call output. Always `computer_call_output`.\n'),
  "id": zod.string().optional().describe('The ID of the computer tool call output.\n'),
  "call_id": zod.string().describe('The ID of the computer tool call that produced the output.\n'),
  "acknowledged_safety_checks": zod.array(zod.object({
  "id": zod.string().describe('The ID of the pending safety check.'),
  "code": zod.string().describe('The type of the pending safety check.').or(zod.null()).optional(),
  "message": zod.string().describe('Details about the pending safety check.').or(zod.null()).optional()
}).describe('A pending safety check for the computer call.')).optional().describe('The safety checks reported by the API that have been acknowledged by the\ndeveloper.\n'),
  "output": zod.object({
  "type": zod.enum(['computer_screenshot']).optional().describe('Specifies the event type. For a computer screenshot, this property is\nalways set to `computer_screenshot`.\n'),
  "image_url": zod.string().optional().describe('The URL of the screenshot image.'),
  "file_id": zod.string().optional().describe('The identifier of an uploaded file that contains the screenshot.')
}).describe('A computer screenshot image used with the computer use tool.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the message input. One of `in_progress`, `completed`, or\n`incomplete`. Populated when input items are returned via API.\n')
}).describe('The output of a computer tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the computer call tool output.\n')
})),zod.object({
  "id": zod.string().describe('The unique ID of the web search tool call.\n'),
  "type": zod.enum(['web_search_call']).describe('The type of the web search tool call. Always `web_search_call`.\n'),
  "status": zod.enum(['in_progress', 'searching', 'completed', 'failed']).describe('The status of the web search tool call.\n'),
  "action": zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['search']).describe('The action type.\n'),
  "query": zod.string().describe('The search query.\n'),
  "sources": zod.array(zod.object({
  "type": zod.enum(['url']).describe('The type of source. Always `url`.\n'),
  "url": zod.string().describe('The URL of the source.\n')
}).describe('A source used in the search.\n')).optional().describe('The sources used in the search.\n')
}).describe('Action type \"search\" - Performs a web search query.\n'),zod.object({
  "type": zod.enum(['open_page']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL opened by the model.\n')
}).describe('Action type \"open_page\" - Opens a specific URL from search results.\n'),zod.object({
  "type": zod.enum(['find']).describe('The action type.\n'),
  "url": zod.string().url().describe('The URL of the page searched for the pattern.\n'),
  "pattern": zod.string().describe('The pattern or text to search for within the page.\n')
}).describe('Action type \"find\": Searches for a pattern within a loaded page.\n')]).describe('An object describing the specific action taken in this web search call.\nIncludes details on how the model used the web (search, open_page, find).\n')
}).describe('The results of a web search tool call. See the\n[web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.\n'),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call.\n'),
  "type": zod.enum(['function_call']).describe('The type of the function tool call. Always `function_call`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "name": zod.string().describe('The name of the function to run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments to pass to the function.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('A tool call to run a function. See the\n[function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function tool call.\n')
})),zod.object({
  "id": zod.string().optional().describe('The unique ID of the function tool call output. Populated when this item\nis returned via API.\n'),
  "type": zod.enum(['function_call_output']).describe('The type of the function tool call output. Always `function_call_output`.\n'),
  "call_id": zod.string().describe('The unique ID of the function tool call generated by the model.\n'),
  "output": zod.string().describe('A string of the output of the function call.\n').or(zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['input_text']).optional().describe('The type of the input item. Always `input_text`.'),
  "text": zod.string().describe('The text input to the model.')
}).describe('A text input to the model.'),zod.object({
  "type": zod.enum(['input_image']).optional().describe('The type of the input item. Always `input_image`.'),
  "image_url": zod.string().describe('The URL of the image to be sent to the model. A fully qualified URL or base64 encoded image in a data URL.').or(zod.null()).optional(),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "detail": zod.enum(['low', 'high', 'auto'])
}).describe('An image input to the model. Learn about [image inputs](https://platform.openai.com/docs/guides/vision).'),zod.object({
  "type": zod.enum(['input_file']).optional().describe('The type of the input item. Always `input_file`.'),
  "file_id": zod.string().describe('The ID of the file to be sent to the model.').or(zod.null()).optional(),
  "filename": zod.string().optional().describe('The name of the file to be sent to the model.'),
  "file_url": zod.string().optional().describe('The URL of the file to be sent to the model.'),
  "file_data": zod.string().optional().describe('The content of the file to be sent to the model.\n')
}).describe('A file input to the model.')])).describe('Text, image, or file output of the function call.\n')).describe('The output from the function call generated by your code.\nCan be a string or an list of output content.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).optional().describe('The status of the item. One of `in_progress`, `completed`, or\n`incomplete`. Populated when items are returned via API.\n')
}).describe('The output of a function tool call.\n').and(zod.object({
  "id": zod.string().describe('The unique ID of the function call tool output.\n')
})),zod.object({
  "type": zod.enum(['image_generation_call']).describe('The type of the image generation call. Always `image_generation_call`.\n'),
  "id": zod.string().describe('The unique ID of the image generation call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'generating', 'failed']).describe('The status of the image generation call.\n'),
  "result": zod.string().describe('The generated image encoded in base64.\n').or(zod.null())
}).describe('An image generation request made by the model.\n'),zod.object({
  "type": zod.enum(['code_interpreter_call']).optional().describe('The type of the code interpreter tool call. Always `code_interpreter_call`.\n'),
  "id": zod.string().describe('The unique ID of the code interpreter tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'interpreting', 'failed']).describe('The status of the code interpreter tool call. Valid values are `in_progress`, `completed`, `incomplete`, `interpreting`, and `failed`.\n'),
  "container_id": zod.string().describe('The ID of the container used to run the code.\n'),
  "code": zod.string().describe('The code to run, or null if not available.\n').or(zod.null()),
  "outputs": zod.array(zod.discriminatedUnion('type', [zod.object({
  "type": zod.enum(['logs']).optional().describe('The type of the output. Always `logs`.'),
  "logs": zod.string().describe('The logs output from the code interpreter.')
}).describe('The logs output from the code interpreter.'),zod.object({
  "type": zod.enum(['image']).optional().describe('The type of the output. Always `image`.'),
  "url": zod.string().describe('The URL of the image output from the code interpreter.')
}).describe('The image output from the code interpreter.')])).describe('The outputs generated by the code interpreter, such as logs or images.\nCan be null if no outputs are available.\n').or(zod.null())
}).describe('A tool call to run code.\n'),zod.object({
  "type": zod.enum(['local_shell_call']).describe('The type of the local shell call. Always `local_shell_call`.\n'),
  "id": zod.string().describe('The unique ID of the local shell call.\n'),
  "call_id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "action": zod.object({
  "type": zod.enum(['exec']).optional().describe('The type of the local shell action. Always `exec`.'),
  "command": zod.array(zod.string()).describe('The command to run.'),
  "timeout_ms": zod.number().describe('Optional timeout in milliseconds for the command.').or(zod.null()).optional(),
  "working_directory": zod.string().describe('Optional working directory to run the command in.').or(zod.null()).optional(),
  "env": zod.record(zod.string(), zod.string()).describe('Environment variables to set for the command.'),
  "user": zod.string().describe('Optional user to run the command as.').or(zod.null()).optional()
}).describe('Execute a shell command on the server.'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the local shell call.\n')
}).describe('A tool call to run a command on the local shell.\n'),zod.object({
  "type": zod.enum(['local_shell_call_output']).describe('The type of the local shell tool call output. Always `local_shell_call_output`.\n'),
  "id": zod.string().describe('The unique ID of the local shell tool call generated by the model.\n'),
  "output": zod.string().describe('A JSON string of the output of the local shell tool call.\n'),
  "status": zod.enum(['in_progress', 'completed', 'incomplete']).describe('The status of the item. One of `in_progress`, `completed`, or `incomplete`.\n').or(zod.null()).optional()
}).describe('The output of a local shell tool call.\n'),zod.object({
  "type": zod.enum(['mcp_list_tools']).describe('The type of the item. Always `mcp_list_tools`.\n'),
  "id": zod.string().describe('The unique ID of the list.\n'),
  "server_label": zod.string().describe('The label of the MCP server.\n'),
  "tools": zod.array(zod.object({
  "name": zod.string().describe('The name of the tool.\n'),
  "description": zod.string().describe('The description of the tool.\n').or(zod.null()).optional(),
  "input_schema": zod.object({

}).describe('The JSON schema describing the tool\'s input.\n'),
  "annotations": zod.object({

}).describe('Additional annotations about the tool.\n').or(zod.null()).optional()
}).describe('A tool available on an MCP server.\n')).describe('The tools available on the server.\n'),
  "error": zod.string().describe('Error message if the server could not list tools.\n').or(zod.null()).optional()
}).describe('A list of tools available on an MCP server.\n'),zod.object({
  "type": zod.enum(['mcp_approval_request']).describe('The type of the item. Always `mcp_approval_request`.\n'),
  "id": zod.string().describe('The unique ID of the approval request.\n'),
  "server_label": zod.string().describe('The label of the MCP server making the request.\n'),
  "name": zod.string().describe('The name of the tool to run.\n'),
  "arguments": zod.string().describe('A JSON string of arguments for the tool.\n')
}).describe('A request for human approval of a tool invocation.\n'),zod.object({
  "type": zod.enum(['mcp_approval_response']).describe('The type of the item. Always `mcp_approval_response`.\n'),
  "id": zod.string().describe('The unique ID of the approval response\n'),
  "approval_request_id": zod.string().describe('The ID of the approval request being answered.\n'),
  "approve": zod.boolean().describe('Whether the request was approved.\n'),
  "reason": zod.string().describe('Optional reason for the decision.\n').or(zod.null()).optional()
}).describe('A response to an MCP approval request.\n'),zod.object({
  "type": zod.enum(['mcp_call']).describe('The type of the item. Always `mcp_call`.\n'),
  "id": zod.string().describe('The unique ID of the tool call.\n'),
  "server_label": zod.string().describe('The label of the MCP server running the tool.\n'),
  "name": zod.string().describe('The name of the tool that was run.\n'),
  "arguments": zod.string().describe('A JSON string of the arguments passed to the tool.\n'),
  "output": zod.string().describe('The output from the tool call.\n').or(zod.null()).optional(),
  "error": zod.string().describe('The error from the tool call, if any.\n').or(zod.null()).optional(),
  "status": zod.enum(['in_progress', 'completed', 'incomplete', 'calling', 'failed']).optional(),
  "approval_request_id": zod.string().describe('Unique identifier for the MCP tool call approval request.\nInclude this value in a subsequent `mcp_approval_response` input to approve or reject the corresponding tool call.\n').or(zod.null()).optional()
}).describe('An invocation of a tool on an MCP server.\n')]).describe('Content item used to generate a response.\n')).describe('A list of items used to generate this response.'),
  "has_more": zod.boolean().describe('Whether there are more items available.'),
  "first_id": zod.string().describe('The ID of the first item in the list.'),
  "last_id": zod.string().describe('The ID of the last item in the list.')
}).describe('A list of Response items.')

