/**
 * Generated by orval v7.7.0 ðŸº
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import * as axios from 'axios';
import type {
  AxiosRequestConfig,
  AxiosResponse
} from 'axios';

import type {
  CreateEvalRequest,
  CreateEvalRunRequest,
  DeleteEval200,
  DeleteEvalRun200,
  Eval,
  EvalList,
  EvalRun,
  EvalRunList,
  EvalRunOutputItem,
  EvalRunOutputItemList,
  GetEvalRunOutputItemsParams,
  GetEvalRunsParams,
  ListEvalsParams,
  UpdateEvalBody
} from '.././schema';




  export const getEvals = () => {
/**
 * List evaluations for a project.

 * @summary List evals
 */
const listEvals = <TData = AxiosResponse<EvalList>>(
    params?: ListEvalsParams, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.get(
      `/evals`,{
    ...options,
        params: {...params, ...options?.params},}
    );
  }
/**
 * Create the structure of an evaluation that can be used to test a model's performance.
An evaluation is a set of testing criteria and the config for a data source, which dictates the schema of the data used in the evaluation. After creating an evaluation, you can run it on different models and model parameters. We support several types of graders and datasources.
For more information, see the [Evals guide](https://platform.openai.com/docs/guides/evals).

 * @summary Create eval
 */
const createEval = <TData = AxiosResponse<Eval>>(
    createEvalRequest: CreateEvalRequest, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.post(
      `/evals`,
      createEvalRequest,options
    );
  }
/**
 * Get an evaluation by ID.

 * @summary Get an eval
 */
const getEval = <TData = AxiosResponse<Eval>>(
    evalId: string, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.get(
      `/evals/${evalId}`,options
    );
  }
/**
 * Update certain properties of an evaluation.

 * @summary Update an eval
 */
const updateEval = <TData = AxiosResponse<Eval>>(
    evalId: string,
    updateEvalBody: UpdateEvalBody, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.post(
      `/evals/${evalId}`,
      updateEvalBody,options
    );
  }
/**
 * Delete an evaluation.

 * @summary Delete an eval
 */
const deleteEval = <TData = AxiosResponse<DeleteEval200>>(
    evalId: string, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.delete(
      `/evals/${evalId}`,options
    );
  }
/**
 * Get a list of runs for an evaluation.

 * @summary Get eval runs
 */
const getEvalRuns = <TData = AxiosResponse<EvalRunList>>(
    evalId: string,
    params?: GetEvalRunsParams, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.get(
      `/evals/${evalId}/runs`,{
    ...options,
        params: {...params, ...options?.params},}
    );
  }
/**
 * Kicks off a new run for a given evaluation, specifying the data source, and what model configuration to use to test. The datasource will be validated against the schema specified in the config of the evaluation.

 * @summary Create eval run
 */
const createEvalRun = <TData = AxiosResponse<EvalRun>>(
    evalId: string,
    createEvalRunRequest: CreateEvalRunRequest, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.post(
      `/evals/${evalId}/runs`,
      createEvalRunRequest,options
    );
  }
/**
 * Get an evaluation run by ID.

 * @summary Get an eval run
 */
const getEvalRun = <TData = AxiosResponse<EvalRun>>(
    evalId: string,
    runId: string, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.get(
      `/evals/${evalId}/runs/${runId}`,options
    );
  }
/**
 * Cancel an ongoing evaluation run.

 * @summary Cancel eval run
 */
const cancelEvalRun = <TData = AxiosResponse<EvalRun>>(
    evalId: string,
    runId: string, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.post(
      `/evals/${evalId}/runs/${runId}`,undefined,options
    );
  }
/**
 * Delete an eval run.

 * @summary Delete eval run
 */
const deleteEvalRun = <TData = AxiosResponse<DeleteEvalRun200>>(
    evalId: string,
    runId: string, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.delete(
      `/evals/${evalId}/runs/${runId}`,options
    );
  }
/**
 * Get a list of output items for an evaluation run.

 * @summary Get eval run output items
 */
const getEvalRunOutputItems = <TData = AxiosResponse<EvalRunOutputItemList>>(
    evalId: string,
    runId: string,
    params?: GetEvalRunOutputItemsParams, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.get(
      `/evals/${evalId}/runs/${runId}/output_items`,{
    ...options,
        params: {...params, ...options?.params},}
    );
  }
/**
 * Get an evaluation run output item by ID.

 * @summary Get an output item of an eval run
 */
const getEvalRunOutputItem = <TData = AxiosResponse<EvalRunOutputItem>>(
    evalId: string,
    runId: string,
    outputItemId: string, options?: AxiosRequestConfig
 ): Promise<TData> => {
    return axios.default.get(
      `/evals/${evalId}/runs/${runId}/output_items/${outputItemId}`,options
    );
  }
return {listEvals,createEval,getEval,updateEval,deleteEval,getEvalRuns,createEvalRun,getEvalRun,cancelEvalRun,deleteEvalRun,getEvalRunOutputItems,getEvalRunOutputItem}};
export type ListEvalsResult = AxiosResponse<EvalList>
export type CreateEvalResult = AxiosResponse<Eval>
export type GetEvalResult = AxiosResponse<Eval>
export type UpdateEvalResult = AxiosResponse<Eval>
export type DeleteEvalResult = AxiosResponse<DeleteEval200>
export type GetEvalRunsResult = AxiosResponse<EvalRunList>
export type CreateEvalRunResult = AxiosResponse<EvalRun>
export type GetEvalRunResult = AxiosResponse<EvalRun>
export type CancelEvalRunResult = AxiosResponse<EvalRun>
export type DeleteEvalRunResult = AxiosResponse<DeleteEvalRun200>
export type GetEvalRunOutputItemsResult = AxiosResponse<EvalRunOutputItemList>
export type GetEvalRunOutputItemResult = AxiosResponse<EvalRunOutputItem>
